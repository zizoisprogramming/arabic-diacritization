{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "lIA95EyTmrHd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-11-30T07:04:26.33294Z",
          "iopub.status.busy": "2025-11-30T07:04:26.332725Z",
          "iopub.status.idle": "2025-11-30T07:04:31.770625Z",
          "shell.execute_reply": "2025-11-30T07:04:31.769689Z",
          "shell.execute_reply.started": "2025-11-30T07:04:26.332923Z"
        },
        "id": "lIA95EyTmrHd",
        "outputId": "176af2bb-24bc-4814-98d7-4df235b8ca74",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting protobuf==3.20.*\n",
            "  Downloading protobuf-3.20.3-py2.py3-none-any.whl.metadata (720 bytes)\n",
            "Downloading protobuf-3.20.3-py2.py3-none-any.whl (162 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.1/162.1 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: protobuf\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 6.33.0\n",
            "    Uninstalling protobuf-6.33.0:\n",
            "      Successfully uninstalled protobuf-6.33.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "bigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\n",
            "opentelemetry-proto 1.37.0 requires protobuf<7.0,>=5.0, but you have protobuf 3.20.3 which is incompatible.\n",
            "onnx 1.18.0 requires protobuf>=4.25.1, but you have protobuf 3.20.3 which is incompatible.\n",
            "a2a-sdk 0.3.10 requires protobuf>=5.29.5, but you have protobuf 3.20.3 which is incompatible.\n",
            "ray 2.51.1 requires click!=8.3.0,>=7.0, but you have click 8.3.0 which is incompatible.\n",
            "bigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\n",
            "tensorflow-metadata 1.17.2 requires protobuf>=4.25.2; python_version >= \"3.11\", but you have protobuf 3.20.3 which is incompatible.\n",
            "pydrive2 1.21.3 requires cryptography<44, but you have cryptography 46.0.3 which is incompatible.\n",
            "pydrive2 1.21.3 requires pyOpenSSL<=24.2.1,>=19.1.0, but you have pyopenssl 25.3.0 which is incompatible.\n",
            "ydf 0.13.0 requires protobuf<7.0.0,>=5.29.1, but you have protobuf 3.20.3 which is incompatible.\n",
            "grpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 3.20.3 which is incompatible.\n",
            "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2025.10.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed protobuf-3.20.3\n"
          ]
        }
      ],
      "source": [
        "!pip install \"protobuf==3.20.*\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f819122-f1ce-4a03-b147-c5b5274813d1",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-30T07:04:41.007813Z",
          "iopub.status.busy": "2025-11-30T07:04:41.007268Z",
          "iopub.status.idle": "2025-11-30T07:04:41.012169Z",
          "shell.execute_reply": "2025-11-30T07:04:41.011323Z",
          "shell.execute_reply.started": "2025-11-30T07:04:41.007777Z"
        },
        "id": "2f819122-f1ce-4a03-b147-c5b5274813d1",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "padded_path = \"/kaggle/input/arabic-diacritics/keras/default/1/padded.pkl\"\n",
        "val_path = \"/kaggle/input/val-2/padded_val.pkl\"\n",
        "\n",
        "diacritic2id_path = \"/kaggle/input/arabic-diacritics/keras/default/1/diacritic2id.json\"\n",
        "idx2char_path = \"/kaggle/input/arabic-diacritics/keras/default/1/idx2char.json\"\n",
        "char2idx_path = \"/kaggle/input/arabic-diacritics/keras/default/1/char2idx.json\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93223c08",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-30T07:04:41.30954Z",
          "iopub.status.busy": "2025-11-30T07:04:41.309084Z",
          "iopub.status.idle": "2025-11-30T07:04:57.929586Z",
          "shell.execute_reply": "2025-11-30T07:04:57.92899Z",
          "shell.execute_reply.started": "2025-11-30T07:04:41.309518Z"
        },
        "id": "93223c08",
        "outputId": "0d590d6c-e562-462f-d987-a9a6329a7af7",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-30 07:04:42.861469: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1764486283.070395      47 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1764486283.126676      47 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, TimeDistributed, Bidirectional, Input\n",
        "import json\n",
        "import os\n",
        "import pickle\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a519aca",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-30T07:05:33.860524Z",
          "iopub.status.busy": "2025-11-30T07:05:33.859598Z",
          "iopub.status.idle": "2025-11-30T07:05:33.882286Z",
          "shell.execute_reply": "2025-11-30T07:05:33.881532Z",
          "shell.execute_reply.started": "2025-11-30T07:05:33.860498Z"
        },
        "id": "4a519aca",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "with open(diacritic2id_path, 'r', encoding='utf-8') as f:\n",
        "    label2id = json.load(f)\n",
        "\n",
        "id2label = {v: k for k, v in label2id.items()}\n",
        "\n",
        "with open(char2idx_path, 'r', encoding='utf-8') as f:\n",
        "    char2idx = json.load(f)\n",
        "\n",
        "with open(idx2char_path, 'r', encoding='utf-8') as f:\n",
        "    idx2char = json.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56750051",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-30T07:05:34.16571Z",
          "iopub.status.busy": "2025-11-30T07:05:34.165264Z",
          "iopub.status.idle": "2025-11-30T07:05:34.16981Z",
          "shell.execute_reply": "2025-11-30T07:05:34.16908Z",
          "shell.execute_reply.started": "2025-11-30T07:05:34.165688Z"
        },
        "id": "56750051",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "MAX_SEQ_LEN = 807\n",
        "CHAR_EMBED_DIM = 256\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 10\n",
        "VOCAB_SIZE = len(char2idx)\n",
        "NUM_CLASSES = len(label2id)\n",
        "DIRTY = False\n",
        "DIACRITICS_PATTERN = re.compile(r'[\\u064B-\\u0652]')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "67563b73-7e38-4550-bd19-c201c4c0d409",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-30T07:05:34.842662Z",
          "iopub.status.busy": "2025-11-30T07:05:34.842086Z",
          "iopub.status.idle": "2025-11-30T07:05:34.847805Z",
          "shell.execute_reply": "2025-11-30T07:05:34.846809Z",
          "shell.execute_reply.started": "2025-11-30T07:05:34.842636Z"
        },
        "id": "67563b73-7e38-4550-bd19-c201c4c0d409",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def load_val_pickle(file_path):\n",
        "    with open(file_path, 'rb') as f:\n",
        "        X_raw, y_raw = pickle.load(f)\n",
        "    X = []\n",
        "    y = []\n",
        "\n",
        "    X_txt = []\n",
        "    y_label = []\n",
        "\n",
        "    for text_seq, label_seq in zip(X_raw, y_raw):\n",
        "\n",
        "        x_ids = [char2idx[c] for c in text_seq]\n",
        "        y_ids = [label2id[t] for t in label_seq]\n",
        "\n",
        "        X.append(x_ids)\n",
        "        y.append(y_ids)\n",
        "\n",
        "    return np.array(X), np.array(y)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da8f863d",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-30T07:05:35.874143Z",
          "iopub.status.busy": "2025-11-30T07:05:35.873386Z",
          "iopub.status.idle": "2025-11-30T07:05:35.878604Z",
          "shell.execute_reply": "2025-11-30T07:05:35.877913Z",
          "shell.execute_reply.started": "2025-11-30T07:05:35.874117Z"
        },
        "id": "da8f863d",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def load_data_pickle(file_path):\n",
        "    with open(file_path, 'rb') as f:\n",
        "        X_raw, y_raw = pickle.load(f)\n",
        "    X = []\n",
        "    y = []\n",
        "\n",
        "    for text_seq, label_seq in zip(X_raw, y_raw):\n",
        "        x_ids = [char2idx[c] for c in text_seq]\n",
        "        y_ids = [label2id[t] for t in label_seq]\n",
        "\n",
        "        X.append(x_ids)\n",
        "        y.append(y_ids)\n",
        "\n",
        "    return np.array(X), np.array(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ca42440-e573-4995-b92d-5f4b5dbe08b2",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-30T07:05:36.060662Z",
          "iopub.status.busy": "2025-11-30T07:05:36.060448Z",
          "iopub.status.idle": "2025-11-30T07:05:36.065363Z",
          "shell.execute_reply": "2025-11-30T07:05:36.064622Z",
          "shell.execute_reply.started": "2025-11-30T07:05:36.060645Z"
        },
        "id": "5ca42440-e573-4995-b92d-5f4b5dbe08b2",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def load_text_pickle(file_path):\n",
        "    with open(file_path, 'rb') as f:\n",
        "        X_raw, y_raw = pickle.load(f)\n",
        "    X = []\n",
        "    y = []\n",
        "\n",
        "    for text_seq, label_seq in zip(X_raw, y_raw):\n",
        "        for i in range(len(text_seq)):\n",
        "            if '(' == text_seq[i] and label_seq[i] != '':\n",
        "                print(label_seq[i])\n",
        "                return\n",
        "        X.append(text_seq)\n",
        "        y.append(label_seq)\n",
        "\n",
        "    return X, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e6eb526",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-30T07:09:55.049895Z",
          "iopub.status.busy": "2025-11-30T07:09:55.04957Z",
          "iopub.status.idle": "2025-11-30T07:10:18.105077Z",
          "shell.execute_reply": "2025-11-30T07:10:18.104198Z",
          "shell.execute_reply.started": "2025-11-30T07:09:55.049872Z"
        },
        "id": "8e6eb526",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "X, y = load_data_pickle(padded_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f142af3d-a0b8-4d43-9e82-07dab219da4d",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-30T07:10:18.106948Z",
          "iopub.status.busy": "2025-11-30T07:10:18.106556Z",
          "iopub.status.idle": "2025-11-30T07:10:27.715448Z",
          "shell.execute_reply": "2025-11-30T07:10:27.71488Z",
          "shell.execute_reply.started": "2025-11-30T07:10:18.106923Z"
        },
        "id": "f142af3d-a0b8-4d43-9e82-07dab219da4d",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "raw_X, raw_y = load_text_pickle(padded_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d0b2cdf-c30d-4b73-99a7-87fbdfc1daa2",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-30T07:10:27.71685Z",
          "iopub.status.busy": "2025-11-30T07:10:27.716627Z",
          "iopub.status.idle": "2025-11-30T07:10:28.101921Z",
          "shell.execute_reply": "2025-11-30T07:10:28.101319Z",
          "shell.execute_reply.started": "2025-11-30T07:10:27.716834Z"
        },
        "id": "4d0b2cdf-c30d-4b73-99a7-87fbdfc1daa2",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "raw_X_val, raw_y_val = load_text_pickle(val_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37e954f8-9bb9-44c0-bae8-a25b279b043c",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-30T07:10:28.103547Z",
          "iopub.status.busy": "2025-11-30T07:10:28.103345Z",
          "iopub.status.idle": "2025-11-30T07:10:29.106416Z",
          "shell.execute_reply": "2025-11-30T07:10:29.105807Z",
          "shell.execute_reply.started": "2025-11-30T07:10:28.103532Z"
        },
        "id": "37e954f8-9bb9-44c0-bae8-a25b279b043c",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "X_val, y_val = load_val_pickle(val_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2993977c-f397-4530-b4ed-58b2f42d2cc0",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-30T07:10:29.107421Z",
          "iopub.status.busy": "2025-11-30T07:10:29.107179Z",
          "iopub.status.idle": "2025-11-30T07:10:29.271671Z",
          "shell.execute_reply": "2025-11-30T07:10:29.27112Z",
          "shell.execute_reply.started": "2025-11-30T07:10:29.107396Z"
        },
        "id": "2993977c-f397-4530-b4ed-58b2f42d2cc0",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "if DIRTY:\n",
        "    X = pad_sequences(X, maxlen=500, padding='post', truncating='post')\n",
        "    y = pad_sequences(y, maxlen=500, padding='post', truncating='post')\n",
        "    MAX_SEQ_LEN = 500\n",
        "\n",
        "padding_mask = (X == 0)\n",
        "y[padding_mask] = -1\n",
        "\n",
        "padding_mask = (X_val == 0)\n",
        "y_val[padding_mask] = -1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "44fbf3e5-7b10-4652-bc19-7934e6c88594",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-30T07:10:29.272515Z",
          "iopub.status.busy": "2025-11-30T07:10:29.272345Z",
          "iopub.status.idle": "2025-11-30T07:10:29.278526Z",
          "shell.execute_reply": "2025-11-30T07:10:29.277683Z",
          "shell.execute_reply.started": "2025-11-30T07:10:29.272501Z"
        },
        "id": "44fbf3e5-7b10-4652-bc19-7934e6c88594",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "class MaskedSparseCategoricalFocalLoss(tf.keras.losses.Loss):\n",
        "    def __init__(self, gamma=2.0, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.gamma = gamma\n",
        "\n",
        "    def call(self, y_true, y_pred):\n",
        "        y_true = tf.cast(y_true, tf.float32)\n",
        "\n",
        "        mask = tf.cast(tf.not_equal(y_true, -1), tf.float32)\n",
        "\n",
        "        y_true_safe = tf.where(tf.equal(y_true, -1), tf.zeros_like(y_true), y_true)\n",
        "\n",
        "        loss = tf.keras.losses.sparse_categorical_crossentropy(\n",
        "            y_true_safe, y_pred, from_logits=False\n",
        "        )\n",
        "\n",
        "        p_t = tf.math.exp(-loss)\n",
        "        focal_loss = tf.math.pow(1.0 - p_t, self.gamma) * loss\n",
        "\n",
        "        masked_focal_loss = focal_loss * mask\n",
        "\n",
        "        return tf.reduce_sum(masked_focal_loss) / (tf.reduce_sum(mask) + 1e-7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e9023a42-a196-42d6-a504-9b910c6a9bfa",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-30T07:10:29.280766Z",
          "iopub.status.busy": "2025-11-30T07:10:29.279324Z",
          "iopub.status.idle": "2025-11-30T07:10:29.297027Z",
          "shell.execute_reply": "2025-11-30T07:10:29.296307Z",
          "shell.execute_reply.started": "2025-11-30T07:10:29.280725Z"
        },
        "id": "e9023a42-a196-42d6-a504-9b910c6a9bfa",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def masked_accuracy(y_true, y_pred):\n",
        "    mask = tf.cast(tf.not_equal(y_true, -1), tf.float32)\n",
        "\n",
        "    y_pred_classes = tf.argmax(y_pred, axis=-1)\n",
        "    y_true = tf.cast(y_true, y_pred_classes.dtype)\n",
        "\n",
        "    matches = tf.cast(tf.equal(y_true, y_pred_classes), tf.float32)\n",
        "\n",
        "    matches *= mask\n",
        "\n",
        "    return tf.reduce_sum(matches) / (tf.reduce_sum(mask) + 1e-7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ff7143a-92c5-4e0f-a754-60ab4a8fdb18",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-30T07:10:29.297841Z",
          "iopub.status.busy": "2025-11-30T07:10:29.297611Z",
          "iopub.status.idle": "2025-11-30T07:51:12.718617Z",
          "shell.execute_reply": "2025-11-30T07:51:12.718035Z",
          "shell.execute_reply.started": "2025-11-30T07:10:29.297822Z"
        },
        "id": "8ff7143a-92c5-4e0f-a754-60ab4a8fdb18",
        "outputId": "03474acf-9058-46a7-ce49-f5c9723f2218",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ char_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ char_embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">13,824</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,050,624</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">656,384</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,855</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ char_input (\u001b[38;5;33mInputLayer\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ char_embedding (\u001b[38;5;33mEmbedding\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │        \u001b[38;5;34m13,824\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional_4 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │     \u001b[38;5;34m1,050,624\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional_5 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │       \u001b[38;5;34m656,384\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ output (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)       │         \u001b[38;5;34m3,855\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,724,687</span> (6.58 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,724,687\u001b[0m (6.58 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,724,687</span> (6.58 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,724,687\u001b[0m (6.58 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m2508/2508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m492s\u001b[0m 194ms/step - loss: 0.3088 - masked_accuracy: 0.8132 - val_loss: 0.0571 - val_masked_accuracy: 0.9533\n",
            "Epoch 2/5\n",
            "\u001b[1m2508/2508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m487s\u001b[0m 194ms/step - loss: 0.0628 - masked_accuracy: 0.9491 - val_loss: 0.0416 - val_masked_accuracy: 0.9644\n",
            "Epoch 3/5\n",
            "\u001b[1m2508/2508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m487s\u001b[0m 194ms/step - loss: 0.0474 - masked_accuracy: 0.9602 - val_loss: 0.0364 - val_masked_accuracy: 0.9687\n",
            "Epoch 4/5\n",
            "\u001b[1m2508/2508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m487s\u001b[0m 194ms/step - loss: 0.0403 - masked_accuracy: 0.9652 - val_loss: 0.0328 - val_masked_accuracy: 0.9714\n",
            "Epoch 5/5\n",
            "\u001b[1m2508/2508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m487s\u001b[0m 194ms/step - loss: 0.0362 - masked_accuracy: 0.9682 - val_loss: 0.0306 - val_masked_accuracy: 0.9734\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Embedding, Input, Dense, Bidirectional, LSTM\n",
        "\n",
        "CHAR_EMBED_DIM = 256\n",
        "BATCH_SIZE = 32\n",
        "VOCAB_SIZE = len(char2idx)\n",
        "NUM_CLASSES = len(label2id)\n",
        "\n",
        "input_chars = Input(shape=(None,), dtype='int32', name='char_input')\n",
        "\n",
        "target_embedding_layer = Embedding(\n",
        "    input_dim=VOCAB_SIZE,\n",
        "    output_dim=CHAR_EMBED_DIM,\n",
        "    # mask_zero=True,\n",
        "    name='char_embedding'\n",
        ")\n",
        "x = target_embedding_layer(input_chars)\n",
        "\n",
        "x = Bidirectional(LSTM(256, return_sequences=True, name='lstm_1'))(x)\n",
        "x = tf.keras.layers.Dropout(0.3)(x)\n",
        "x = Bidirectional(LSTM(128, return_sequences=True, name='lstm_2'))(x)\n",
        "x = tf.keras.layers.Dropout(0.3)(x)\n",
        "\n",
        "output = Dense(NUM_CLASSES, activation='softmax', name='output')(x)\n",
        "\n",
        "model = tf.keras.Model(inputs=input_chars, outputs=output)\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss=MaskedSparseCategoricalFocalLoss(gamma=2.0),\n",
        "    metrics=[masked_accuracy]\n",
        ")\n",
        "\n",
        "model.summary()\n",
        "\n",
        "history = model.fit(\n",
        "    X, y,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    epochs=5,\n",
        "    validation_data=(X_val, y_val)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c3e9833-4668-44d6-afb1-753d17d07231",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-30T07:51:20.480736Z",
          "iopub.status.busy": "2025-11-30T07:51:20.480467Z",
          "iopub.status.idle": "2025-11-30T07:51:20.603332Z",
          "shell.execute_reply": "2025-11-30T07:51:20.602581Z",
          "shell.execute_reply.started": "2025-11-30T07:51:20.480715Z"
        },
        "id": "2c3e9833-4668-44d6-afb1-753d17d07231",
        "outputId": "f587d50f-14b3-4c2d-c5c9-fd7dd4e807d9",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model and mappings saved successfully.\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "import tensorflow as tf\n",
        "\n",
        "model.save('/kaggle/working/diacritization_model.keras')\n",
        "\n",
        "packaging = {\n",
        "    'char2id': char2idx,\n",
        "    'id2label': id2label\n",
        "}\n",
        "\n",
        "with open('/kaggle/working/mappings.pkl', 'wb') as f:\n",
        "    pickle.dump(packaging, f)\n",
        "\n",
        "print(\"Model and mappings saved successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e35b5334-b2a1-45a7-be84-67b56b0de17f",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-30T07:51:22.137351Z",
          "iopub.status.busy": "2025-11-30T07:51:22.136841Z",
          "iopub.status.idle": "2025-11-30T07:51:33.200654Z",
          "shell.execute_reply": "2025-11-30T07:51:33.199927Z",
          "shell.execute_reply.started": "2025-11-30T07:51:22.13733Z"
        },
        "id": "e35b5334-b2a1-45a7-be84-67b56b0de17f",
        "outputId": "792ec114-f716-4d0a-a5a2-3701fc05eaa8",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating predictions...\n",
            "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 75ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           َ       0.96      0.97      0.97    144327\n",
            "           ً       0.92      0.94      0.93      2997\n",
            "           ُ       0.93      0.90      0.92     38932\n",
            "           ٌ       0.85      0.85      0.85      2865\n",
            "           ِ       0.96      0.96      0.96     61952\n",
            "           ٍ       0.92      0.90      0.91      4372\n",
            "           ْ       0.98      0.99      0.98     60276\n",
            "           ّ       0.84      0.17      0.28       254\n",
            "          َّ       0.95      0.95      0.95     14618\n",
            "          ًّ       0.93      0.95      0.94       189\n",
            "          ُّ       0.91      0.89      0.90      2185\n",
            "          ٌّ       0.80      0.87      0.83       239\n",
            "          ِّ       0.92      0.88      0.90      3156\n",
            "          ٍّ       0.85      0.85      0.85       300\n",
            "                   1.00      1.00      1.00    198025\n",
            "\n",
            "    accuracy                           0.97    534687\n",
            "   macro avg       0.91      0.87      0.88    534687\n",
            "weighted avg       0.97      0.97      0.97    534687\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "\n",
        "print(\"Generating predictions...\")\n",
        "y_pred = model.predict(X_val, batch_size=32)\n",
        "y_pred_classes = np.argmax(y_pred, axis=-1)\n",
        "\n",
        "mask = X_val.flatten() != 0\n",
        "y_true_clean = y_val.flatten()[mask]\n",
        "y_pred_clean = y_pred_classes.flatten()[mask]\n",
        "\n",
        "target_names = [k for k, v in sorted(label2id.items(), key=lambda item: item[1])]\n",
        "\n",
        "print(classification_report(y_true_clean, y_pred_clean, target_names=target_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4985d84-2fe4-4a0b-a0ed-f8843cf8ada1",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-30T07:56:10.363363Z",
          "iopub.status.busy": "2025-11-30T07:56:10.36308Z",
          "iopub.status.idle": "2025-11-30T07:56:12.599496Z",
          "shell.execute_reply": "2025-11-30T07:56:12.598906Z",
          "shell.execute_reply.started": "2025-11-30T07:56:10.363341Z"
        },
        "id": "b4985d84-2fe4-4a0b-a0ed-f8843cf8ada1",
        "outputId": "d884304b-3059-483e-c28a-be71389d4da7",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step\n",
            "True:    الشَّهَادَةِ ظَاهِرَةً ، وَبِحَقٍّ بَيِّنٍ تَضْعُفُ التُّهْمَةُ ، وَهُوَ الْفَرْقُ بَيْنَهُ وَبَيْنَ الشَّهَادَةِ ، وَعَنْ أَصْبَغَ الْجَوَازُ فِي الْوَلَدِ وَالزَّوْجَةِ وَالْأَخِ وَالْمُكَاتَبِ وَالْمُدَبَّرِ وَالْمِدْيَانِ إنْ كَانَ مِنْ أَهْلِ الْقِيَامِ بِالْحَقِّ ، وَصَحَّ الْحُكْمُ ، وَقَدْ يَحْكُمُ لِلْخَلِيفَةِ ، وَهُوَ فَوْقَهُ ، وَتُهْمَتُهُ أَقْوَى ، وَلَا يَنْبَغِي لَهُ الْقَضَاءُ بَيْنَ أَحَدٍ مِنْ عَشِيرَتِهِ وَخَصْمِهِ ، وَإِنْ رَضِيَ الْخَصْمُ بِخِلَافِ رَجُلَيْنِ رَضِيَا بِحُكْمِ رَجُلٍ أَجْنَبِيٍّ فَيَنْفُذُ ذَلِكَ عَلَيْهِمَا ، وَلَا يَقْضِي بَيْنَهُ وَبَيْنَ غَيْرِهِ ، وَإِنْ رَضِيَ الْخَصْمُ بِذَلِكَ فَإِنْ فَعَلَ فَيُشْهِدُ عَلَى رِضَاهُ ، وَيَجْتَهِدُ فِي الْحَقِّ فَإِنْ قَضَى لِنَفْسِهِ أَوْ لِمَنْ يَمْتَنِعُ قَضَاؤُهُ لَهُ فَلْيَذْكُرْ الْقِصَّةَ كُلَّهَا ، وَرَضِيَ خَصْمِهِ ، وَشَهَادَةَ مَنْ شَهِدَ بِرِضَى الْخَصْمِ .\n",
            "Predicted:    الشَّهَادَةِ ظَاهِرَةٌ ، وَبِحَقٍّ بَيْنَ تَضَعُّفِ التُّهْمَةَ ، وَهُوَ الْفَرْقُ بَيْنَهُ وَبَيْنَ الشَّهَادَةِ ، وَعَنْ أَصْبَغَ الْجَوَازُ فِي الْوَلَدِ وَالزَّوْجَةِ وَالْأَخِ وَالْمُكَاتَبِ وَالْمُدَبَّرِ وَالْمِدْيَانِ إنْ كَانَ مِنْ أَهْلِ الْقِيَامِ بِالْحَقِّ ، وَصَحَّ الْحُكْمُ ، وَقَدْ يُحْكَمُ لِلْخَلِيفَةِ ، وَهُوَ فَوْقَهُ ، وَتُهْمَتُهُ أَقْوَى ، وَلَا يَنْبَغِي لَهُ الْقَضَاءُ بَيْنَ أَحَدٍ مِنْ عَشِيرَتِهِ وَخَصْمِهِ ، وَإِنْ رَضِيَ الْخَصْمُ بِخِلَافِ رَجُلَيْنِ رَضِيَا بِحُكْمِ رَجُلٍ أَجْنَبِيٍّ فَيَنْفُذُ ذَلِكَ عَلَيْهِمَا ، وَلَا يَقْضِي بَيْنَهُ وَبَيْنَ غَيْرِهِ ، وَإِنْ رَضِيَ الْخَصْمُ بِذَلِكَ فَإِنْ فَعَلَ فَيَشْهَدُ عَلَى رِضَاهُ ، وَيَجْتَهِدُ فِي الْحَقِّ فَإِنْ قَضَى لِنَفْسِهِ أَوْ لِمَنْ يَمْتَنِعُ قَضَاؤُهُ لَهُ فَلْيَذْكُرْ الْقِصَّةَ كُلَّهَا ، وَرَضِيَ خَصْمُهُ ، وَشَهَادَةُ مَنْ شَهِدَ بِرْضَى الْخَصْمِ .\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step\n",
            "True:    وَقَوْلُهُ ( وَلَوْ حَلَفَ لَا يَجْلِسُ عَلَى سَرِيرٍ ) ظَاهِرٌ مِمَّا تَقَدَّمَ .\n",
            "Predicted:    وَقَوْلُهُ ( وَلَوْ حَلَفَ لَا يَجْلِسُ عَلَى سَرِيرٍ ) ظَاهِرٌ مِمَّا تَقَدَّمَ .\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step\n",
            "True:    وَلَوْ لَمْ تَزِدْ\n",
            "Predicted:    وَلَوْ لَمْ تَزِدْ\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step\n",
            "True:    لِأَنَّ حَالَهُمْ كَحَالِ الْأُسَرَاءِ وَاَلَّذِينَ أَسْلَمُوا مِنْ أَهْلِ الْحَرْبِ مِنْ حَيْثُ إنَّ سَبَبَ الِاسْتِحْقَاقِ يَنْعَقِدُ لَهُمْ الْآنَ .\n",
            "Predicted:    لِأَنَّ حَالَهُمْ كَحَالَ الْأَسْرَاءِ وَاَلَّذِينَ أَسْلَمُوا مِنْ أَهْلِ الْحَرْبِ مِنْ حَيْثُ إنَّ سَبَبَ الِاسْتِحْقَاقِ يَنْعَقِدُ لَهُمْ الْآنَ .\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n",
            "True:    قَوْلُهُ تَعَالَى: تُطَهِّرُهُمْ �\n",
            "Predicted:    قَوْلُهُ تَعَالَى: تَطَهُرُهُمْ �\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step\n",
            "True:    قَوْلُهُ تَعَالَى : فَإِنْ يَكُنْ مِنْكُمْ مِائَةٌ صَابِرَةٌ\n",
            "Predicted:    قَوْلِهِ تَعَالَى : فَإِنْ يَكُنْ مِنْكُمْ مِائَةً صَابِرَةً\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step\n",
            "True:    قَالَ ابْنُ إسْحَاقَ : وَمِنْ بَنِي سَالِمِ بْنِ عَوْفِ بْنِ عَمْرِو بْنِ الْخَزْرَجِ ، ثُمّ مِنْ بَنِي الْعَجْلَانِ بْنِ زَيْدِ بْنِ غَنْمِ بْنِ سَالِمٍ نَوْفَلُ بْنُ عَبْدِ اللّهِ بْنِ نَضْلَةَ بْنِ مَالِكِ بْنِ الْعَجْلَانِ بْنِ الْعَجْلَانِ . رَجُلٌ .\n",
            "Predicted:    قَالَ ابْنُ إِسْحَاقَ : وَمِنْ بَنِي سَالِمِ بْنِ عَوْفِ بْنِ عَمْرِو بْنِ الْخَزْرَجِ ، ثُمَّ مِنْ بَنِي الْعَجْلَانِ بْنِ زَيْدِ بْنِ غَنْمِ بْنِ سَالِمٍ نَوْفَلُ بْنُ عَبْدِ اللَّهِ بْنِ نَضْلَةَ بْنِ مَالِكِ بْنِ الْعَجْلَانِ بْنِ الْعَجْلَانِ . رَجُلٌ .\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n",
            "True:    بَدَلٌ مِنْ\n",
            "Predicted:    بَدَلٌ مِنْ\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step\n",
            "True:    قَوْلِهِ : فِي فَرِيضَتَيْنِ بَدَلُ مُفَصَّلٍ مِنْ مُجْمَلٍ أَيْ بَدَلٌ مِنْ مَجْمُوعِ الْجَارِّ وَالْمَجْرُورِ ، وَلَا يَخْفَى أَنَّ الْمَسْأَلَةَ زَوْجَةٌ وَأَبَوَانِ لَا فِي زَوْجَةٍ وَأَبَوَيْنِ كَمَا هُوَ ظَاهِرُ الْعِبَارَةِ ، فَتُؤَوَّلُ بِأَنَّ الْمَعْنَى أُولَاهُمَا مَجْرُورٌ فِي زَوْجَةٍ وَأَبَوَيْنِ أَيْ الْمَجْرُورُ فِي ذَلِكَ وَهُوَ زَوْجَةٌ وَأَبَوَيْنِ .\n",
            "Predicted:    قَوْلُهُ : فِي فَرِيضَتَيْنِ بَدَلٌ مُفَصَّلٌ مِنْ مَجْمَلٍ أَيْ بَدَلٍ مِنْ مَجْمُوعِ الْجَارِّ وَالْمَجْرُورِ ، وَلَا يَخْفَى أَنَّ الْمَسْأَلَةَ زَوْجَةٌ وَأَبَوَانِ لَا فِي زَوْجَةٍ وَأَبَوَيْنِ كَمَا هُوَ ظَاهِرُ الْعِبَارَةِ ، فَتُؤُوَّلُ بِأَنَّ الْمَعْنَى أَوْلَاهُمَا مَجْرُورٌ فِي زَوْجَةٍ وَأَبَوَيْنِ أَيْ الْمَجْرُورِ فِي ذَلِكَ وَهُوَ زَوْجَةٌ وَأَبَوَيْنِ .\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n",
            "True:    قَوْلُهُ : [ وَإِنْ أَتَتْ الْمُطَلَّقَةُ ] : لَا مَفْهُومَ لِلْمُطَلَّقَةِ بَلْ الْمَدَارُ عَلَى كَوْنِهَا مُعْتَدَّةً مِنْ طَلَاقٍ أَوْ وَفَاةٍ .\n",
            "Predicted:    قَوْلُهُ : [ وَإِنْ أَتَتْ الْمُطَلَّقَةُ ] : لَا مَفْهُومَ لِلْمُطَلَّقَةِ بَلْ الْمَدَارُ عَلَى كَوْنِهَا مُعْتَدَّةً مِنْ طَلَاقٍ أَوْ وَفَاةٍ .\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "for test_index in range(len(raw_X_val[:10])):\n",
        "\n",
        "    raw_text = raw_X_val[test_index]\n",
        "    input_seq = X_val[test_index]\n",
        "\n",
        "    input_ready = np.expand_dims(input_seq, axis=0)\n",
        "    y_pred = model.predict(input_ready)\n",
        "    y_pred_classes = np.argmax(y_pred, axis=-1)[0]\n",
        "\n",
        "    pred_result = ''\n",
        "    act_result = ''\n",
        "\n",
        "    for j in range(len(raw_text)):\n",
        "        char = raw_text[j]\n",
        "        if char == '<PAD>':\n",
        "            break\n",
        "        pred_id = y_pred_classes[j]\n",
        "\n",
        "        predicted_diacritic = id2label[pred_id]\n",
        "\n",
        "        pred_result += char + predicted_diacritic\n",
        "        act_result += char + raw_y_val[test_index][j]\n",
        "\n",
        "    print(\"True:   \", act_result)\n",
        "    print(\"Predicted:   \", pred_result)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "name": "character-embeddings",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "datasetId": 8842886,
          "sourceId": 13879577,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 8842900,
          "sourceId": 13879601,
          "sourceType": "datasetVersion"
        },
        {
          "isSourceIdPinned": true,
          "modelId": 515654,
          "modelInstanceId": 500445,
          "sourceId": 661533,
          "sourceType": "modelInstanceVersion"
        },
        {
          "isSourceIdPinned": true,
          "modelId": 516265,
          "modelInstanceId": 501072,
          "sourceId": 662311,
          "sourceType": "modelInstanceVersion"
        }
      ],
      "dockerImageVersionId": 31193,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
