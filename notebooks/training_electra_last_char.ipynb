{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "name": "training-electra-last-char"
    },
    "accelerator": "GPU",
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 13908408,
          "sourceType": "datasetVersion",
          "datasetId": 8861767
        },
        {
          "sourceId": 13989718,
          "sourceType": "datasetVersion",
          "datasetId": 8916698
        },
        {
          "sourceId": 14064986,
          "sourceType": "datasetVersion",
          "datasetId": 8952497
        },
        {
          "sourceId": 14065020,
          "sourceType": "datasetVersion",
          "datasetId": 8952520
        },
        {
          "sourceId": 14065067,
          "sourceType": "datasetVersion",
          "datasetId": 8952542
        },
        {
          "sourceId": 14065098,
          "sourceType": "datasetVersion",
          "datasetId": 8952560
        },
        {
          "sourceId": 14065131,
          "sourceType": "datasetVersion",
          "datasetId": 8952588
        },
        {
          "sourceId": 14065134,
          "sourceType": "datasetVersion",
          "datasetId": 8952590
        },
        {
          "sourceId": 14065248,
          "sourceType": "datasetVersion",
          "datasetId": 8952670
        },
        {
          "sourceId": 673146,
          "sourceType": "modelInstanceVersion",
          "isSourceIdPinned": true,
          "modelInstanceId": 510098,
          "modelId": 524762
        }
      ],
      "dockerImageVersionId": 31193,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "id": "lIA95EyTmrHd",
      "cell_type": "code",
      "source": [
        "!pip install -q \"protobuf==3.20.*\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lIA95EyTmrHd",
        "outputId": "176af2bb-24bc-4814-98d7-4df235b8ca74",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-09T09:10:15.77212Z",
          "iopub.execute_input": "2025-12-09T09:10:15.77239Z",
          "iopub.status.idle": "2025-12-09T09:10:20.73943Z",
          "shell.execute_reply.started": "2025-12-09T09:10:15.772368Z",
          "shell.execute_reply": "2025-12-09T09:10:20.738545Z"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.1/162.1 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\nopentelemetry-proto 1.37.0 requires protobuf<7.0,>=5.0, but you have protobuf 3.20.3 which is incompatible.\nonnx 1.18.0 requires protobuf>=4.25.1, but you have protobuf 3.20.3 which is incompatible.\na2a-sdk 0.3.10 requires protobuf>=5.29.5, but you have protobuf 3.20.3 which is incompatible.\nray 2.51.1 requires click!=8.3.0,>=7.0, but you have click 8.3.0 which is incompatible.\nbigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\ntensorflow-metadata 1.17.2 requires protobuf>=4.25.2; python_version >= \"3.11\", but you have protobuf 3.20.3 which is incompatible.\npydrive2 1.21.3 requires cryptography<44, but you have cryptography 46.0.3 which is incompatible.\npydrive2 1.21.3 requires pyOpenSSL<=24.2.1,>=19.1.0, but you have pyopenssl 25.3.0 which is incompatible.\nydf 0.13.0 requires protobuf<7.0.0,>=5.29.1, but you have protobuf 3.20.3 which is incompatible.\ngrpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 3.20.3 which is incompatible.\ngcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2025.10.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "id": "1be8abeb-b020-4b07-a672-1bbf5e4fc006",
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, TimeDistributed, Bidirectional, Input\n",
        "import json\n",
        "import os\n",
        "import pickle\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import re"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-09T09:10:33.791369Z",
          "iopub.execute_input": "2025-12-09T09:10:33.792099Z",
          "iopub.status.idle": "2025-12-09T09:10:49.42208Z",
          "shell.execute_reply.started": "2025-12-09T09:10:33.792063Z",
          "shell.execute_reply": "2025-12-09T09:10:49.421241Z"
        },
        "id": "1be8abeb-b020-4b07-a672-1bbf5e4fc006",
        "outputId": "fd4e2953-0a1d-4972-96b4-672f2971b53b"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "2025-12-09 09:10:35.228801: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1765271435.426581      47 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1765271435.476922      47 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "id": "2f819122-f1ce-4a03-b147-c5b5274813d1",
      "cell_type": "code",
      "source": [
        "diacritic2id_path = \"/kaggle/input/arabicia-2/diacritic2id.json\"\n",
        "idx2char_path = \"/kaggle/input/arabicia-3/idx2char.json\"\n",
        "char2idx_path = \"/kaggle/input/arabicia-3/char2idx.json\"\n",
        "\n",
        "y_train_path = \"/kaggle/input/arabicia-3/cleaned_tashkeel.txt\"\n",
        "y_val_path = \"/kaggle/input/arabicia-3/cleaned_tashkeel_val.txt\"\n",
        "\n",
        "padded_train = \"/kaggle/input/arabicia-3/padded_2.pkl\"\n",
        "padded_val = \"/kaggle/input/arabicia-3/padded_val.pkl\"\n",
        "\n",
        "char_embeddings_path = \"/kaggle/input/arabic-chars/keras/default/1/embedding_matrix(1).npy\""
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-09T09:10:49.423349Z",
          "iopub.execute_input": "2025-12-09T09:10:49.424246Z",
          "iopub.status.idle": "2025-12-09T09:10:49.428096Z",
          "shell.execute_reply.started": "2025-12-09T09:10:49.424224Z",
          "shell.execute_reply": "2025-12-09T09:10:49.427459Z"
        },
        "id": "2f819122-f1ce-4a03-b147-c5b5274813d1"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "4a519aca",
      "cell_type": "code",
      "source": [
        "with open(diacritic2id_path, 'r', encoding='utf-8') as f:\n",
        "    diacritic2id = json.load(f)\n",
        "\n",
        "id2label = {v: k for k, v in diacritic2id.items()}\n",
        "\n",
        "with open(char2idx_path, 'r', encoding='utf-8') as f:\n",
        "    char2idx = json.load(f)\n",
        "\n",
        "with open(idx2char_path, 'r', encoding='utf-8') as f:\n",
        "    idx2char = json.load(f)\n",
        "\n",
        "# idx2char['1'] = '?'\n",
        "# value = char2idx.pop('\\uFFFD')\n",
        "# char2idx['?'] = value\n",
        "for key, value in char2idx.items():\n",
        "    if value != 0:\n",
        "        char2idx[key] = value - 1"
      ],
      "metadata": {
        "id": "4a519aca",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-09T09:10:49.42867Z",
          "iopub.execute_input": "2025-12-09T09:10:49.428915Z",
          "iopub.status.idle": "2025-12-09T09:10:49.463438Z",
          "shell.execute_reply.started": "2025-12-09T09:10:49.428898Z",
          "shell.execute_reply": "2025-12-09T09:10:49.462915Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "5b5669c8-f0bd-4be0-8d55-b4092404caac",
      "cell_type": "code",
      "source": [
        "def recover(sentence, tashkeel):\n",
        "    result = \"\"\n",
        "    i = 0\n",
        "    while i < len(sentence):\n",
        "        result += sentence[i] + tashkeel[i]\n",
        "        i += 1\n",
        "\n",
        "    return result"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-09T09:10:49.465096Z",
          "iopub.execute_input": "2025-12-09T09:10:49.46532Z",
          "iopub.status.idle": "2025-12-09T09:10:49.46912Z",
          "shell.execute_reply.started": "2025-12-09T09:10:49.465303Z",
          "shell.execute_reply": "2025-12-09T09:10:49.468507Z"
        },
        "id": "5b5669c8-f0bd-4be0-8d55-b4092404caac"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "092bb84d-5fef-4755-8620-656afb5f36fe",
      "cell_type": "code",
      "source": [
        "def load_data_pickle(file_path):\n",
        "    with open(file_path, 'rb') as f:\n",
        "        X_raw, y_raw = pickle.load(f)\n",
        "    X = []\n",
        "    y = []\n",
        "\n",
        "    for text_seq, label_seq in zip(X_raw, y_raw):\n",
        "        x_ids = [c for c in text_seq]\n",
        "        y_ids = [t for t in label_seq]\n",
        "\n",
        "        X.append(x_ids)\n",
        "        y.append(y_ids)\n",
        "\n",
        "    return X, y"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-09T09:10:49.469642Z",
          "iopub.execute_input": "2025-12-09T09:10:49.469895Z",
          "iopub.status.idle": "2025-12-09T09:10:49.479282Z",
          "shell.execute_reply.started": "2025-12-09T09:10:49.469872Z",
          "shell.execute_reply": "2025-12-09T09:10:49.478716Z"
        },
        "id": "092bb84d-5fef-4755-8620-656afb5f36fe"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "5e0c99c1-2de3-4b7d-8120-a771122f1d52",
      "cell_type": "code",
      "source": [
        "sentences, tashkeel_sequences = load_data_pickle(padded_train)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-09T09:10:49.49111Z",
          "iopub.execute_input": "2025-12-09T09:10:49.491306Z",
          "iopub.status.idle": "2025-12-09T09:10:54.121089Z",
          "shell.execute_reply.started": "2025-12-09T09:10:49.49129Z",
          "shell.execute_reply": "2025-12-09T09:10:54.120408Z"
        },
        "id": "5e0c99c1-2de3-4b7d-8120-a771122f1d52"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "54480d8a-ef95-4d30-a826-8fcebeed5c16",
      "cell_type": "code",
      "source": [
        "new_sentences = sentences\n",
        "new_tashkeel = tashkeel_sequences\n",
        "# for i in range(len(sentences)):\n",
        "#     text, tashkeel = remove_pads(sentences[i], tashkeel_sequences[i])\n",
        "#     new_sentences.append(text)\n",
        "#     new_tashkeel.append(tashkeel)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-09T09:10:54.121857Z",
          "iopub.execute_input": "2025-12-09T09:10:54.122084Z",
          "iopub.status.idle": "2025-12-09T09:10:54.125767Z",
          "shell.execute_reply.started": "2025-12-09T09:10:54.122062Z",
          "shell.execute_reply": "2025-12-09T09:10:54.125004Z"
        },
        "id": "54480d8a-ef95-4d30-a826-8fcebeed5c16"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "65fb4fbf-9015-48b9-bb3f-be736ef177c9",
      "cell_type": "code",
      "source": [
        "sentence_lengths = [len(sentence) for sentence in new_sentences]"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-09T09:10:54.126593Z",
          "iopub.execute_input": "2025-12-09T09:10:54.127032Z",
          "iopub.status.idle": "2025-12-09T09:10:54.22594Z",
          "shell.execute_reply.started": "2025-12-09T09:10:54.127014Z",
          "shell.execute_reply": "2025-12-09T09:10:54.225165Z"
        },
        "id": "65fb4fbf-9015-48b9-bb3f-be736ef177c9"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "5aff964d-f7e0-469b-acfc-4f4cc76ea23f",
      "cell_type": "code",
      "source": [
        "files_config = []\n",
        "for i in range(0, 64001, 16000):\n",
        "    files_config.append((f'/kaggle/input/arabic-diacrirization-features-electra-{i + 16000}/zizo_part_{i + 16000}.h5', sentence_lengths[i:i + 16000]))\n",
        "files_config.append((f'/kaggle/input/arabic-diacrirization-features-electra-80392/zizo_part_80392.h5', sentence_lengths[80000:80392]))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-09T09:10:54.227716Z",
          "iopub.execute_input": "2025-12-09T09:10:54.227958Z",
          "iopub.status.idle": "2025-12-09T09:10:54.238142Z",
          "shell.execute_reply.started": "2025-12-09T09:10:54.22794Z",
          "shell.execute_reply": "2025-12-09T09:10:54.237395Z"
        },
        "id": "5aff964d-f7e0-469b-acfc-4f4cc76ea23f"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "56750051",
      "cell_type": "code",
      "source": [
        "MAX_SEQ_LEN = 807\n",
        "CHAR_EMBED_DIM = 256\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 10\n",
        "VOCAB_SIZE = len(char2idx)\n",
        "NUM_CLASSES = len(diacritic2id)\n",
        "DIRTY = False\n",
        "DIACRITICS_PATTERN = re.compile(r'[\\u064B-\\u0652]')\n",
        "INPUT_DIM = 1024 # bert + mine\n",
        "HIDDEN_DIM = 512\n",
        "total_sentences = sum([len(lengths) for _, lengths in files_config])\n",
        "STEPS_PER_EPOCH = total_sentences // BATCH_SIZE\n",
        "PADDING_INPUT = -99999.0"
      ],
      "metadata": {
        "id": "56750051",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-09T09:10:57.79817Z",
          "iopub.execute_input": "2025-12-09T09:10:57.798873Z",
          "iopub.status.idle": "2025-12-09T09:10:57.803464Z",
          "shell.execute_reply.started": "2025-12-09T09:10:57.798848Z",
          "shell.execute_reply": "2025-12-09T09:10:57.802809Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "6417930e-ab40-422d-8b34-032ea47451b7",
      "cell_type": "code",
      "source": [
        "custom_char_embedding = np.load('/kaggle/input/arabic-chars/keras/default/1/embedding_matrix(1).npy')\n",
        "\n",
        "def extract_custom_char_embeddings(char):\n",
        "    return custom_char_embedding[char2idx[char]]"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-09T09:11:00.109779Z",
          "iopub.execute_input": "2025-12-09T09:11:00.110482Z",
          "iopub.status.idle": "2025-12-09T09:11:00.118039Z",
          "shell.execute_reply.started": "2025-12-09T09:11:00.110456Z",
          "shell.execute_reply": "2025-12-09T09:11:00.117448Z"
        },
        "id": "6417930e-ab40-422d-8b34-032ea47451b7"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "65fbba63-fdc3-4200-a952-e3bf77dee72f",
      "cell_type": "code",
      "source": [
        "punctuation = ['.', ':', '{', '}', '[', ']', '(', ')', '؛', '«', '»', '!', '،', '؟', '-', ' ']\n",
        "punc_matrix = []\n",
        "for punc in punctuation:\n",
        "    punc_matrix.append(extract_custom_char_embeddings(punc))\n",
        "punc_matrix = np.array(punc_matrix)\n",
        "\n",
        "def is_vector_punctuation(vec, threshold=1e-5):\n",
        "    diff = np.linalg.norm(punc_matrix - vec, axis=1)\n",
        "    return np.any(diff < threshold)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-09T09:54:02.885728Z",
          "iopub.execute_input": "2025-12-09T09:54:02.886225Z",
          "iopub.status.idle": "2025-12-09T09:54:02.891585Z",
          "shell.execute_reply.started": "2025-12-09T09:54:02.886189Z",
          "shell.execute_reply": "2025-12-09T09:54:02.890878Z"
        },
        "id": "65fbba63-fdc3-4200-a952-e3bf77dee72f"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "f4d4a670-0330-4368-96ad-3c36faab3012",
      "cell_type": "code",
      "source": [
        "class SparseCategoricalFocalLoss(tf.keras.losses.Loss):\n",
        "    def __init__(self, gamma=2.0, ignore_id=15, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.gamma = gamma\n",
        "        self.ignore_id = ignore_id\n",
        "\n",
        "    def call(self, y_true, y_pred):\n",
        "        y_true = tf.squeeze(y_true, axis=-1)\n",
        "        y_true = tf.cast(y_true, tf.int32)\n",
        "\n",
        "        mask = tf.cast(tf.not_equal(y_true, self.ignore_id), tf.float32)\n",
        "\n",
        "        y_true_safe = tf.where(y_true == self.ignore_id, 0, y_true)\n",
        "\n",
        "        loss = tf.keras.losses.sparse_categorical_crossentropy(y_true_safe, y_pred, from_logits=False)\n",
        "\n",
        "        p_t = tf.math.exp(-loss)\n",
        "        focal_loss = tf.math.pow(1.0 - p_t, self.gamma) * loss\n",
        "\n",
        "        masked_loss = focal_loss * mask\n",
        "\n",
        "        return tf.reduce_sum(masked_loss) / (tf.reduce_sum(mask) + 1e-6)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-09T11:46:29.417252Z",
          "iopub.execute_input": "2025-12-09T11:46:29.417801Z",
          "iopub.status.idle": "2025-12-09T11:46:29.423653Z",
          "shell.execute_reply.started": "2025-12-09T11:46:29.417774Z",
          "shell.execute_reply": "2025-12-09T11:46:29.423024Z"
        },
        "id": "f4d4a670-0330-4368-96ad-3c36faab3012"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "89523874-72ec-42cc-b038-6693b2270e1a",
      "cell_type": "code",
      "source": [
        "import h5py\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "def multi_file_generator():\n",
        "    for h5_path, lengths in files_config:\n",
        "        with h5py.File(h5_path, 'r') as f:\n",
        "            features_dset = f['features']\n",
        "            labels_dset = f['tashkeel']\n",
        "\n",
        "            current_idx = 0\n",
        "\n",
        "            for seq_len in lengths:\n",
        "                end_idx = current_idx + seq_len\n",
        "\n",
        "                feat = features_dset[current_idx : end_idx]\n",
        "\n",
        "                lbl = np.full((seq_len,), 15, dtype=np.int32)\n",
        "\n",
        "                if feat.shape[0] > 0:\n",
        "                    local_idx = 0\n",
        "\n",
        "                    for feat_item in feat:\n",
        "                        is_separator = np.all(feat_item[:768] == 0)\n",
        "\n",
        "                        if is_separator:\n",
        "                            lbl[local_idx] = 15\n",
        "                            if local_idx > 0:\n",
        "                                prev_emb = features_dset[current_idx + local_idx - 1]\n",
        "\n",
        "                                if not is_vector_punctuation(prev_emb[768:1024]):\n",
        "                                    lbl[local_idx - 1] = labels_dset[current_idx + local_idx - 1]\n",
        "\n",
        "                        local_idx += 1\n",
        "\n",
        "                    if not np.all(feat[-1][:768] == 0):\n",
        "                        prev_emb = features_dset[end_idx - 1]\n",
        "\n",
        "                        if not is_vector_punctuation(prev_emb[768:1024]):\n",
        "                            lbl[-1] = labels_dset[end_idx - 1]\n",
        "\n",
        "                    lbl = lbl.reshape(-1, 1)\n",
        "                    yield feat, lbl\n",
        "\n",
        "                current_idx = end_idx\n",
        "\n",
        "dataset = tf.data.Dataset.from_generator(\n",
        "    multi_file_generator,\n",
        "    output_signature=(\n",
        "        tf.TensorSpec(shape=(None, INPUT_DIM), dtype=tf.float32),\n",
        "        tf.TensorSpec(shape=(None, 1), dtype=tf.int32)\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-09T11:46:29.723296Z",
          "iopub.execute_input": "2025-12-09T11:46:29.723956Z",
          "iopub.status.idle": "2025-12-09T11:46:29.760594Z",
          "shell.execute_reply.started": "2025-12-09T11:46:29.723935Z",
          "shell.execute_reply": "2025-12-09T11:46:29.759799Z"
        },
        "id": "89523874-72ec-42cc-b038-6693b2270e1a"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "09ddfe8e-7866-4b37-8d82-902b967e06b1",
      "cell_type": "code",
      "source": [
        "dataset = dataset.padded_batch(\n",
        "    BATCH_SIZE,\n",
        "    padding_values=(PADDING_INPUT, 15)\n",
        ")\n",
        "dataset = dataset.repeat()\n",
        "\n",
        "dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "def build_model():\n",
        "    inputs = tf.keras.Input(shape=(None, INPUT_DIM))\n",
        "    masked = tf.keras.layers.Masking(mask_value=PADDING_INPUT)(inputs)\n",
        "\n",
        "    x = tf.keras.layers.Dense(HIDDEN_DIM * 2)(masked)\n",
        "    x = tf.keras.layers.Activation('relu')(x)\n",
        "    x = tf.keras.layers.Dropout(0.2)(x)\n",
        "    residual = x\n",
        "\n",
        "    x = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(HIDDEN_DIM, return_sequences=True))(x)\n",
        "    x = tf.keras.layers.Dropout(0.3)(x)\n",
        "    x = tf.keras.layers.Add()([x, residual])\n",
        "    residual = x\n",
        "\n",
        "    x = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(HIDDEN_DIM, return_sequences=True))(x)\n",
        "    x = tf.keras.layers.Dropout(0.3)(x)\n",
        "    x = tf.keras.layers.Add()([x, residual])\n",
        "    residual = x\n",
        "\n",
        "    x = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(HIDDEN_DIM, return_sequences=True))(x)\n",
        "    x = tf.keras.layers.Dropout(0.3)(x)\n",
        "    x = tf.keras.layers.Add()([x, residual])\n",
        "\n",
        "    x = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(HIDDEN_DIM, return_sequences=True))(x)\n",
        "\n",
        "    x = tf.keras.layers.Dense(HIDDEN_DIM, activation='relu')(x)\n",
        "    x = tf.keras.layers.Dropout(0.3)(x)\n",
        "\n",
        "    outputs = tf.keras.layers.Dense(NUM_CLASSES, activation='softmax')(x)\n",
        "\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "    return model"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-09T11:46:31.628454Z",
          "iopub.execute_input": "2025-12-09T11:46:31.62913Z",
          "iopub.status.idle": "2025-12-09T11:46:31.643498Z",
          "shell.execute_reply.started": "2025-12-09T11:46:31.629103Z",
          "shell.execute_reply": "2025-12-09T11:46:31.642696Z"
        },
        "id": "09ddfe8e-7866-4b37-8d82-902b967e06b1"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "93cf727b-5347-45ac-8609-37489c84452d",
      "cell_type": "code",
      "source": [
        "def masked_accuracy(y_true, y_pred):\n",
        "    y_true = tf.squeeze(y_true, axis=-1)\n",
        "    y_true = tf.cast(y_true, tf.int32)\n",
        "\n",
        "    mask = tf.cast(tf.not_equal(y_true, 15), tf.float32)\n",
        "\n",
        "    y_pred_class = tf.cast(tf.argmax(y_pred, axis=-1), tf.int32)\n",
        "\n",
        "    correct = tf.cast(tf.equal(y_true, y_pred_class), tf.float32)\n",
        "\n",
        "    masked_correct = correct * mask\n",
        "\n",
        "    return tf.reduce_sum(masked_correct) / (tf.reduce_sum(mask) + 1e-6)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-09T11:46:31.820508Z",
          "iopub.execute_input": "2025-12-09T11:46:31.821204Z",
          "iopub.status.idle": "2025-12-09T11:46:31.825816Z",
          "shell.execute_reply.started": "2025-12-09T11:46:31.821181Z",
          "shell.execute_reply": "2025-12-09T11:46:31.825103Z"
        },
        "id": "93cf727b-5347-45ac-8609-37489c84452d"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "693f8d56-4d14-4a77-a39b-2bf97b2a8ed1",
      "cell_type": "code",
      "source": [
        "import h5py\n",
        "import numpy as np\n",
        "\n",
        "def another_smart_slicer_generator(lengths, offset=0):\n",
        "    with h5py.File('/kaggle/input/arabic-diacritics-features-electra-val-4152/zizo_part_4152.h5', 'r') as f:\n",
        "        features_dset = f['features']\n",
        "        labels_dset = f['tashkeel']\n",
        "\n",
        "        current_idx = offset\n",
        "\n",
        "        for seq_len in lengths:\n",
        "            end_idx = current_idx + seq_len\n",
        "\n",
        "            feat = features_dset[current_idx : end_idx]\n",
        "            raw_lbl = labels_dset[current_idx : end_idx]\n",
        "\n",
        "            lbl = np.full((seq_len,), 15, dtype=np.int32)\n",
        "\n",
        "            if feat.shape[0] > 0:\n",
        "                local_idx = 0\n",
        "                for feat_item in feat:\n",
        "                    # Check if separator\n",
        "                    if np.all(feat_item[:768] == 0):\n",
        "                        lbl[local_idx] = 15\n",
        "                        if local_idx > 0:\n",
        "                            prev_emb = features_dset[current_idx + local_idx - 1]\n",
        "\n",
        "                            if not is_vector_punctuation(prev_emb[768:1024]):\n",
        "                                lbl[local_idx - 1] = labels_dset[current_idx + local_idx - 1]\n",
        "                    local_idx += 1\n",
        "\n",
        "                if not np.all(feat[-1][:768] == 0):\n",
        "                    prev_emb = features_dset[end_idx - 1]\n",
        "                    if not is_vector_punctuation(prev_emb[768:1024]):\n",
        "                        lbl[-1] = labels_dset[end_idx - 1]\n",
        "\n",
        "            lbl = lbl.reshape(-1, 1)\n",
        "            yield feat, lbl\n",
        "\n",
        "            current_idx = end_idx"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-09T11:46:32.01581Z",
          "iopub.execute_input": "2025-12-09T11:46:32.016399Z",
          "iopub.status.idle": "2025-12-09T11:46:32.023012Z",
          "shell.execute_reply.started": "2025-12-09T11:46:32.016373Z",
          "shell.execute_reply": "2025-12-09T11:46:32.02221Z"
        },
        "id": "693f8d56-4d14-4a77-a39b-2bf97b2a8ed1"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "9e7f167e-d0f0-4972-a2d5-6860393326df",
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "sentences, tashkeel_sequences = load_data_pickle(padded_val)\n",
        "\n",
        "new_sentences = sentences\n",
        "new_tashkeel = tashkeel_sequences\n",
        "\n",
        "# for i in range(len(sentences)):\n",
        "#     text, tashkeel = remove_pads(sentences[i], tashkeel_sequences[i])\n",
        "#     new_sentences.append(text)\n",
        "#     new_tashkeel.append(tashkeel)\n",
        "\n",
        "val_lengths = [len(s) for s in new_sentences]"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-09T11:46:33.427158Z",
          "iopub.execute_input": "2025-12-09T11:46:33.42816Z",
          "iopub.status.idle": "2025-12-09T11:46:33.594623Z",
          "shell.execute_reply.started": "2025-12-09T11:46:33.428111Z",
          "shell.execute_reply": "2025-12-09T11:46:33.593957Z"
        },
        "id": "9e7f167e-d0f0-4972-a2d5-6860393326df"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "df5dc600-f896-487c-aa82-32787d0160ee",
      "cell_type": "code",
      "source": [
        "import math\n",
        "val_dataset = tf.data.Dataset.from_generator(\n",
        "    lambda: another_smart_slicer_generator(val_lengths, offset=0),\n",
        "    output_signature=(\n",
        "        tf.TensorSpec(shape=(None, INPUT_DIM), dtype=tf.float32),\n",
        "        tf.TensorSpec(shape=(None, 1), dtype=tf.int32)\n",
        "    )\n",
        ")\n",
        "\n",
        "val_dataset = val_dataset.padded_batch(\n",
        "    BATCH_SIZE,\n",
        "    padding_values=(PADDING_INPUT, 15)\n",
        ")\n",
        "val_dataset = val_dataset.repeat()\n",
        "\n",
        "\n",
        "val_dataset = val_dataset.prefetch(tf.data.AUTOTUNE)\n",
        "val_steps = math.ceil(len(val_lengths) / BATCH_SIZE)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-09T11:46:33.634753Z",
          "iopub.execute_input": "2025-12-09T11:46:33.635281Z",
          "iopub.status.idle": "2025-12-09T11:46:33.673992Z",
          "shell.execute_reply.started": "2025-12-09T11:46:33.635257Z",
          "shell.execute_reply": "2025-12-09T11:46:33.673234Z"
        },
        "id": "df5dc600-f896-487c-aa82-32787d0160ee"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "fba07dfd-4c23-4d62-8134-284ae35050f9",
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.load_model(\n",
        "    '/kaggle/working/last_char_electra_test.keras',\n",
        "    custom_objects={\n",
        "        'SparseCategoricalFocalLoss': SparseCategoricalFocalLoss,\n",
        "        'masked_accuracy': masked_accuracy\n",
        "    }\n",
        ")\n",
        "\n",
        "lr_callback = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.5,\n",
        "    patience=1,\n",
        "    min_lr=1e-6,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "    dataset,\n",
        "    steps_per_epoch=STEPS_PER_EPOCH,\n",
        "    epochs=15,\n",
        "    initial_epoch=4,\n",
        "    validation_data=val_dataset,\n",
        "    validation_steps=val_steps,\n",
        "    callbacks=[lr_callback],\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-09T11:46:35.993037Z",
          "iopub.execute_input": "2025-12-09T11:46:35.99332Z"
        },
        "id": "fba07dfd-4c23-4d62-8134-284ae35050f9",
        "outputId": "90d55cd8-7f2c-4e58-b1be-64eeca1530ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Epoch 5/15\n\u001b[1m2512/2512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1611s\u001b[0m 638ms/step - loss: 0.0352 - masked_accuracy: 0.9697 - val_loss: 0.0421 - val_masked_accuracy: 0.9685 - learning_rate: 0.0010\nEpoch 6/15\n\u001b[1m2182/2512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m3:25\u001b[0m 623ms/step - loss: 0.0323 - masked_accuracy: 0.9712",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "id": "74979fba-033a-456a-a7f0-3c52f2b4fbcc",
      "cell_type": "code",
      "source": [
        "# model = build_model()\n",
        "\n",
        "# lr_callback = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "#     monitor='val_loss',\n",
        "#     factor=0.5,\n",
        "#     patience=1,\n",
        "#     min_lr=1e-6,\n",
        "#     verbose=1\n",
        "# )\n",
        "\n",
        "# model.compile(\n",
        "#     optimizer='adam',\n",
        "#     loss=SparseCategoricalFocalLoss(gamma=2.0),\n",
        "#     metrics=[masked_accuracy]\n",
        "# )\n",
        "\n",
        "# model.fit(\n",
        "#     dataset,\n",
        "#     steps_per_epoch=STEPS_PER_EPOCH,\n",
        "#     epochs=15,\n",
        "#     validation_data=val_dataset,\n",
        "#     validation_steps=val_steps,\n",
        "#     callbacks=[lr_callback],\n",
        "#     verbose=1\n",
        "# )"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-09T09:54:20.076183Z",
          "iopub.execute_input": "2025-12-09T09:54:20.076917Z",
          "iopub.status.idle": "2025-12-09T11:41:31.638413Z",
          "shell.execute_reply.started": "2025-12-09T09:54:20.076891Z",
          "shell.execute_reply": "2025-12-09T11:41:31.637314Z"
        },
        "id": "74979fba-033a-456a-a7f0-3c52f2b4fbcc",
        "outputId": "2becfff8-1439-430e-899a-e36e595143a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Epoch 1/15\n\u001b[1m2512/2512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1615s\u001b[0m 639ms/step - loss: 0.3353 - masked_accuracy: 0.8162 - val_loss: 0.0585 - val_masked_accuracy: 0.9540 - learning_rate: 0.0010\nEpoch 2/15\n\u001b[1m2512/2512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1604s\u001b[0m 639ms/step - loss: 0.0606 - masked_accuracy: 0.9538 - val_loss: 0.0479 - val_masked_accuracy: 0.9628 - learning_rate: 0.0010\nEpoch 3/15\n\u001b[1m2512/2512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1604s\u001b[0m 639ms/step - loss: 0.0466 - masked_accuracy: 0.9629 - val_loss: 0.0452 - val_masked_accuracy: 0.9655 - learning_rate: 0.0010\nEpoch 4/15\n\u001b[1m2512/2512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1605s\u001b[0m 639ms/step - loss: 0.0396 - masked_accuracy: 0.9672 - val_loss: 0.0432 - val_masked_accuracy: 0.9676 - learning_rate: 0.0010\nEpoch 5/15\n\u001b[1m   2/2512\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m28:21\u001b[0m 678ms/step - loss: 0.0395 - masked_accuracy: 0.9735",
          "output_type": "stream"
        },
        {
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_47/3822838289.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m )\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m model.fit(\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSTEPS_PER_EPOCH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    369\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfunction\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    217\u001b[0m                 \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDistributedIterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             ):\n\u001b[0;32m--> 219\u001b[0;31m                 \u001b[0mopt_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmulti_step_on_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mopt_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    876\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m       results = tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    879\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1321\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1681\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1682\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1683\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1684\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1685\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ],
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error"
        }
      ],
      "execution_count": null
    },
    {
      "id": "a84d4c61-7cb6-41d5-9b24-b7e43fc32d4f",
      "cell_type": "markdown",
      "source": [
        "# Testing"
      ],
      "metadata": {
        "id": "a84d4c61-7cb6-41d5-9b24-b7e43fc32d4f"
      }
    },
    {
      "id": "02e1a6bf-e926-4e7f-b105-2f5fb5150d29",
      "cell_type": "code",
      "source": [
        "import h5py\n",
        "\n",
        "def another_smart_slicer_generator(lengths, offset=0):\n",
        "    with h5py.File('/kaggle/input/arabic-diacrirization-features-really-val-4152/zizo_part_4152.h5', 'r') as f:\n",
        "        features_dset = f['features']\n",
        "        labels_dset = f['tashkeel']\n",
        "\n",
        "        current_idx = offset\n",
        "\n",
        "        for seq_len in lengths:\n",
        "            end_idx = current_idx + seq_len\n",
        "\n",
        "            feat = features_dset[current_idx : end_idx]\n",
        "            lbl = labels_dset[current_idx : end_idx]\n",
        "            is_space = np.all(feat[:, :768] == 0, axis=1)\n",
        "            lbl[is_space] = 15\n",
        "\n",
        "            lbl = lbl.reshape(-1, 1)\n",
        "\n",
        "            yield feat, lbl\n",
        "\n",
        "            current_idx = end_idx"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-06T10:31:02.588727Z",
          "iopub.execute_input": "2025-12-06T10:31:02.589007Z",
          "iopub.status.idle": "2025-12-06T10:31:02.594268Z",
          "shell.execute_reply.started": "2025-12-06T10:31:02.588984Z",
          "shell.execute_reply": "2025-12-06T10:31:02.593574Z"
        },
        "id": "02e1a6bf-e926-4e7f-b105-2f5fb5150d29"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "19fe5f37-4e61-4c7c-a88d-720a42d85c37",
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "sentences, tashkeel_sequences = load_data_pickle(padded_val)\n",
        "\n",
        "new_sentences = sentences\n",
        "new_tashkeel = tashkeel_sequences\n",
        "\n",
        "# for i in range(len(sentences)):\n",
        "#     text, tashkeel = remove_pads(sentences[i], tashkeel_sequences[i])\n",
        "#     new_sentences.append(text)\n",
        "#     new_tashkeel.append(tashkeel)\n",
        "\n",
        "all_sentence_lengths = [len(s) for s in new_sentences]"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-06T10:31:04.355594Z",
          "iopub.execute_input": "2025-12-06T10:31:04.356154Z",
          "iopub.status.idle": "2025-12-06T10:31:04.478436Z",
          "shell.execute_reply.started": "2025-12-06T10:31:04.356129Z",
          "shell.execute_reply": "2025-12-06T10:31:04.477816Z"
        },
        "id": "19fe5f37-4e61-4c7c-a88d-720a42d85c37"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "82fb3170-4371-4faf-a95c-5452354825ff",
      "cell_type": "code",
      "source": [
        "test_dataset = tf.data.Dataset.from_generator(\n",
        "    lambda: another_smart_slicer_generator(all_sentence_lengths, offset=0),\n",
        "    output_signature=(\n",
        "        tf.TensorSpec(shape=(None, INPUT_DIM), dtype=tf.float32),\n",
        "        tf.TensorSpec(shape=(None, 1), dtype=tf.int32)\n",
        "    )\n",
        ").padded_batch(BATCH_SIZE, padding_values=(PADDING_INPUT, 15))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-06T10:31:05.112198Z",
          "iopub.execute_input": "2025-12-06T10:31:05.112746Z",
          "iopub.status.idle": "2025-12-06T10:31:05.163053Z",
          "shell.execute_reply.started": "2025-12-06T10:31:05.112717Z",
          "shell.execute_reply": "2025-12-06T10:31:05.162481Z"
        },
        "id": "82fb3170-4371-4faf-a95c-5452354825ff"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "651d9d7b-5698-424f-84aa-3e92c4b6adfd",
      "cell_type": "code",
      "source": [
        "total_correct = 0\n",
        "total_chars = 0\n",
        "sentences_processed = 0\n",
        "\n",
        "for batch_x, batch_y in test_dataset:\n",
        "\n",
        "    batch_probs = model.predict_on_batch(batch_x)\n",
        "\n",
        "    batch_pred_ids = np.argmax(batch_probs, axis=-1)\n",
        "\n",
        "    batch_true_ids = batch_y.numpy().squeeze(axis=-1)\n",
        "\n",
        "    batch_size = batch_pred_ids.shape[0]\n",
        "\n",
        "    for k in range(batch_size):\n",
        "        valid_indices = np.where(batch_true_ids[k] != -1)[0]\n",
        "\n",
        "        if len(valid_indices) == 0:\n",
        "            continue\n",
        "\n",
        "        real_len = valid_indices[-1] + 1\n",
        "\n",
        "        p_seq = batch_pred_ids[k][:real_len]\n",
        "        t_seq = batch_true_ids[k][:real_len]\n",
        "        mask = (t_seq != 15)\n",
        "        matches = np.sum(p_seq[mask] == t_seq[mask])\n",
        "        total_chars += np.sum(mask)\n",
        "\n",
        "\n",
        "        total_correct += matches\n",
        "        sentences_processed += 1\n",
        "if total_chars > 0:\n",
        "    print(f\"Final Accuracy: {total_correct / total_chars:.2%}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-06T10:31:05.170252Z",
          "iopub.execute_input": "2025-12-06T10:31:05.170798Z",
          "iopub.status.idle": "2025-12-06T10:31:31.912135Z",
          "shell.execute_reply.started": "2025-12-06T10:31:05.170779Z",
          "shell.execute_reply": "2025-12-06T10:31:31.911528Z"
        },
        "id": "651d9d7b-5698-424f-84aa-3e92c4b6adfd",
        "outputId": "597f1ccc-9968-4ab7-eb57-ed548182dbd0"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Final Accuracy: 97.68%\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "id": "4d5bb98d-8c28-480f-a247-3a7ce2ebaffe",
      "cell_type": "markdown",
      "source": [
        "# Save the model"
      ],
      "metadata": {
        "id": "4d5bb98d-8c28-480f-a247-3a7ce2ebaffe"
      }
    },
    {
      "id": "405aa89f-e380-415a-bfe7-19abe6be6a3f",
      "cell_type": "code",
      "source": [
        "model.save('last_char_electra_test.keras')"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-09T11:41:43.57274Z",
          "iopub.execute_input": "2025-12-09T11:41:43.573463Z",
          "iopub.status.idle": "2025-12-09T11:41:44.666766Z",
          "shell.execute_reply.started": "2025-12-09T11:41:43.573436Z",
          "shell.execute_reply": "2025-12-09T11:41:44.666143Z"
        },
        "id": "405aa89f-e380-415a-bfe7-19abe6be6a3f"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "e6950a22-7c49-44d9-91eb-9475fc170447",
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "from kaggle_secrets import UserSecretsClient\n",
        "import os\n",
        "\n",
        "my_username = \"ziad23samer\"\n",
        "my_key = \"0dda25fbbd0112eac2ff1848742972a2\"\n",
        "os.environ[\"KAGGLE_USERNAME\"] = my_username\n",
        "os.environ[\"KAGGLE_KEY\"] = my_key\n",
        "\n",
        "handle = f\"{my_username}/last_char_electra_test/keras/1\"\n",
        "\n",
        "local_model_dir = \"/kaggle/working/\"\n",
        "\n",
        "kagglehub.model_upload(handle, local_model_dir, version_notes=\"Initial release from notebook\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-09T11:41:45.719313Z",
          "iopub.execute_input": "2025-12-09T11:41:45.71985Z",
          "iopub.status.idle": "2025-12-09T11:41:51.427797Z",
          "shell.execute_reply.started": "2025-12-09T11:41:45.719825Z",
          "shell.execute_reply": "2025-12-09T11:41:51.427052Z"
        },
        "id": "e6950a22-7c49-44d9-91eb-9475fc170447",
        "outputId": "10a18e6c-ded2-4ec9-e29c-a18b3ccd2cd1"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Uploading Model https://www.kaggle.com/models/ziad23samer/last_char_electra_test/keras/1 ...\nModel 'last_char_electra_test' does not exist or access is forbidden for user 'ziad23samer'. Creating or handling Model...\nModel 'last_char_electra_test' Created.\nStarting upload for file /kaggle/working/last_char_electra_test.keras\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Uploading: 100%|██████████| 321M/321M [00:02<00:00, 119MB/s]  ",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Upload successful: /kaggle/working/last_char_electra_test.keras (306MB)\nStarting upload for file /kaggle/working/.virtual_documents/__notebook_source__.ipynb\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "\nUploading: 100%|██████████| 14.2k/14.2k [00:00<00:00, 62.6kB/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Upload successful: /kaggle/working/.virtual_documents/__notebook_source__.ipynb (14KB)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Your model instance has been created.\nFiles are being processed...\nSee at: https://www.kaggle.com/models/ziad23samer/last_char_electra_test/keras/1\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "id": "c72a674d-eadd-4bc1-b614-418938da4664",
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "c72a674d-eadd-4bc1-b614-418938da4664"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}