{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4943355d",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-12-09T11:44:37.98946Z",
          "iopub.status.busy": "2025-12-09T11:44:37.988872Z",
          "iopub.status.idle": "2025-12-09T11:44:44.346989Z",
          "shell.execute_reply": "2025-12-09T11:44:44.345889Z",
          "shell.execute_reply.started": "2025-12-09T11:44:37.989413Z"
        },
        "id": "4943355d",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "!pip install -q \"protobuf==3.20.*\"\n",
        "!pip install -q transformers arabert preprocess"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa5539c4-c043-4558-aca6-57945fc29458",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-12-09T11:44:44.34901Z",
          "iopub.status.busy": "2025-12-09T11:44:44.348504Z",
          "iopub.status.idle": "2025-12-09T11:44:44.353486Z",
          "shell.execute_reply": "2025-12-09T11:44:44.352819Z",
          "shell.execute_reply.started": "2025-12-09T11:44:44.348981Z"
        },
        "id": "aa5539c4-c043-4558-aca6-57945fc29458",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import pickle\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import itertools\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from arabert.preprocess import ArabertPreprocessor"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c247254",
      "metadata": {
        "id": "0c247254"
      },
      "source": [
        "# Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38777fe6",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-12-09T11:44:44.354466Z",
          "iopub.status.busy": "2025-12-09T11:44:44.354235Z",
          "iopub.status.idle": "2025-12-09T11:44:44.368953Z",
          "shell.execute_reply": "2025-12-09T11:44:44.368238Z",
          "shell.execute_reply.started": "2025-12-09T11:44:44.35444Z"
        },
        "id": "38777fe6",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "char2idx_path = '/kaggle/input/arabicia-3/char2idx.json'\n",
        "arabic_letters_map = '/kaggle/input/arabic-letters-map/arabic_letters.pickle'\n",
        "model_path = '/kaggle/input/arabic-diacritizer-residual/keras/1/1/model_with_features_v2_res.keras'\n",
        "char_embeddings_path = '/kaggle/input/embeddings-chars/keras/default/1/embedding_matrix(1).npy'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a82bd59",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-12-09T11:44:44.37099Z",
          "iopub.status.busy": "2025-12-09T11:44:44.370723Z",
          "iopub.status.idle": "2025-12-09T11:44:44.383877Z",
          "shell.execute_reply": "2025-12-09T11:44:44.383191Z",
          "shell.execute_reply.started": "2025-12-09T11:44:44.370973Z"
        },
        "id": "2a82bd59",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def get_diacritics_map():\n",
        "\n",
        "    diacritic2id = {\n",
        "        \"َ\": 0,\n",
        "        \"ً\": 1,\n",
        "        \"ُ\": 2,\n",
        "        \"ٌ\": 3,\n",
        "        \"ِ\": 4,\n",
        "        \"ٍ\": 5,\n",
        "        \"ْ\": 6,\n",
        "        \"ّ\": 7,\n",
        "        \"َّ\": 8,\n",
        "        \"ًّ\": 9,\n",
        "        \"ُّ\": 10,\n",
        "        \"ٌّ\": 11,\n",
        "        \"ِّ\": 12,\n",
        "        \"ٍّ\": 13,\n",
        "        \"\": 14\n",
        "    }\n",
        "    idx2label = {v: k for k, v in diacritic2id.items()}\n",
        "\n",
        "    return diacritic2id, idx2label\n",
        "\n",
        "def get_char_map():\n",
        "    with open(char2idx_path, 'r', encoding='utf-8') as f:\n",
        "        char2idx = json.load(f)\n",
        "    for key, value in char2idx.items():\n",
        "        if value != 0:\n",
        "            char2idx[key] = value - 1\n",
        "    idx2char = {k : v for v, k in char2idx.items()}\n",
        "\n",
        "    return char2idx, idx2char"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c9f6658",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-12-09T11:44:44.384715Z",
          "iopub.status.busy": "2025-12-09T11:44:44.384518Z",
          "iopub.status.idle": "2025-12-09T11:44:44.400441Z",
          "shell.execute_reply": "2025-12-09T11:44:44.399891Z",
          "shell.execute_reply.started": "2025-12-09T11:44:44.3847Z"
        },
        "id": "4c9f6658",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def get_arabic_characters():\n",
        "    with open(arabic_letters_map, 'rb') as f:\n",
        "        arabic_letters = pickle.load(f)\n",
        "    return arabic_letters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b97c37b-d9e7-448a-bad3-85cbe4501b14",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-12-09T11:44:44.401214Z",
          "iopub.status.busy": "2025-12-09T11:44:44.401055Z",
          "iopub.status.idle": "2025-12-09T11:44:44.41498Z",
          "shell.execute_reply": "2025-12-09T11:44:44.4143Z",
          "shell.execute_reply.started": "2025-12-09T11:44:44.4012Z"
        },
        "id": "4b97c37b-d9e7-448a-bad3-85cbe4501b14",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "char2idx, idx2char = get_char_map()\n",
        "diacritic2id, idx2label = get_diacritics_map()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bfadf730",
      "metadata": {
        "id": "bfadf730"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3576806d",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-12-09T11:44:44.416032Z",
          "iopub.status.busy": "2025-12-09T11:44:44.415702Z",
          "iopub.status.idle": "2025-12-09T11:44:44.426426Z",
          "shell.execute_reply": "2025-12-09T11:44:44.425506Z",
          "shell.execute_reply.started": "2025-12-09T11:44:44.416009Z"
        },
        "id": "3576806d",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "DIACRITICS_PATTERN = re.compile(r'[\\u064B-\\u0652]')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e3041bf",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-12-09T11:44:44.428056Z",
          "iopub.status.busy": "2025-12-09T11:44:44.427245Z",
          "iopub.status.idle": "2025-12-09T11:44:44.440115Z",
          "shell.execute_reply": "2025-12-09T11:44:44.439592Z",
          "shell.execute_reply.started": "2025-12-09T11:44:44.428038Z"
        },
        "id": "1e3041bf",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def split_text_and_diacritics(text):\n",
        "\n",
        "    letters = []\n",
        "    labels = []\n",
        "\n",
        "    i = 0\n",
        "    while i < len(text):\n",
        "        char = text[i]\n",
        "\n",
        "        if DIACRITICS_PATTERN.match(char):\n",
        "            if labels:\n",
        "                labels[-1] += char\n",
        "        else:\n",
        "            letters.append(char)\n",
        "            labels.append(\"\")\n",
        "\n",
        "        i += 1\n",
        "\n",
        "    return \"\".join(letters), labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "475e996f",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-12-09T12:20:11.775507Z",
          "iopub.status.busy": "2025-12-09T12:20:11.775217Z",
          "iopub.status.idle": "2025-12-09T12:20:11.792423Z",
          "shell.execute_reply": "2025-12-09T12:20:11.791636Z",
          "shell.execute_reply.started": "2025-12-09T12:20:11.775489Z"
        },
        "id": "475e996f",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "numeric_pattern = r\"\\(\\s*\\d+\\s*/\\s*\\d+\\s*\\)\"\n",
        "english = r\"[a-zA-Z]\"\n",
        "numbers = r\"\\s*\\d+\\s*\"\n",
        "numering_items = r\"\\s*\\d+\\s*[-]\\s*\"\n",
        "empty_brackets = r'\\(\\s*\\)|\\[\\s*\\]|\\{\\s*\\}|<<\\s*>>|\"\\s*\"|\\'\\s*\\''\n",
        "\n",
        "def clean_punctuation_sequence(text):\n",
        "    collapsible = re.escape(\".,:;!?'\\\"/،؛؟\")\n",
        "    pattern = rf\"([{collapsible}])(?:\\s*\\1)+\"\n",
        "\n",
        "    return re.sub(pattern, r\"\\1\", text)\n",
        "\n",
        "def remove_unbalanced_brackets(text):\n",
        "    pair_map = {')': '(', '}': '{', ']': '[', '>':'<', '»': '«', '\"':'\"', \"'\":\"'\"}\n",
        "    openers = set(['(', '{', '[', '<', '«', '\"', \"'\"])\n",
        "\n",
        "    stack = []\n",
        "    indices_to_remove = set()\n",
        "\n",
        "    for i, char in enumerate(text):\n",
        "        if char in openers:\n",
        "            stack.append((char, i))\n",
        "\n",
        "        elif char in pair_map:\n",
        "            if stack:\n",
        "                last_opener, _ = stack[-1]\n",
        "                if last_opener == pair_map[char]:\n",
        "                    stack.pop()\n",
        "                else:\n",
        "                    indices_to_remove.add(i)\n",
        "            else:\n",
        "                indices_to_remove.add(i)\n",
        "\n",
        "    for char, index in stack:\n",
        "        indices_to_remove.add(index)\n",
        "\n",
        "    return \"\".join([char for i, char in enumerate(text) if i not in indices_to_remove])\n",
        "\n",
        "\n",
        "def initial_process(line):\n",
        "    res = re.sub(numering_items, '', line)\n",
        "    res = re.sub(numeric_pattern, '', res)\n",
        "    res = re.sub(english, ' ', res)\n",
        "    res = re.sub(numbers, '', res)\n",
        "    res = re.sub(empty_brackets, '', res)\n",
        "    res = re.sub(',', '،', res)\n",
        "    res = re.sub(';', '؛', res)\n",
        "    res = re.sub(r'\\?', '؟', res)\n",
        "    res = re.sub(r'/', '', res)\n",
        "    res = re.sub(r'\\*', '', res)\n",
        "    res = re.sub(r'–', '-', res)\n",
        "    res = res.replace('\\u200f', '')\n",
        "\n",
        "\n",
        "    res = clean_punctuation_sequence(res)\n",
        "\n",
        "    res = remove_unbalanced_brackets(res)\n",
        "\n",
        "    res = re.sub(r\"\\s+\", \" \", res).strip()\n",
        "\n",
        "    return res\n",
        "\n",
        "\n",
        "def split_citations_raw(line):\n",
        "    qal_list = [\n",
        "        \"قال\", \"قالت\", \"قالوا\", \"قلت\", \"قلنا\",\n",
        "        \"أقول\", \"يقول\", \"يقولون\", \"قيل\", \"يقال\"\n",
        "    ]\n",
        "\n",
        "    qal_regex = \"|\".join(qal_list)\n",
        "\n",
        "    qal_with_colon = rf\"(?:{qal_regex})\\s*[:：]\"\n",
        "\n",
        "\n",
        "    qawloho_regex = r\"(?:و|ف)?قول(?:ه)?(?:\\s*تعالى)?\"\n",
        "\n",
        "    trigger = rf\"({qal_with_colon}|{qawloho_regex})\"\n",
        "\n",
        "    final_lines = []\n",
        "    matches = list(re.finditer(trigger, line))\n",
        "\n",
        "    if not matches:\n",
        "        final_lines.append(line.strip())\n",
        "    else:\n",
        "        last_idx = 0\n",
        "        for m in matches:\n",
        "            start = m.start()\n",
        "            if line[last_idx:start]:\n",
        "                final_lines.append(line[last_idx:start])\n",
        "            last_idx = start\n",
        "\n",
        "        final_lines.append(line[last_idx:])\n",
        "\n",
        "    return final_lines\n",
        "\n",
        "def slide_window_raw(text, overlap=50, max_len=807):\n",
        "    if len(text) <= max_len:\n",
        "        return [text], [0]\n",
        "\n",
        "    chunks = []\n",
        "    overlaps = []\n",
        "\n",
        "    chunks.append(text[:max_len])\n",
        "    overlaps.append(0)\n",
        "\n",
        "    current_start = 0\n",
        "    text_len = len(text)\n",
        "\n",
        "    while True:\n",
        "        ideal_stride = max_len - overlap\n",
        "\n",
        "        ideal_next_start = current_start + ideal_stride\n",
        "\n",
        "        if ideal_next_start >= text_len:\n",
        "            break\n",
        "\n",
        "        found_next_start = -1\n",
        "\n",
        "        search_limit = current_start\n",
        "\n",
        "        for i in range(ideal_next_start, search_limit, -1):\n",
        "            if i < text_len and text[i] == ' ':\n",
        "                found_next_start = i + 1\n",
        "                break\n",
        "\n",
        "        if found_next_start == -1:\n",
        "            found_next_start = ideal_next_start\n",
        "\n",
        "        actual_overlap = (current_start + max_len) - found_next_start\n",
        "\n",
        "        if actual_overlap < 0:\n",
        "            actual_overlap = 0\n",
        "\n",
        "        next_chunk = text[found_next_start : found_next_start + max_len]\n",
        "\n",
        "        chunks.append(next_chunk)\n",
        "        overlaps.append(actual_overlap)\n",
        "\n",
        "        current_start = found_next_start\n",
        "\n",
        "        if current_start + max_len >= text_len:\n",
        "            break\n",
        "\n",
        "    return chunks, overlaps\n",
        "\n",
        "\n",
        "def prepare_for_predict():\n",
        "    all_recovery = []\n",
        "    assertions_text = []\n",
        "    assertions_tashkeel = []\n",
        "    test = True\n",
        "    curr_chunks = []\n",
        "    curr_overlaps = []\n",
        "\n",
        "    with open(f'/kaggle/input/test-set/sample_test_no_diacritics.txt', \"r\", encoding=\"utf-8\") as file:\n",
        "\n",
        "        for line in file:\n",
        "\n",
        "            cleaned = initial_process(line.strip())\n",
        "            if test == True:\n",
        "                assertions_text.append(cleaned)\n",
        "                line = cleaned\n",
        "            else:\n",
        "                line, tashkeel = split_text_and_diacritics(cleaned)\n",
        "                assertions_text.append(line)\n",
        "                assertions_tashkeel.append(tashkeel)\n",
        "\n",
        "            raw_segments = split_citations_raw(line)\n",
        "            recovery = []\n",
        "\n",
        "            for seg in raw_segments:\n",
        "                t_chunks, t_overlaps = slide_window_raw(seg, overlap=50, max_len=807)\n",
        "                assert len(t_chunks) == len(t_overlaps), print(len(t_chunks), len(t_overlaps))\n",
        "\n",
        "                for i, chunk in enumerate(t_chunks):\n",
        "                    recovery.append(i)\n",
        "                    curr_chunks.append(chunk)\n",
        "\n",
        "                curr_overlaps.extend(t_overlaps)\n",
        "            all_recovery.append(recovery)\n",
        "\n",
        "    print(f\"Generated {len(curr_chunks)} chunks.\")\n",
        "    return curr_chunks, curr_overlaps, all_recovery, assertions_text, assertions_tashkeel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bdf5e723-557b-4b88-8ea2-fe7fd298194c",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-12-09T12:20:13.276573Z",
          "iopub.status.busy": "2025-12-09T12:20:13.276328Z",
          "iopub.status.idle": "2025-12-09T12:20:13.309941Z",
          "shell.execute_reply": "2025-12-09T12:20:13.309333Z",
          "shell.execute_reply.started": "2025-12-09T12:20:13.276556Z"
        },
        "id": "bdf5e723-557b-4b88-8ea2-fe7fd298194c",
        "outputId": "ff15a3a7-0ed8-4d83-de59-63289a7bb423",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated 2 chunks.\n"
          ]
        }
      ],
      "source": [
        "chunks, overlaps, recovery, assertions_text, assertions_tashkeel = prepare_for_predict()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "72140541",
      "metadata": {
        "id": "72140541"
      },
      "source": [
        "# Post Processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c88d970",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-12-09T12:20:15.517668Z",
          "iopub.status.busy": "2025-12-09T12:20:15.517123Z",
          "iopub.status.idle": "2025-12-09T12:20:15.524856Z",
          "shell.execute_reply": "2025-12-09T12:20:15.524078Z",
          "shell.execute_reply.started": "2025-12-09T12:20:15.517643Z"
        },
        "id": "7c88d970",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def reconstruct_text_window(chunks, overlaps):\n",
        "    if not chunks:\n",
        "        return \"\"\n",
        "\n",
        "    reconstructed_parts = []\n",
        "\n",
        "    for chunk, ov in zip(chunks[0:], overlaps):\n",
        "        reconstructed_parts.append(chunk[ov:])\n",
        "\n",
        "    return \"\".join(reconstructed_parts)\n",
        "\n",
        "\n",
        "def arabic_only_text_and_tashkeel(text, tashkeel):\n",
        "    ARABIC_CHARS = get_arabic_characters()\n",
        "    return \"\".join([char for char in text if char in ARABIC_CHARS or char == \" \"]), [tashkeel[i] for i, char in enumerate(text) if char in ARABIC_CHARS or char == \" \"]\n",
        "\n",
        "def arabic_only_text_and_tashkeel_no_spaces(text, tashkeel):\n",
        "    ARABIC_CHARS = get_arabic_characters()\n",
        "    return \"\".join([char for char in text if char in ARABIC_CHARS]), [tashkeel[i] for i, char in enumerate(text) if char in ARABIC_CHARS]\n",
        "\n",
        "def post_process(chunks, overlaps, recovery):\n",
        "    results = []\n",
        "    start_chnk_idx = 0\n",
        "    end_chnk_idx = 0\n",
        "\n",
        "    for i in range(len(recovery)):\n",
        "        zero_before = False\n",
        "        res = ''\n",
        "        for j in recovery[i]:\n",
        "            if j == 0:\n",
        "                if zero_before:\n",
        "                    res += reconstruct_text_window(chunks[start_chnk_idx:end_chnk_idx + 1], overlaps[start_chnk_idx:end_chnk_idx + 1])\n",
        "                    start_chnk_idx = end_chnk_idx + 1\n",
        "                    end_chnk_idx += 1\n",
        "                zero_before = True\n",
        "            else:\n",
        "                end_chnk_idx += 1\n",
        "\n",
        "        res += reconstruct_text_window(chunks[start_chnk_idx:end_chnk_idx + 1], overlaps[start_chnk_idx:end_chnk_idx + 1])\n",
        "        start_chnk_idx = end_chnk_idx + 1\n",
        "        end_chnk_idx += 1\n",
        "        results.append(res)\n",
        "\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "291b7a47-3b99-4580-88f2-8ebeaf026955",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-12-09T12:20:17.262913Z",
          "iopub.status.busy": "2025-12-09T12:20:17.262627Z",
          "iopub.status.idle": "2025-12-09T12:20:17.269371Z",
          "shell.execute_reply": "2025-12-09T12:20:17.268631Z",
          "shell.execute_reply.started": "2025-12-09T12:20:17.262892Z"
        },
        "id": "291b7a47-3b99-4580-88f2-8ebeaf026955",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def reconstruct_diacritics_window(chunks, overlaps):\n",
        "    if not chunks:\n",
        "        return np.array([])\n",
        "\n",
        "    reconstructed_parts = []\n",
        "\n",
        "    for chunk, ov in zip(chunks, overlaps):\n",
        "        reconstructed_parts.append(chunk[ov:])\n",
        "\n",
        "    return np.concatenate(reconstructed_parts)\n",
        "\n",
        "\n",
        "def post_process_diacritics(chunks, overlaps, recovery):\n",
        "    results = []\n",
        "    start_chnk_idx = 0\n",
        "    end_chnk_idx = 0\n",
        "\n",
        "    for i in range(len(recovery)):\n",
        "        zero_before = False\n",
        "\n",
        "        res = np.array([], dtype=int)\n",
        "\n",
        "        for j in recovery[i]:\n",
        "            if j == 0:\n",
        "                if zero_before:\n",
        "                    segment = reconstruct_diacritics_window(\n",
        "                        chunks[start_chnk_idx : end_chnk_idx + 1],\n",
        "                        overlaps[start_chnk_idx : end_chnk_idx + 1]\n",
        "                    )\n",
        "                    res = np.concatenate([res, segment])\n",
        "\n",
        "                    start_chnk_idx = end_chnk_idx + 1\n",
        "                    end_chnk_idx += 1\n",
        "                zero_before = True\n",
        "            else:\n",
        "                end_chnk_idx += 1\n",
        "\n",
        "        segment = reconstruct_diacritics_window(\n",
        "            chunks[start_chnk_idx : end_chnk_idx + 1],\n",
        "            overlaps[start_chnk_idx : end_chnk_idx + 1]\n",
        "        )\n",
        "        res = np.concatenate([res, segment])\n",
        "\n",
        "        start_chnk_idx = end_chnk_idx + 1\n",
        "        end_chnk_idx += 1\n",
        "\n",
        "        results.append(res)\n",
        "\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "70f52a9d-ef07-4ffc-aa7b-01a70eee1860",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-12-09T12:20:17.455126Z",
          "iopub.status.busy": "2025-12-09T12:20:17.454688Z",
          "iopub.status.idle": "2025-12-09T12:20:17.459317Z",
          "shell.execute_reply": "2025-12-09T12:20:17.458651Z",
          "shell.execute_reply.started": "2025-12-09T12:20:17.455107Z"
        },
        "id": "70f52a9d-ef07-4ffc-aa7b-01a70eee1860",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def get_finals(results, labels, tokens=True):\n",
        "    flat_labels = list(itertools.chain.from_iterable(labels))\n",
        "    if tokens:\n",
        "        new_flat_labels = [idx2label[label] for label in flat_labels]\n",
        "    else:\n",
        "        new_flat_labels = flat_labels\n",
        "    idx = 0\n",
        "    final_results = []\n",
        "    for result in results:\n",
        "        final_str = ''\n",
        "        for char in result:\n",
        "            final_str += char + new_flat_labels[idx]\n",
        "            idx += 1\n",
        "        final_results.append(final_str)\n",
        "    return final_results"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c802d3df",
      "metadata": {
        "id": "c802d3df"
      },
      "source": [
        "# Extract Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c12ea8cd",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-12-09T12:20:18.895577Z",
          "iopub.status.busy": "2025-12-09T12:20:18.895291Z",
          "iopub.status.idle": "2025-12-09T12:20:20.527846Z",
          "shell.execute_reply": "2025-12-09T12:20:20.527285Z",
          "shell.execute_reply.started": "2025-12-09T12:20:18.895553Z"
        },
        "id": "c12ea8cd",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "\n",
        "arabert_model_name = \"aubmindlab/bert-base-arabertv02\"\n",
        "bert_tokenizer = AutoTokenizer.from_pretrained(arabert_model_name)\n",
        "bert_model = AutoModel.from_pretrained(arabert_model_name)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "bert_model.to(device)\n",
        "bert_model.eval()\n",
        "arabert_prep = ArabertPreprocessor(model_name=arabert_model_name)\n",
        "\n",
        "\n",
        "MODEL_NAME = \"aubmindlab/araelectra-base-discriminator\"\n",
        "\n",
        "electra_tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "electra_model = AutoModel.from_pretrained(MODEL_NAME)\n",
        "electra_model.to(device)\n",
        "electra_model.eval()\n",
        "\n",
        "\n",
        "custom_char_embedding = np.load(char_embeddings_path)\n",
        "\n",
        "def get_arabert_embeddings(sentence: str):\n",
        "\n",
        "    tokens = bert_tokenizer(sentence, return_tensors=\"pt\", truncation=True, padding=True)\n",
        "    tokens = {k: v.to(device) for k, v in tokens.items()}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = bert_model(**tokens)\n",
        "\n",
        "    emb = output.last_hidden_state.squeeze(0).cpu()\n",
        "    token_list = bert_tokenizer.convert_ids_to_tokens(tokens[\"input_ids\"][0])\n",
        "\n",
        "    return emb.numpy(), token_list\n",
        "\n",
        "\n",
        "def get_araelectra_embeddings(sentence, device=\"cuda\"):\n",
        "    \"\"\"\n",
        "    Get token-level embeddings from AraELECTRA\n",
        "    Returns a list of sentence embeddings (list of token embeddings)\n",
        "    \"\"\"\n",
        "    electra_model.to(device)\n",
        "    inputs = electra_tokenizer(sentence, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
        "    token_ids = inputs['input_ids'][0]\n",
        "\n",
        "    tokens = electra_tokenizer.convert_ids_to_tokens(token_ids)\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "    with torch.no_grad():\n",
        "        outputs = electra_model(**inputs)\n",
        "        last_hidden_state = outputs.last_hidden_state\n",
        "    token_embeddings = last_hidden_state.squeeze(0)\n",
        "    return token_embeddings, tokens\n",
        "\n",
        "def extract_custom_char_embeddings(char):\n",
        "    char2idx, _ = get_char_map()\n",
        "    return custom_char_embedding[char2idx[char]]\n",
        "\n",
        "def tokens_to_word_embeddings(tokens, embeddings):\n",
        "    word_embeddings = []\n",
        "    current_word_embs = []\n",
        "\n",
        "    for token, emb in zip(tokens, embeddings):\n",
        "        emb_tensor = torch.tensor(emb) if isinstance(emb, np.ndarray) else emb\n",
        "\n",
        "        if token.startswith(\"##\"):\n",
        "            current_word_embs.append(emb_tensor)\n",
        "        else:\n",
        "            if current_word_embs:\n",
        "                word_embeddings.append(torch.mean(torch.stack(current_word_embs), dim=0))\n",
        "            current_word_embs = [emb_tensor]\n",
        "\n",
        "    if current_word_embs:\n",
        "        word_embeddings.append(torch.mean(torch.stack(current_word_embs), dim=0))\n",
        "\n",
        "    return torch.stack(word_embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c192470",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-12-09T12:20:21.336385Z",
          "iopub.status.busy": "2025-12-09T12:20:21.335756Z",
          "iopub.status.idle": "2025-12-09T12:20:21.345823Z",
          "shell.execute_reply": "2025-12-09T12:20:21.345002Z",
          "shell.execute_reply.started": "2025-12-09T12:20:21.336363Z"
        },
        "id": "6c192470",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def zizo_features(sentence: str):\n",
        "\n",
        "    sentence_vec = []\n",
        "\n",
        "    arabert_emb, tokens = get_arabert_embeddings(sentence)\n",
        "    final_arabert_emb = tokens_to_word_embeddings(tokens, arabert_emb)\n",
        "\n",
        "    words_raw = sentence.split()\n",
        "    word_idx = 0\n",
        "    char_in_word_idx = 0\n",
        "\n",
        "    emb_dim = final_arabert_emb[0].shape[0]\n",
        "\n",
        "    for i, char in enumerate(sentence):\n",
        "\n",
        "        char_emb = extract_custom_char_embeddings(char)\n",
        "        char_emb_array = np.array(char_emb).flatten()\n",
        "\n",
        "        if char == ' ':\n",
        "            bert_vec = np.zeros(emb_dim)\n",
        "\n",
        "        else:\n",
        "            bert_vec = final_arabert_emb[word_idx]\n",
        "            if isinstance(bert_vec, torch.Tensor):\n",
        "                bert_vec = bert_vec.numpy()\n",
        "\n",
        "            char_in_word_idx += 1\n",
        "\n",
        "            if char_in_word_idx == len(words_raw[word_idx]):\n",
        "                word_idx += 1\n",
        "                char_in_word_idx = 0\n",
        "\n",
        "        char_vector = np.concatenate([bert_vec, char_emb_array])\n",
        "        sentence_vec.append(char_vector)\n",
        "\n",
        "    return sentence_vec\n",
        "\n",
        "def zizo_features_electra(sentence: str):\n",
        "\n",
        "    sentence_vec = []\n",
        "\n",
        "    araelectra_emb, tokens = get_araelectra_embeddings(sentence)\n",
        "    final_araelectra_emb = tokens_to_word_embeddings(tokens, araelectra_emb)\n",
        "\n",
        "    words_raw = sentence.split()\n",
        "    word_idx = 0\n",
        "    char_in_word_idx = 0\n",
        "\n",
        "    emb_dim = final_araelectra_emb[0].shape[0]\n",
        "\n",
        "    for i, char in enumerate(sentence):\n",
        "\n",
        "        char_emb = extract_custom_char_embeddings(char)\n",
        "        char_emb_array = np.array(char_emb).flatten()\n",
        "\n",
        "        if char in punctuation:\n",
        "            araelectra_vec = np.zeros(emb_dim)\n",
        "\n",
        "        else:\n",
        "            araelectra_vec = final_araelectra_emb[word_idx]\n",
        "            if isinstance(araelectra_vec, torch.Tensor):\n",
        "                araelectra_vec = araelectra_vec.cpu().numpy()\n",
        "\n",
        "            char_in_word_idx += 1\n",
        "\n",
        "            if char_in_word_idx == len(words_raw[word_idx]):\n",
        "                word_idx += 1\n",
        "                char_in_word_idx = 0\n",
        "\n",
        "        char_vector = np.concatenate([araelectra_vec, char_emb_array])\n",
        "        sentence_vec.append(char_vector)\n",
        "\n",
        "    return sentence_vec\n",
        "\n",
        "def extract_features(sentences):\n",
        "    all_sentence_features = []\n",
        "\n",
        "    for i in tqdm(range(len(sentences)), total=len(sentences), desc=\"extracting features\"):\n",
        "        sent = sentences[i]\n",
        "        features_list = zizo_features(\"\".join(sent))\n",
        "\n",
        "        all_sentence_features.append(np.array(features_list, dtype=np.float16))\n",
        "\n",
        "    return all_sentence_features\n",
        "\n",
        "def extract_features_electra(sentences):\n",
        "    all_sentence_features = []\n",
        "\n",
        "    for i in tqdm(range(len(sentences)), total=len(sentences), desc=\"extracting features\"):\n",
        "        sent = sentences[i]\n",
        "        features_list = zizo_features_electra(\"\".join(sent))\n",
        "\n",
        "        all_sentence_features.append(np.array(features_list, dtype=np.float16))\n",
        "\n",
        "    return all_sentence_features"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3cf52ca1",
      "metadata": {
        "id": "3cf52ca1"
      },
      "source": [
        "# Predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b99d3ec0-0608-48c7-903a-e53daae9f4ac",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-12-09T12:09:16.426478Z",
          "iopub.status.busy": "2025-12-09T12:09:16.426185Z",
          "iopub.status.idle": "2025-12-09T12:09:26.221196Z",
          "shell.execute_reply": "2025-12-09T12:09:26.220548Z",
          "shell.execute_reply.started": "2025-12-09T12:09:16.426453Z"
        },
        "id": "b99d3ec0-0608-48c7-903a-e53daae9f4ac",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "electra_all_model = tf.keras.models.load_model(f'/kaggle/input/arabic-diacritizer-araelectra-all/keras/1/1/araelectra_all.keras', compile=False)\n",
        "electra_lastchar_model = tf.keras.models.load_model(f'/kaggle/input/last_char_electra_test/keras/1/1/last_char_electra_test.keras', compile=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed31e647",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-12-09T12:20:23.717409Z",
          "iopub.status.busy": "2025-12-09T12:20:23.716698Z",
          "iopub.status.idle": "2025-12-09T12:20:23.726081Z",
          "shell.execute_reply": "2025-12-09T12:20:23.725271Z",
          "shell.execute_reply.started": "2025-12-09T12:20:23.717381Z"
        },
        "id": "ed31e647",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "\n",
        "# Configuration\n",
        "INTAHA = r'\\s+ا\\s*هـ?\\s+'\n",
        "BATCH_SIZE = 32\n",
        "PADDING_INPUT = -99999.0\n",
        "INPUT_DIM = 1024\n",
        "\n",
        "def predict(text_chunks):\n",
        "\n",
        "    global_max_len = max([len(f) for f in features])\n",
        "\n",
        "    print(f\"Padding all batches to fixed length: {global_max_len}\")\n",
        "\n",
        "    sentence_lengths = [len(f) for f in features]\n",
        "\n",
        "    def test_set_generator():\n",
        "        for i in range(len(features)):\n",
        "            yield features[i], [sentence_lengths[i]], text_chunks[i]\n",
        "\n",
        "    test_dataset = tf.data.Dataset.from_generator(\n",
        "        test_set_generator,\n",
        "        output_signature=(\n",
        "            tf.TensorSpec(shape=(None, INPUT_DIM), dtype=tf.float32),\n",
        "            tf.TensorSpec(shape=(1,), dtype=tf.int32),\n",
        "            tf.TensorSpec(shape=(), dtype=tf.string)\n",
        "        )\n",
        "    ).padded_batch(\n",
        "        BATCH_SIZE,\n",
        "        padded_shapes=(\n",
        "            [global_max_len, INPUT_DIM],\n",
        "            [1],\n",
        "            []\n",
        "        ),\n",
        "        padding_values=(PADDING_INPUT, 0, \"\")\n",
        "    )\n",
        "\n",
        "    all_predictions = []\n",
        "\n",
        "    print(\"Starting prediction...\")\n",
        "\n",
        "    for batch_x, batch_lens, batch_text in test_dataset:\n",
        "\n",
        "        batch_probs = electra_all_model.predict_on_batch(batch_x)\n",
        "        batch_pred_ids = np.argmax(batch_probs, axis=-1)\n",
        "\n",
        "        batch_probs_lc = electra_lastchar_model.predict_on_batch(batch_x)\n",
        "        batch_pred_ids_lc = np.argmax(batch_probs_lc, axis=-1)\n",
        "\n",
        "        current_batch_lengths = batch_lens.numpy().flatten()\n",
        "        batch_size_current = batch_pred_ids.shape[0]\n",
        "\n",
        "        for k in range(batch_size_current):\n",
        "\n",
        "            valid_len = current_batch_lengths[k]\n",
        "\n",
        "            current_text_str = batch_text[k].numpy().decode('utf-8')\n",
        "\n",
        "            pred_seq = batch_pred_ids[k][:valid_len]\n",
        "\n",
        "            current_text_str = current_text_str[:valid_len]\n",
        "\n",
        "            for i, char in enumerate(current_text_str):\n",
        "                if char == ' ':\n",
        "                    if i > 0:\n",
        "                        pred_seq[i - 1] = batch_pred_ids_lc[k][i - 1]\n",
        "\n",
        "            if len(current_text_str) > 0 and current_text_str[-1] != ' ':\n",
        "                pred_seq[-1] = batch_pred_ids_lc[k][valid_len - 1]\n",
        "\n",
        "            all_predictions.append(pred_seq)\n",
        "\n",
        "    return all_predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7fc4acfb-37d7-4de4-b3d2-312fdf6577a2",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-12-09T12:20:23.982493Z",
          "iopub.status.busy": "2025-12-09T12:20:23.981956Z",
          "iopub.status.idle": "2025-12-09T12:20:24.91113Z",
          "shell.execute_reply": "2025-12-09T12:20:24.910486Z",
          "shell.execute_reply.started": "2025-12-09T12:20:23.982475Z"
        },
        "id": "7fc4acfb-37d7-4de4-b3d2-312fdf6577a2",
        "outputId": "24b36530-c9bf-4e61-f329-f0a5d53cd41b",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "extracting features:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "extracting features:  50%|█████     | 1/2 [00:00<00:00,  1.70it/s]\u001b[A\n",
            "extracting features: 100%|██████████| 2/2 [00:00<00:00,  2.17it/s]\u001b[A\n"
          ]
        }
      ],
      "source": [
        "punctuation = ['.', ':', '{', '}', '[', ']', '(', ')', '؛', '«', '»', '!', '،', '؟', '-', ' ']\n",
        "features = extract_features_electra(chunks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a087e846-8394-43c3-ab62-971a014f9a95",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-12-09T12:20:57.220567Z",
          "iopub.status.busy": "2025-12-09T12:20:57.219988Z",
          "iopub.status.idle": "2025-12-09T12:20:57.638374Z",
          "shell.execute_reply": "2025-12-09T12:20:57.637828Z",
          "shell.execute_reply.started": "2025-12-09T12:20:57.22054Z"
        },
        "id": "a087e846-8394-43c3-ab62-971a014f9a95",
        "outputId": "deb9c33b-eaec-4cae-ffc2-774fe28c56e1",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Padding all batches to fixed length: 807\n",
            "Starting prediction...\n"
          ]
        }
      ],
      "source": [
        "all_predictions = predict(chunks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "834b3cbf-b688-441b-a8f9-05a4fd62c062",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-12-09T12:21:00.838428Z",
          "iopub.status.busy": "2025-12-09T12:21:00.837746Z",
          "iopub.status.idle": "2025-12-09T12:21:00.841864Z",
          "shell.execute_reply": "2025-12-09T12:21:00.841151Z",
          "shell.execute_reply.started": "2025-12-09T12:21:00.838404Z"
        },
        "id": "834b3cbf-b688-441b-a8f9-05a4fd62c062",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "results = post_process(chunks, overlaps, recovery)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e704182-cbcf-495f-8c71-61babaedc3cb",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-12-09T12:21:02.706515Z",
          "iopub.status.busy": "2025-12-09T12:21:02.705963Z",
          "iopub.status.idle": "2025-12-09T12:21:02.709913Z",
          "shell.execute_reply": "2025-12-09T12:21:02.709067Z",
          "shell.execute_reply.started": "2025-12-09T12:21:02.706492Z"
        },
        "id": "0e704182-cbcf-495f-8c71-61babaedc3cb",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "pred_diac = post_process_diacritics(all_predictions, overlaps, recovery)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37dc0fc2-5e02-4eb4-b080-6b5d238e4650",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-12-09T12:09:28.556385Z",
          "iopub.status.busy": "2025-12-09T12:09:28.556091Z",
          "iopub.status.idle": "2025-12-09T12:09:28.570463Z",
          "shell.execute_reply": "2025-12-09T12:09:28.569794Z",
          "shell.execute_reply.started": "2025-12-09T12:09:28.556367Z"
        },
        "id": "37dc0fc2-5e02-4eb4-b080-6b5d238e4650",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "predicted_text = get_finals(results, pred_diac)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1769536-700a-4df6-a9f1-56feb1c34c16",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-12-09T12:21:59.245286Z",
          "iopub.status.busy": "2025-12-09T12:21:59.245013Z",
          "iopub.status.idle": "2025-12-09T12:21:59.249279Z",
          "shell.execute_reply": "2025-12-09T12:21:59.248685Z",
          "shell.execute_reply.started": "2025-12-09T12:21:59.245264Z"
        },
        "id": "b1769536-700a-4df6-a9f1-56feb1c34c16",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "with open(f'/kaggle/input/test-set/sample_test_no_diacritics.txt', \"r\", encoding=\"utf-8\") as file:\n",
        "    lines = file.readlines()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d8e0126d-10fc-48f3-beac-e17f98a49a3f",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-12-09T12:22:53.990337Z",
          "iopub.status.busy": "2025-12-09T12:22:53.989734Z",
          "iopub.status.idle": "2025-12-09T12:22:54.001709Z",
          "shell.execute_reply": "2025-12-09T12:22:54.001132Z",
          "shell.execute_reply.started": "2025-12-09T12:22:53.990312Z"
        },
        "id": "d8e0126d-10fc-48f3-beac-e17f98a49a3f",
        "outputId": "4ad1cfb3-b8a0-4e1f-9a6e-36f220027358",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Internal Diacritic Accuracy (No Last Char): 20.44%\n"
          ]
        }
      ],
      "source": [
        "start_index = 0\n",
        "current_lines = lines\n",
        "current_preds = predicted_text\n",
        "matches = 0\n",
        "total = 0\n",
        "\n",
        "for line_str, pred_str in zip(current_lines, current_preds):\n",
        "    og_text, og_tashkeel = split_text_and_diacritics(initial_process(line_str.strip()))\n",
        "    ll, og = arabic_only_text_and_tashkeel(og_text, og_tashkeel)\n",
        "\n",
        "    pred_text, pred_tashkeel = split_text_and_diacritics(pred_str.strip())\n",
        "    _, pred = arabic_only_text_and_tashkeel(pred_text, pred_tashkeel)\n",
        "\n",
        "    for i, (char, o, p) in enumerate(zip(ll, og, pred)):\n",
        "\n",
        "        if char == ' ':\n",
        "            continue\n",
        "\n",
        "        is_last_char = (i == len(ll) - 1) or (ll[i+1] == ' ')\n",
        "\n",
        "        if not is_last_char:\n",
        "            if o == p:\n",
        "                matches += 1\n",
        "            total += 1\n",
        "\n",
        "print(f\"Internal Diacritic Accuracy (No Last Char): {matches * 100 / total:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "835ce1bc-564b-47ca-8b6a-89a374eaead4",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-12-09T12:22:54.499885Z",
          "iopub.status.busy": "2025-12-09T12:22:54.499344Z",
          "iopub.status.idle": "2025-12-09T12:22:54.504629Z",
          "shell.execute_reply": "2025-12-09T12:22:54.503929Z",
          "shell.execute_reply.started": "2025-12-09T12:22:54.499859Z"
        },
        "id": "835ce1bc-564b-47ca-8b6a-89a374eaead4",
        "outputId": "5b13023f-d7f6-497c-f5be-eee042449428",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{0: 'َ',\n",
              " 1: 'ً',\n",
              " 2: 'ُ',\n",
              " 3: 'ٌ',\n",
              " 4: 'ِ',\n",
              " 5: 'ٍ',\n",
              " 6: 'ْ',\n",
              " 7: 'ّ',\n",
              " 8: 'َّ',\n",
              " 9: 'ًّ',\n",
              " 10: 'ُّ',\n",
              " 11: 'ٌّ',\n",
              " 12: 'ِّ',\n",
              " 13: 'ٍّ',\n",
              " 14: ''}"
            ]
          },
          "execution_count": 110,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "idx2label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c895400-79fd-49f2-9b1f-906698aca7e9",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-12-09T12:22:55.357553Z",
          "iopub.status.busy": "2025-12-09T12:22:55.35694Z",
          "iopub.status.idle": "2025-12-09T12:22:55.36392Z",
          "shell.execute_reply": "2025-12-09T12:22:55.363225Z",
          "shell.execute_reply.started": "2025-12-09T12:22:55.357532Z"
        },
        "id": "3c895400-79fd-49f2-9b1f-906698aca7e9",
        "outputId": "1e4bf04e-5247-44be-b14d-098f77aa1dfb",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0, 6, 0, 4, 6, 0, 4, 14, 4, 4, 14, 6, 0, 6, 4, 0, 6, 0, 6, 0, 0, 14, 6, 0, 4, 14, 2, 0, 6, 0, 0, 0, 14, 14, 8, 6, 2, 0, 2, 0, 6, 0, 6, 2, 0, 0, 6, 1, 14, 4, 6, 14, 6, 0, 4, 14, 4, 4, 14, 2, 0, 14, 4, 4, 14, 14, 8, 6, 4, 0, 6, 0, 6, 0, 0, 14, 0, 14, 0, 0, 2, 0, 0, 14, 0, 6, 5, 14, 0, 0, 0, 4, 6, 0, 2, 0, 6, 0, 6, 2, 0, 0, 4, 14, 1, 14, 0, 4, 6, 0, 6, 0, 0, 2, 0, 6, 0, 6, 2, 0, 0, 4, 14, 1, 14, 4, 0, 6, 4, 0, 0, 14, 0, 4, 14, 6, 0, 4, 14, 4, 2, 6, 2, 6, 14, 6, 0, 14, 8, 0, 14, 6, 0, 6, 4, 6, 4, 10, 14, 14, 8, 6, 0, 14, 4, 10, 0, 2, 8, 2, 14, 6, 0, 0, 14, 0, 14, 14, 6, 0, 6, 2, 0, 6, 0, 4, 6, 0, 4, 14, 4, 4, 14, 6, 0, 6, 4, 0, 6, 0, 6, 0, 0, 14, 6, 0, 4, 14, 2, 0, 6, 0, 0, 2, 14, 14, 8, 6, 2, 0, 2, 0, 6, 0, 6, 2, 0, 0, 6, 1, 14, 4, 6, 14, 6, 0, 4, 14, 4, 4, 14, 2, 0, 14, 4, 4, 14, 14, 8, 6, 4, 0, 6, 0, 6, 0, 2, 14, 0, 14, 0, 0, 2, 0, 0, 14, 0, 6, 5, 14, 0, 0, 0, 4, 6, 0, 2, 0, 6, 0, 6, 2, 0, 0, 4, 14, 1, 14, 0, 4, 6, 0, 6, 0, 0, 2, 0, 6, 0, 6, 2, 0, 0, 4, 14, 1, 14, 4, 0, 6, 4, 0, 0, 14, 0, 4, 14, 6, 0, 4, 14, 4, 2, 6, 2, 6, 14, 6, 0, 14, 8, 0, 14, 6, 0, 6, 4, 6, 4, 10, 14, 14, 8, 6, 0, 14, 4, 10, 0, 2, 8, 2, 14, 6, 0, 0, 14, 0, 14, 14, 6, 0, 6, 2, 0, 6, 0, 4, 6, 0, 4, 14, 4, 4, 14, 6, 0, 6, 4, 0, 6, 0, 6, 0, 0, 14, 6, 0, 4, 14, 2, 0, 6, 0, 0, 0, 14, 14, 8, 6, 2, 0, 2, 0, 6, 0, 6, 2, 0, 0, 6, 1, 14, 4, 0, 14, 6, 0, 4, 14, 4, 4, 14, 2, 0, 14, 4, 4, 14, 14, 8, 6, 4, 0, 6, 0, 6, 0, 2, 14, 0, 14, 0, 0, 2, 0, 0, 14, 0, 6, 5, 14, 4, 0, 0, 4, 6, 0, 2, 0, 6, 0, 6, 2, 0, 0, 4, 14, 1, 14, 0, 4, 6, 0, 6, 0, 0, 2, 0, 6, 0, 6, 2, 0, 0, 4, 14, 1, 14, 4, 0, 6, 4, 0, 0, 14, 0, 4, 14, 6, 0, 4, 14, 4, 2, 6, 2, 6, 14, 6, 0, 14, 8, 0, 14, 6, 0, 6, 4, 6, 4, 10, 14, 14, 8, 6, 0, 14, 4, 10, 0, 2, 8, 2, 14, 6, 0, 0, 14, 0, 14, 14, 6, 0, 6, 2, 0, 6, 0, 4, 6, 0, 4, 14, 4, 4, 14, 6, 0, 6, 4, 0, 6, 0, 6, 0, 0, 14, 6, 0, 4, 14, 2, 0, 6, 0, 0, 0, 14, 14, 8, 6, 2, 0, 2, 0, 6, 0, 6, 2, 0, 0, 6, 1, 14, 4, 6, 14, 6, 0, 4, 14, 4, 4, 14, 2, 0, 14, 4, 4, 14, 14, 8, 6, 4, 0, 6, 2, 6, 0, 2, 0, 0, 14, 0, 0, 2, 0, 0, 14, 0, 6, 5, 14, 0, 0, 0, 4, 6, 0, 2, 0, 6, 0, 6, 2, 0, 0, 4, 14, 1, 14, 0, 4, 6, 0, 6, 0, 0, 2, 0, 6, 0, 6, 2, 0, 0, 4, 14, 1, 14, 4, 0, 6, 4, 0, 0, 14, 0, 4, 14, 6, 0, 4, 14, 4, 2, 6, 2, 6, 14, 6, 0, 14, 8, 0, 14, 6, 0, 6, 4, 6, 4, 10, 14, 14, 8, 6, 0, 14, 4, 10, 0, 2, 8, 2, 14, 6, 0, 0, 14, 0, 14, 14, 6, 0, 6, 2, 0, 6, 0, 4, 6, 0, 4, 14, 4, 4, 14, 6, 0, 6, 4, 0, 6, 0, 6, 0, 0, 14, 6, 0, 4, 14, 0, 0, 6, 0, 0, 0, 14, 14, 8, 6, 0, 0, 2, 0, 6, 0, 6, 2, 0, 0, 6, 1, 14, 4, 6, 14, 6, 0, 4, 14, 4, 4, 14, 2, 0, 14, 4, 4, 14, 14, 8, 6, 4, 0, 6, 0, 6, 0, 2, 14, 0, 14, 0, 0, 2, 0, 0, 14, 0, 6, 5, 14, 0, 0, 0, 4, 6, 0, 2, 0, 6, 0, 6, 2, 0, 0, 4, 14, 1, 14, 0, 4, 6, 0, 6, 0, 0, 2, 0, 6, 0, 6, 2, 0, 0, 4, 14, 1, 14, 4, 0, 6, 4, 0, 0, 14, 0, 4, 14, 6, 0, 4, 14, 4, 2, 6, 2, 6, 14, 6, 0, 14, 8, 0, 14, 6, 0, 6, 4, 6, 4, 10, 14, 14, 8, 6, 0, 14, 4, 10, 0, 2, 8, 2, 14, 6, 0, 0, 14, 0, 14, 14, 6, 0, 6, 2]\n"
          ]
        }
      ],
      "source": [
        "start_index = 0\n",
        "current_lines = lines\n",
        "current_preds = pred_diac\n",
        "matches = 0\n",
        "total = 0\n",
        "\n",
        "for line_str, pred_label in zip(current_lines, current_preds):\n",
        "    cleaned = initial_process(line_str.strip())\n",
        "    new_sent, pred = arabic_only_text_and_tashkeel_no_spaces(cleaned, pred_label)\n",
        "    print(pred)\n",
        "\n",
        "# print(f\"Internal Diacritic Accuracy (No Last Char): {matches * 100 / total:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1263b7ea-7a00-46e6-a415-bde7ab9d5177",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-12-09T12:22:58.549303Z",
          "iopub.status.busy": "2025-12-09T12:22:58.549019Z",
          "iopub.status.idle": "2025-12-09T12:22:58.554503Z",
          "shell.execute_reply": "2025-12-09T12:22:58.553869Z",
          "shell.execute_reply.started": "2025-12-09T12:22:58.54928Z"
        },
        "id": "1263b7ea-7a00-46e6-a415-bde7ab9d5177",
        "outputId": "511c1dd4-3238-438a-fe2b-952db7f01262",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "910"
            ]
          },
          "execution_count": 112,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e534a62f-ba0c-48dc-b5c7-ab6266ed7827",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-12-09T12:09:28.638906Z",
          "iopub.status.busy": "2025-12-09T12:09:28.638695Z",
          "iopub.status.idle": "2025-12-09T12:09:28.64989Z",
          "shell.execute_reply": "2025-12-09T12:09:28.649224Z",
          "shell.execute_reply.started": "2025-12-09T12:09:28.638891Z"
        },
        "id": "e534a62f-ba0c-48dc-b5c7-ab6266ed7827",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "42098910-a2d8-47bb-a7cc-54db29dda8a8",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-12-09T12:09:28.650698Z",
          "iopub.status.busy": "2025-12-09T12:09:28.650475Z",
          "iopub.status.idle": "2025-12-09T12:09:28.665743Z",
          "shell.execute_reply": "2025-12-09T12:09:28.665134Z",
          "shell.execute_reply.started": "2025-12-09T12:09:28.650677Z"
        },
        "id": "42098910-a2d8-47bb-a7cc-54db29dda8a8",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "table = pd.read_csv('/kaggle/input/gold-test/sample_test_set_gold.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa984914-f241-4202-87a7-dc679f31169d",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-12-09T12:09:28.666597Z",
          "iopub.status.busy": "2025-12-09T12:09:28.666386Z",
          "iopub.status.idle": "2025-12-09T12:09:28.671879Z",
          "shell.execute_reply": "2025-12-09T12:09:28.671275Z",
          "shell.execute_reply.started": "2025-12-09T12:09:28.666573Z"
        },
        "id": "fa984914-f241-4202-87a7-dc679f31169d",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "to_compare = table['label'].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e595b3a6-65d4-4391-b1cc-9ea6d05b6bb9",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-12-09T12:09:28.672702Z",
          "iopub.status.busy": "2025-12-09T12:09:28.672491Z",
          "iopub.status.idle": "2025-12-09T12:09:28.684022Z",
          "shell.execute_reply": "2025-12-09T12:09:28.683344Z",
          "shell.execute_reply.started": "2025-12-09T12:09:28.672678Z"
        },
        "id": "e595b3a6-65d4-4391-b1cc-9ea6d05b6bb9",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "matches = sum(og == pr for og, pr in zip(to_compare, pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8f852d5-115b-4ccf-b0ad-a1bc2ee7d44d",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-12-09T12:09:28.6849Z",
          "iopub.status.busy": "2025-12-09T12:09:28.68465Z",
          "iopub.status.idle": "2025-12-09T12:09:28.696751Z",
          "shell.execute_reply": "2025-12-09T12:09:28.69612Z",
          "shell.execute_reply.started": "2025-12-09T12:09:28.684884Z"
        },
        "id": "e8f852d5-115b-4ccf-b0ad-a1bc2ee7d44d",
        "outputId": "1981e33b-4a53-4e58-c7ad-976641ffb737",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "182"
            ]
          },
          "execution_count": 86,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "matches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2586af94-3034-45e6-88d6-83efe209b329",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-12-09T12:09:39.723365Z",
          "iopub.status.busy": "2025-12-09T12:09:39.722443Z",
          "iopub.status.idle": "2025-12-09T12:09:39.727769Z",
          "shell.execute_reply": "2025-12-09T12:09:39.727194Z",
          "shell.execute_reply.started": "2025-12-09T12:09:39.723337Z"
        },
        "id": "2586af94-3034-45e6-88d6-83efe209b329",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "table['pred'] = pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "058a55c2-38cf-4158-8a2f-f901c517868b",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-12-09T12:09:40.03444Z",
          "iopub.status.busy": "2025-12-09T12:09:40.03395Z",
          "iopub.status.idle": "2025-12-09T12:09:40.041038Z",
          "shell.execute_reply": "2025-12-09T12:09:40.040285Z",
          "shell.execute_reply.started": "2025-12-09T12:09:40.034424Z"
        },
        "id": "058a55c2-38cf-4158-8a2f-f901c517868b",
        "outputId": "c5422ca3-0f44-438d-f37b-c4dc820b399e",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>label</th>\n",
              "      <th>pred</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [ID, label, pred]\n",
              "Index: []"
            ]
          },
          "execution_count": 88,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "table[table['pred'] != table['label']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c581d83-9c74-4f64-a5c9-fb4c712a8046",
      "metadata": {
        "id": "7c581d83-9c74-4f64-a5c9-fb4c712a8046",
        "trusted": true
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "full_pipeline",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "datasetId": 8855126,
          "sourceId": 13898942,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 8861767,
          "sourceId": 13908408,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 8916698,
          "sourceId": 13989718,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 8943213,
          "sourceId": 14047777,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 8943230,
          "sourceId": 14047800,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 8958050,
          "sourceId": 14072827,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 8958271,
          "sourceId": 14073120,
          "sourceType": "datasetVersion"
        },
        {
          "isSourceIdPinned": true,
          "modelId": 525712,
          "modelInstanceId": 511023,
          "sourceId": 674220,
          "sourceType": "modelInstanceVersion"
        },
        {
          "isSourceIdPinned": true,
          "modelId": 526936,
          "modelInstanceId": 512293,
          "sourceId": 675738,
          "sourceType": "modelInstanceVersion"
        },
        {
          "isSourceIdPinned": true,
          "modelId": 527061,
          "modelInstanceId": 512419,
          "sourceId": 675905,
          "sourceType": "modelInstanceVersion"
        },
        {
          "isSourceIdPinned": true,
          "modelId": 528054,
          "modelInstanceId": 513419,
          "sourceId": 677088,
          "sourceType": "modelInstanceVersion"
        },
        {
          "isSourceIdPinned": true,
          "modelId": 528434,
          "modelInstanceId": 513795,
          "sourceId": 677554,
          "sourceType": "modelInstanceVersion"
        },
        {
          "isSourceIdPinned": true,
          "modelId": 528556,
          "modelInstanceId": 513917,
          "sourceId": 677697,
          "sourceType": "modelInstanceVersion"
        }
      ],
      "dockerImageVersionId": 31192,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "project (3.12.3)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
