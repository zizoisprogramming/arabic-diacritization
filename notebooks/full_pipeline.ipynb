{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 13898942,
          "sourceType": "datasetVersion",
          "datasetId": 8855126
        },
        {
          "sourceId": 13908408,
          "sourceType": "datasetVersion",
          "datasetId": 8861767
        },
        {
          "sourceId": 13989718,
          "sourceType": "datasetVersion",
          "datasetId": 8916698
        },
        {
          "sourceId": 14047777,
          "sourceType": "datasetVersion",
          "datasetId": 8943213
        },
        {
          "sourceId": 14047800,
          "sourceType": "datasetVersion",
          "datasetId": 8943230
        },
        {
          "sourceId": 674220,
          "sourceType": "modelInstanceVersion",
          "isSourceIdPinned": true,
          "modelInstanceId": 511023,
          "modelId": 525712
        },
        {
          "sourceId": 675738,
          "sourceType": "modelInstanceVersion",
          "isSourceIdPinned": true,
          "modelInstanceId": 512293,
          "modelId": 526936
        }
      ],
      "dockerImageVersionId": 31192,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "full_pipeline",
      "provenance": []
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "id": "4943355d",
      "cell_type": "code",
      "source": [
        "!pip install -q \"protobuf==3.20.*\"\n",
        "!pip install -q transformers arabert preprocess"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-07T20:21:53.844987Z",
          "iopub.execute_input": "2025-12-07T20:21:53.845666Z",
          "iopub.status.idle": "2025-12-07T20:22:00.318556Z",
          "shell.execute_reply.started": "2025-12-07T20:21:53.845643Z",
          "shell.execute_reply": "2025-12-07T20:22:00.317819Z"
        },
        "id": "4943355d",
        "outputId": "ae2f681a-201b-48fe-f1eb-25c0e350dfd1"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "id": "aa5539c4-c043-4558-aca6-57945fc29458",
      "cell_type": "code",
      "source": [
        "import re\n",
        "import pickle\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import itertools\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from arabert.preprocess import ArabertPreprocessor"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-07T20:22:00.320036Z",
          "iopub.execute_input": "2025-12-07T20:22:00.320327Z",
          "iopub.status.idle": "2025-12-07T20:22:00.325052Z",
          "shell.execute_reply.started": "2025-12-07T20:22:00.320296Z",
          "shell.execute_reply": "2025-12-07T20:22:00.324449Z"
        },
        "id": "aa5539c4-c043-4558-aca6-57945fc29458"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "0c247254",
      "cell_type": "markdown",
      "source": [
        "# Utils"
      ],
      "metadata": {
        "id": "0c247254"
      }
    },
    {
      "id": "38777fe6",
      "cell_type": "code",
      "source": [
        "char2idx_path = '/kaggle/input/arabicia-3/char2idx.json'\n",
        "arabic_letters_map = '/kaggle/input/arabic-letters-map/arabic_letters.pickle'\n",
        "model_path = '/kaggle/input/arabic-diacritizer-residual/keras/1/1/model_with_features_v2_res.keras'\n",
        "char_embeddings_path = '/kaggle/input/embeddings-chars/keras/default/1/embedding_matrix(1).npy'"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-07T20:22:00.325802Z",
          "iopub.execute_input": "2025-12-07T20:22:00.326058Z",
          "iopub.status.idle": "2025-12-07T20:22:00.343097Z",
          "shell.execute_reply.started": "2025-12-07T20:22:00.326037Z",
          "shell.execute_reply": "2025-12-07T20:22:00.342526Z"
        },
        "id": "38777fe6"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "2a82bd59",
      "cell_type": "code",
      "source": [
        "def get_diacritics_map():\n",
        "    # with open(diacritic2id_path, 'r', encoding='utf-8') as f:\n",
        "    #     diacritic2id = json.load(f)\n",
        "    diacritic2id = {\n",
        "        \"َ\": 0,\n",
        "        \"ً\": 1,\n",
        "        \"ُ\": 2,\n",
        "        \"ٌ\": 3,\n",
        "        \"ِ\": 4,\n",
        "        \"ٍ\": 5,\n",
        "        \"ْ\": 6,\n",
        "        \"ّ\": 7,\n",
        "        \"َّ\": 8,\n",
        "        \"ًّ\": 9,\n",
        "        \"ُّ\": 10,\n",
        "        \"ٌّ\": 11,\n",
        "        \"ِّ\": 12,\n",
        "        \"ٍّ\": 13,\n",
        "        \"\": 14\n",
        "    }\n",
        "    idx2label = {v: k for k, v in diacritic2id.items()}\n",
        "\n",
        "    return diacritic2id, idx2label\n",
        "\n",
        "def get_char_map():\n",
        "    with open(char2idx_path, 'r', encoding='utf-8') as f:\n",
        "        char2idx = json.load(f)\n",
        "    for key, value in char2idx.items():\n",
        "        if value != 0:\n",
        "            char2idx[key] = value - 1\n",
        "    idx2char = {k : v for v, k in char2idx.items()}\n",
        "\n",
        "    return char2idx, idx2char"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-07T20:22:00.344669Z",
          "iopub.execute_input": "2025-12-07T20:22:00.344889Z",
          "iopub.status.idle": "2025-12-07T20:22:00.358344Z",
          "shell.execute_reply.started": "2025-12-07T20:22:00.344866Z",
          "shell.execute_reply": "2025-12-07T20:22:00.357815Z"
        },
        "id": "2a82bd59"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "4c9f6658",
      "cell_type": "code",
      "source": [
        "def get_arabic_characters():\n",
        "    with open(arabic_letters_map, 'rb') as f:\n",
        "        arabic_letters = pickle.load(f)\n",
        "    return arabic_letters"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-07T20:22:00.359019Z",
          "iopub.execute_input": "2025-12-07T20:22:00.359348Z",
          "iopub.status.idle": "2025-12-07T20:22:00.381061Z",
          "shell.execute_reply.started": "2025-12-07T20:22:00.359323Z",
          "shell.execute_reply": "2025-12-07T20:22:00.380463Z"
        },
        "id": "4c9f6658"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "4b97c37b-d9e7-448a-bad3-85cbe4501b14",
      "cell_type": "code",
      "source": [
        "char2idx, idx2char = get_char_map()\n",
        "diacritic2id, idx2label = get_diacritics_map()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-07T20:22:00.381721Z",
          "iopub.execute_input": "2025-12-07T20:22:00.381966Z",
          "iopub.status.idle": "2025-12-07T20:22:00.402804Z",
          "shell.execute_reply.started": "2025-12-07T20:22:00.381951Z",
          "shell.execute_reply": "2025-12-07T20:22:00.402214Z"
        },
        "id": "4b97c37b-d9e7-448a-bad3-85cbe4501b14"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "bfadf730",
      "cell_type": "markdown",
      "source": [
        "# Preprocessing"
      ],
      "metadata": {
        "id": "bfadf730"
      }
    },
    {
      "id": "3576806d",
      "cell_type": "code",
      "source": [
        "DIACRITICS_PATTERN = re.compile(r'[\\u064B-\\u0652]')"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-07T20:22:00.403439Z",
          "iopub.execute_input": "2025-12-07T20:22:00.403689Z",
          "iopub.status.idle": "2025-12-07T20:22:00.409348Z",
          "shell.execute_reply.started": "2025-12-07T20:22:00.403667Z",
          "shell.execute_reply": "2025-12-07T20:22:00.408644Z"
        },
        "id": "3576806d"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "1e3041bf",
      "cell_type": "code",
      "source": [
        "def split_text_and_diacritics(text):\n",
        "\n",
        "    letters = []\n",
        "    labels = []\n",
        "\n",
        "    i = 0\n",
        "    while i < len(text):\n",
        "        char = text[i]\n",
        "\n",
        "        if DIACRITICS_PATTERN.match(char):\n",
        "            if labels:\n",
        "                labels[-1] += char\n",
        "        else:\n",
        "            letters.append(char)\n",
        "            labels.append(\"\")\n",
        "\n",
        "        i += 1\n",
        "\n",
        "    return \"\".join(letters), labels"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-07T20:22:00.410002Z",
          "iopub.execute_input": "2025-12-07T20:22:00.410259Z",
          "iopub.status.idle": "2025-12-07T20:22:00.426329Z",
          "shell.execute_reply.started": "2025-12-07T20:22:00.41023Z",
          "shell.execute_reply": "2025-12-07T20:22:00.425657Z"
        },
        "id": "1e3041bf"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "475e996f",
      "cell_type": "code",
      "source": [
        "numeric_pattern = r\"\\(\\s*\\d+\\s*/\\s*\\d+\\s*\\)\"\n",
        "english = r\"[a-zA-Z]\"\n",
        "numbers = r\"\\s*\\d+\\s*\"\n",
        "numering_items = r\"\\s*\\d+\\s*[-]\\s*\"\n",
        "empty_brackets = r'\\(\\s*\\)|\\[\\s*\\]|\\{\\s*\\}|<<\\s*>>|\"\\s*\"|\\'\\s*\\''\n",
        "\n",
        "def clean_punctuation_sequence(text):\n",
        "    collapsible = re.escape(\".,:;!?'\\\"/،؛؟\")\n",
        "    pattern = rf\"([{collapsible}])(?:\\s*\\1)+\"\n",
        "\n",
        "    return re.sub(pattern, r\"\\1\", text)\n",
        "\n",
        "def remove_unbalanced_brackets(text):\n",
        "    pair_map = {')': '(', '}': '{', ']': '[', '>':'<', '»': '«', '\"':'\"', \"'\":\"'\"}\n",
        "    openers = set(['(', '{', '[', '<', '«', '\"', \"'\"])\n",
        "\n",
        "    stack = []\n",
        "    indices_to_remove = set()\n",
        "\n",
        "    for i, char in enumerate(text):\n",
        "        if char in openers:\n",
        "            stack.append((char, i))\n",
        "\n",
        "        elif char in pair_map:\n",
        "            if stack:\n",
        "                last_opener, _ = stack[-1]\n",
        "                if last_opener == pair_map[char]:\n",
        "                    stack.pop()\n",
        "                else:\n",
        "                    indices_to_remove.add(i)\n",
        "            else:\n",
        "                indices_to_remove.add(i)\n",
        "\n",
        "    for char, index in stack:\n",
        "        indices_to_remove.add(index)\n",
        "\n",
        "    return \"\".join([char for i, char in enumerate(text) if i not in indices_to_remove])\n",
        "\n",
        "\n",
        "def initial_process(line):\n",
        "    res = re.sub(numering_items, '', line)\n",
        "    res = re.sub(numeric_pattern, '', res)\n",
        "    res = re.sub(english, ' ', res)\n",
        "    res = re.sub(numbers, '', res)\n",
        "    res = re.sub(empty_brackets, '', res)\n",
        "    res = re.sub(',', '،', res)\n",
        "    res = re.sub(';', '؛', res)\n",
        "    res = re.sub(r'\\?', '؟', res)\n",
        "    res = re.sub(r'/', '', res)\n",
        "    res = re.sub(r'\\*', '', res)\n",
        "    res = re.sub(r'–', '-', res)\n",
        "    res = res.replace('\\u200f', '')\n",
        "\n",
        "\n",
        "    res = clean_punctuation_sequence(res)\n",
        "\n",
        "    res = remove_unbalanced_brackets(res)\n",
        "\n",
        "    res = re.sub(r\"\\s+\", \" \", res).strip()\n",
        "\n",
        "    return res\n",
        "\n",
        "\n",
        "def split_citations_raw(line):\n",
        "    qal_list = [\n",
        "        \"قال\", \"قالت\", \"قالوا\", \"قلت\", \"قلنا\",\n",
        "        \"أقول\", \"يقول\", \"يقولون\", \"قيل\", \"يقال\"\n",
        "    ]\n",
        "\n",
        "    qal_regex = \"|\".join(qal_list)\n",
        "\n",
        "    qal_with_colon = rf\"(?:{qal_regex})\\s*[:：]\"\n",
        "\n",
        "\n",
        "    qawloho_regex = r\"(?:و|ف)?قول(?:ه)?(?:\\s*تعالى)?\"\n",
        "\n",
        "    trigger = rf\"({qal_with_colon}|{qawloho_regex})\"\n",
        "\n",
        "    final_lines = []\n",
        "    matches = list(re.finditer(trigger, line))\n",
        "\n",
        "    if not matches:\n",
        "        final_lines.append(line.strip())\n",
        "    else:\n",
        "        last_idx = 0\n",
        "        for m in matches:\n",
        "            start = m.start()\n",
        "            if line[last_idx:start]:\n",
        "                final_lines.append(line[last_idx:start])\n",
        "            last_idx = start\n",
        "\n",
        "        final_lines.append(line[last_idx:])\n",
        "\n",
        "    return final_lines\n",
        "\n",
        "def slide_window_raw(text, overlap=50, max_len=807):\n",
        "    if len(text) <= max_len:\n",
        "        return [text], [0]\n",
        "\n",
        "    chunks = []\n",
        "    overlaps = []\n",
        "\n",
        "    chunks.append(text[:max_len])\n",
        "    overlaps.append(0)\n",
        "\n",
        "    current_start = 0\n",
        "    text_len = len(text)\n",
        "\n",
        "    while True:\n",
        "        ideal_stride = max_len - overlap\n",
        "\n",
        "        ideal_next_start = current_start + ideal_stride\n",
        "\n",
        "        if ideal_next_start >= text_len:\n",
        "            break\n",
        "\n",
        "        found_next_start = -1\n",
        "\n",
        "        search_limit = current_start\n",
        "\n",
        "        for i in range(ideal_next_start, search_limit, -1):\n",
        "            if i < text_len and text[i] == ' ':\n",
        "                found_next_start = i + 1\n",
        "                break\n",
        "\n",
        "        if found_next_start == -1:\n",
        "            found_next_start = ideal_next_start\n",
        "\n",
        "        actual_overlap = (current_start + max_len) - found_next_start\n",
        "\n",
        "        if actual_overlap < 0:\n",
        "            actual_overlap = 0\n",
        "\n",
        "        next_chunk = text[found_next_start : found_next_start + max_len]\n",
        "\n",
        "        chunks.append(next_chunk)\n",
        "        overlaps.append(actual_overlap)\n",
        "\n",
        "        current_start = found_next_start\n",
        "\n",
        "        if current_start + max_len >= text_len:\n",
        "            break\n",
        "\n",
        "    return chunks, overlaps\n",
        "\n",
        "\n",
        "def prepare_for_predict():\n",
        "    all_recovery = []\n",
        "    assertions_text = []\n",
        "    assertions_tashkeel = []\n",
        "    test = False\n",
        "    curr_chunks = []\n",
        "    curr_overlaps = []\n",
        "\n",
        "    with open('/kaggle/input/val-only/val.txt', \"r\", encoding=\"utf-8\") as file:\n",
        "\n",
        "        for line in file:\n",
        "\n",
        "            cleaned = initial_process(line.strip())\n",
        "            if test == True:\n",
        "                assertions_text.append(cleaned)\n",
        "                line = cleaned\n",
        "            else:\n",
        "                line, tashkeel = split_text_and_diacritics(cleaned)\n",
        "                assertions_text.append(line)\n",
        "                assertions_tashkeel.append(tashkeel)\n",
        "\n",
        "            raw_segments = split_citations_raw(line)\n",
        "            recovery = []\n",
        "\n",
        "            for seg in raw_segments:\n",
        "                t_chunks, t_overlaps = slide_window_raw(seg, overlap=50, max_len=807)\n",
        "                assert len(t_chunks) == len(t_overlaps), print(len(t_chunks), len(t_overlaps))\n",
        "\n",
        "                for i, chunk in enumerate(t_chunks):\n",
        "                    recovery.append(i)\n",
        "                    curr_chunks.append(chunk)\n",
        "\n",
        "                curr_overlaps.extend(t_overlaps)\n",
        "            all_recovery.append(recovery)\n",
        "\n",
        "    print(f\"Generated {len(curr_chunks)} chunks.\")\n",
        "    return curr_chunks, curr_overlaps, all_recovery, assertions_text, assertions_tashkeel"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-07T20:22:00.427086Z",
          "iopub.execute_input": "2025-12-07T20:22:00.427333Z",
          "iopub.status.idle": "2025-12-07T20:22:00.446647Z",
          "shell.execute_reply.started": "2025-12-07T20:22:00.427318Z",
          "shell.execute_reply": "2025-12-07T20:22:00.446102Z"
        },
        "id": "475e996f"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "bdf5e723-557b-4b88-8ea2-fe7fd298194c",
      "cell_type": "code",
      "source": [
        "chunks, overlaps, recovery, assertions_text, assertions_tashkeel = prepare_for_predict()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-07T20:22:00.449297Z",
          "iopub.execute_input": "2025-12-07T20:22:00.449546Z",
          "iopub.status.idle": "2025-12-07T20:22:01.285163Z",
          "shell.execute_reply.started": "2025-12-07T20:22:00.449532Z",
          "shell.execute_reply": "2025-12-07T20:22:01.284461Z"
        },
        "id": "bdf5e723-557b-4b88-8ea2-fe7fd298194c",
        "outputId": "60a40798-6cd4-41ab-98d3-0f5325a43d43"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Generated 4277 chunks.\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "id": "72140541",
      "cell_type": "markdown",
      "source": [
        "# Post Processing"
      ],
      "metadata": {
        "id": "72140541"
      }
    },
    {
      "id": "7c88d970",
      "cell_type": "code",
      "source": [
        "def reconstruct_text_window(chunks, overlaps):\n",
        "    if not chunks:\n",
        "        return \"\"\n",
        "\n",
        "    reconstructed_parts = []\n",
        "\n",
        "    for chunk, ov in zip(chunks[0:], overlaps):\n",
        "        reconstructed_parts.append(chunk[ov:])\n",
        "\n",
        "    return \"\".join(reconstructed_parts)\n",
        "\n",
        "\n",
        "def arabic_only_text_and_tashkeel(text, tashkeel):\n",
        "    ARABIC_CHARS = get_arabic_characters()\n",
        "    return \"\".join([char for char in text if char in ARABIC_CHARS]), [tashkeel[i] for i, char in enumerate(text) if char in ARABIC_CHARS]\n",
        "\n",
        "def post_process(chunks, overlaps, recovery):\n",
        "    results = []\n",
        "    start_chnk_idx = 0\n",
        "    end_chnk_idx = 0\n",
        "\n",
        "    for i in range(len(recovery)):\n",
        "        zero_before = False\n",
        "        res = ''\n",
        "        for j in recovery[i]:\n",
        "            if j == 0:\n",
        "                if zero_before:\n",
        "                    res += reconstruct_text_window(chunks[start_chnk_idx:end_chnk_idx + 1], overlaps[start_chnk_idx:end_chnk_idx + 1])\n",
        "                    start_chnk_idx = end_chnk_idx + 1\n",
        "                    end_chnk_idx += 1\n",
        "                zero_before = True\n",
        "            else:\n",
        "                end_chnk_idx += 1\n",
        "\n",
        "        res += reconstruct_text_window(chunks[start_chnk_idx:end_chnk_idx + 1], overlaps[start_chnk_idx:end_chnk_idx + 1])\n",
        "        start_chnk_idx = end_chnk_idx + 1\n",
        "        end_chnk_idx += 1\n",
        "        results.append(res)\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-07T20:22:01.285998Z",
          "iopub.execute_input": "2025-12-07T20:22:01.286218Z",
          "iopub.status.idle": "2025-12-07T20:22:01.293101Z",
          "shell.execute_reply.started": "2025-12-07T20:22:01.286202Z",
          "shell.execute_reply": "2025-12-07T20:22:01.292386Z"
        },
        "id": "7c88d970"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "291b7a47-3b99-4580-88f2-8ebeaf026955",
      "cell_type": "code",
      "source": [
        "def reconstruct_diacritics_window(chunks, overlaps):\n",
        "    if not chunks:\n",
        "        return np.array([])\n",
        "\n",
        "    reconstructed_parts = []\n",
        "\n",
        "    for chunk, ov in zip(chunks, overlaps):\n",
        "        reconstructed_parts.append(chunk[ov:])\n",
        "\n",
        "    return np.concatenate(reconstructed_parts)\n",
        "\n",
        "\n",
        "def post_process_diacritics(chunks, overlaps, recovery):\n",
        "    results = []\n",
        "    start_chnk_idx = 0\n",
        "    end_chnk_idx = 0\n",
        "\n",
        "    for i in range(len(recovery)):\n",
        "        zero_before = False\n",
        "\n",
        "        res = np.array([], dtype=int)\n",
        "\n",
        "        for j in recovery[i]:\n",
        "            if j == 0:\n",
        "                if zero_before:\n",
        "                    segment = reconstruct_diacritics_window(\n",
        "                        chunks[start_chnk_idx : end_chnk_idx + 1],\n",
        "                        overlaps[start_chnk_idx : end_chnk_idx + 1]\n",
        "                    )\n",
        "                    res = np.concatenate([res, segment])\n",
        "\n",
        "                    start_chnk_idx = end_chnk_idx + 1\n",
        "                    end_chnk_idx += 1\n",
        "                zero_before = True\n",
        "            else:\n",
        "                end_chnk_idx += 1\n",
        "\n",
        "        segment = reconstruct_diacritics_window(\n",
        "            chunks[start_chnk_idx : end_chnk_idx + 1],\n",
        "            overlaps[start_chnk_idx : end_chnk_idx + 1]\n",
        "        )\n",
        "        res = np.concatenate([res, segment])\n",
        "\n",
        "        start_chnk_idx = end_chnk_idx + 1\n",
        "        end_chnk_idx += 1\n",
        "\n",
        "        results.append(res)\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-07T20:22:01.294508Z",
          "iopub.execute_input": "2025-12-07T20:22:01.294697Z",
          "iopub.status.idle": "2025-12-07T20:22:01.31379Z",
          "shell.execute_reply.started": "2025-12-07T20:22:01.294681Z",
          "shell.execute_reply": "2025-12-07T20:22:01.313226Z"
        },
        "id": "291b7a47-3b99-4580-88f2-8ebeaf026955"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "70f52a9d-ef07-4ffc-aa7b-01a70eee1860",
      "cell_type": "code",
      "source": [
        "def get_finals(results, labels, tokens=True):\n",
        "    flat_labels = list(itertools.chain.from_iterable(labels))\n",
        "    if tokens:\n",
        "        new_flat_labels = [idx2label[label] for label in flat_labels]\n",
        "    else:\n",
        "        new_flat_labels = flat_labels\n",
        "    idx = 0\n",
        "    final_results = []\n",
        "    for result in results:\n",
        "        final_str = ''\n",
        "        for char in result:\n",
        "            final_str += char + new_flat_labels[idx]\n",
        "            idx += 1\n",
        "        final_results.append(final_str)\n",
        "    return final_results"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-07T20:22:01.314538Z",
          "iopub.execute_input": "2025-12-07T20:22:01.314809Z",
          "iopub.status.idle": "2025-12-07T20:22:01.333022Z",
          "shell.execute_reply.started": "2025-12-07T20:22:01.314787Z",
          "shell.execute_reply": "2025-12-07T20:22:01.332488Z"
        },
        "id": "70f52a9d-ef07-4ffc-aa7b-01a70eee1860"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "c802d3df",
      "cell_type": "markdown",
      "source": [
        "# Extract Features"
      ],
      "metadata": {
        "id": "c802d3df"
      }
    },
    {
      "id": "c12ea8cd",
      "cell_type": "code",
      "source": [
        "\n",
        "arabert_model_name = \"aubmindlab/bert-base-arabertv02\"\n",
        "bert_tokenizer = AutoTokenizer.from_pretrained(arabert_model_name)\n",
        "bert_model = AutoModel.from_pretrained(arabert_model_name)\n",
        "bert_model.to(device)\n",
        "bert_model.eval()\n",
        "arabert_prep = ArabertPreprocessor(model_name=arabert_model_name)\n",
        "\n",
        "\n",
        "custom_char_embedding = np.load(char_embeddings_path)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def get_arabert_embeddings(sentence: str):\n",
        "\n",
        "    tokens = bert_tokenizer(sentence, return_tensors=\"pt\", truncation=True, padding=True)\n",
        "    tokens = {k: v.to(device) for k, v in tokens.items()}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = bert_model(**tokens)\n",
        "\n",
        "    emb = output.last_hidden_state.squeeze(0).cpu()\n",
        "    token_list = bert_tokenizer.convert_ids_to_tokens(tokens[\"input_ids\"][0])\n",
        "\n",
        "    return emb.numpy(), token_list\n",
        "\n",
        "\n",
        "\n",
        "def extract_custom_char_embeddings(char):\n",
        "    char2idx, _ = get_char_map()\n",
        "    return custom_char_embedding[char2idx[char]]\n",
        "\n",
        "def tokens_to_word_embeddings(tokens, embeddings):\n",
        "    word_embeddings = []\n",
        "    current_word_embs = []\n",
        "\n",
        "    for token, emb in zip(tokens, embeddings):\n",
        "        emb_tensor = torch.tensor(emb) if isinstance(emb, np.ndarray) else emb\n",
        "\n",
        "        if token.startswith(\"##\"):\n",
        "            current_word_embs.append(emb_tensor)\n",
        "        else:\n",
        "            if current_word_embs:\n",
        "                word_embeddings.append(torch.mean(torch.stack(current_word_embs), dim=0))\n",
        "            current_word_embs = [emb_tensor]\n",
        "\n",
        "    if current_word_embs:\n",
        "        word_embeddings.append(torch.mean(torch.stack(current_word_embs), dim=0))\n",
        "\n",
        "    return torch.stack(word_embeddings)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-07T20:22:01.3337Z",
          "iopub.execute_input": "2025-12-07T20:22:01.334245Z",
          "iopub.status.idle": "2025-12-07T20:22:02.204205Z",
          "shell.execute_reply.started": "2025-12-07T20:22:01.334222Z",
          "shell.execute_reply": "2025-12-07T20:22:02.203621Z"
        },
        "id": "c12ea8cd"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "6c192470",
      "cell_type": "code",
      "source": [
        "def zizo_features(sentence: str):\n",
        "\n",
        "    sentence_vec = []\n",
        "\n",
        "    arabert_emb, tokens = get_arabert_embeddings(sentence)\n",
        "    final_arabert_emb = tokens_to_word_embeddings(tokens, arabert_emb)\n",
        "\n",
        "    words_raw = sentence.split()\n",
        "    word_idx = 0\n",
        "    char_in_word_idx = 0\n",
        "\n",
        "    emb_dim = final_arabert_emb[0].shape[0]\n",
        "\n",
        "    for i, char in enumerate(sentence):\n",
        "\n",
        "        char_emb = extract_custom_char_embeddings(char)\n",
        "        char_emb_array = np.array(char_emb).flatten()\n",
        "\n",
        "        if char == ' ':\n",
        "            bert_vec = np.zeros(emb_dim)\n",
        "\n",
        "        else:\n",
        "            bert_vec = final_arabert_emb[word_idx]\n",
        "            if isinstance(bert_vec, torch.Tensor):\n",
        "                bert_vec = bert_vec.numpy()\n",
        "\n",
        "            char_in_word_idx += 1\n",
        "\n",
        "            if char_in_word_idx == len(words_raw[word_idx]):\n",
        "                word_idx += 1\n",
        "                char_in_word_idx = 0\n",
        "\n",
        "        char_vector = np.concatenate([bert_vec, char_emb_array])\n",
        "        sentence_vec.append(char_vector)\n",
        "\n",
        "    return sentence_vec\n",
        "\n",
        "\n",
        "def extract_features(sentences):\n",
        "    all_sentence_features = []\n",
        "\n",
        "    for i in tqdm(range(len(sentences)), total=len(sentences), desc=\"extracting features\"):\n",
        "        sent = sentences[i]\n",
        "        features_list = zizo_features(\"\".join(sent))\n",
        "\n",
        "        all_sentence_features.append(np.array(features_list, dtype=np.float16))\n",
        "\n",
        "    return all_sentence_features"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-07T20:22:02.204861Z",
          "iopub.execute_input": "2025-12-07T20:22:02.205037Z",
          "iopub.status.idle": "2025-12-07T20:22:02.211519Z",
          "shell.execute_reply.started": "2025-12-07T20:22:02.205022Z",
          "shell.execute_reply": "2025-12-07T20:22:02.210703Z"
        },
        "id": "6c192470"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "3cf52ca1",
      "cell_type": "markdown",
      "source": [
        "# Predict"
      ],
      "metadata": {
        "id": "3cf52ca1"
      }
    },
    {
      "id": "b99d3ec0-0608-48c7-903a-e53daae9f4ac",
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.load_model('/kaggle/input/arabic-diacritizer-residual/keras/1/1/model_with_features_v2_res.keras', compile=False)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-07T20:22:02.212158Z",
          "iopub.execute_input": "2025-12-07T20:22:02.212346Z",
          "iopub.status.idle": "2025-12-07T20:22:04.525258Z",
          "shell.execute_reply.started": "2025-12-07T20:22:02.212323Z",
          "shell.execute_reply": "2025-12-07T20:22:04.524667Z"
        },
        "id": "b99d3ec0-0608-48c7-903a-e53daae9f4ac"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "ed31e647",
      "cell_type": "code",
      "source": [
        "INTAHA = r'\\s+ا\\s*هـ?\\s+'\n",
        "BATCH_SIZE = 32\n",
        "PADDING_INPUT = -99999.0\n",
        "INPUT_DIM = 1024\n",
        "\n",
        "def predict(text_chunks):\n",
        "\n",
        "    # features = extract_features(text_chunks)\n",
        "\n",
        "\n",
        "    sentence_lengths = [len(f) for f in text_chunks]\n",
        "\n",
        "    def test_set_generator(features, lengths):\n",
        "        for i in range(len(features)):\n",
        "            yield features[i], [lengths[i]]\n",
        "\n",
        "    test_dataset = tf.data.Dataset.from_generator(\n",
        "            lambda: test_set_generator(features, sentence_lengths),\n",
        "            output_signature=(\n",
        "                tf.TensorSpec(shape=(None, INPUT_DIM), dtype=tf.float32),\n",
        "                tf.TensorSpec(shape=(1,), dtype=tf.int32)\n",
        "            )\n",
        "        ).padded_batch(BATCH_SIZE, padding_values=(PADDING_INPUT, 15))\n",
        "\n",
        "    all_predictions = []\n",
        "\n",
        "    print(\"Starting prediction...\")\n",
        "    for batch_x, batch_lens in test_dataset:\n",
        "\n",
        "        batch_probs = model.predict_on_batch(batch_x)\n",
        "\n",
        "        batch_pred_ids = np.argmax(batch_probs, axis=-1)\n",
        "\n",
        "        current_batch_lengths = batch_lens.numpy().flatten()\n",
        "\n",
        "        batch_size_current = batch_pred_ids.shape[0]\n",
        "\n",
        "        for k in range(batch_size_current):\n",
        "\n",
        "            valid_len = current_batch_lengths[k]\n",
        "            pred_seq = batch_pred_ids[k][:valid_len]\n",
        "            all_predictions.append(pred_seq)\n",
        "\n",
        "    return all_predictions"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-07T20:22:04.526079Z",
          "iopub.execute_input": "2025-12-07T20:22:04.526282Z",
          "iopub.status.idle": "2025-12-07T20:22:04.533193Z",
          "shell.execute_reply.started": "2025-12-07T20:22:04.526266Z",
          "shell.execute_reply": "2025-12-07T20:22:04.532492Z"
        },
        "id": "ed31e647"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "7fc4acfb-37d7-4de4-b3d2-312fdf6577a2",
      "cell_type": "code",
      "source": [
        "features = extract_features(chunks)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-07T20:22:04.533999Z",
          "iopub.execute_input": "2025-12-07T20:22:04.534235Z",
          "iopub.status.idle": "2025-12-07T20:28:17.616715Z",
          "shell.execute_reply.started": "2025-12-07T20:22:04.534213Z",
          "shell.execute_reply": "2025-12-07T20:28:17.61605Z"
        },
        "id": "7fc4acfb-37d7-4de4-b3d2-312fdf6577a2",
        "outputId": "7bb9f889-b6c5-4146-ed16-62a586731bd6"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "extracting features: 100%|██████████| 4277/4277 [06:13<00:00, 11.46it/s]\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "id": "a087e846-8394-43c3-ab62-971a014f9a95",
      "cell_type": "code",
      "source": [
        "all_predictions = predict(chunks)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-07T20:28:17.619013Z",
          "iopub.execute_input": "2025-12-07T20:28:17.619238Z",
          "iopub.status.idle": "2025-12-07T20:28:59.432501Z"
        },
        "id": "a087e846-8394-43c3-ab62-971a014f9a95",
        "outputId": "9ef41256-5a3d-4772-8567-5768eca978d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Starting prediction...\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "id": "834b3cbf-b688-441b-a8f9-05a4fd62c062",
      "cell_type": "code",
      "source": [
        "results = post_process(chunks, overlaps, recovery)"
      ],
      "metadata": {
        "trusted": true,
        "id": "834b3cbf-b688-441b-a8f9-05a4fd62c062"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "0e704182-cbcf-495f-8c71-61babaedc3cb",
      "cell_type": "code",
      "source": [
        "pred_diac = post_process_diacritics(all_predictions, overlaps, recovery)"
      ],
      "metadata": {
        "trusted": true,
        "id": "0e704182-cbcf-495f-8c71-61babaedc3cb"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "37dc0fc2-5e02-4eb4-b080-6b5d238e4650",
      "cell_type": "code",
      "source": [
        "predicted_text = get_finals(results, pred_diac)"
      ],
      "metadata": {
        "trusted": true,
        "id": "37dc0fc2-5e02-4eb4-b080-6b5d238e4650"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "b1769536-700a-4df6-a9f1-56feb1c34c16",
      "cell_type": "code",
      "source": [
        "with open('/kaggle/input/val-only/val.txt', \"r\", encoding=\"utf-8\") as file:\n",
        "    lines = file.readlines()"
      ],
      "metadata": {
        "trusted": true,
        "id": "b1769536-700a-4df6-a9f1-56feb1c34c16"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "d8e0126d-10fc-48f3-beac-e17f98a49a3f",
      "cell_type": "code",
      "source": [
        "start_index = 0\n",
        "current_lines = lines\n",
        "current_preds = predicted_text\n",
        "\n",
        "matches = 0\n",
        "total = 0\n",
        "\n",
        "for line_str, pred_str in zip(current_lines, current_preds):\n",
        "    og_text, og_tashkeel = split_text_and_diacritics(initial_process(line_str.strip()))\n",
        "    ll, og = arabic_only_text_and_tashkeel(og_text, og_tashkeel)\n",
        "\n",
        "    pred_text, pred_tashkeel = split_text_and_diacritics(pred_str.strip())\n",
        "    rr, pred = arabic_only_text_and_tashkeel(pred_text, pred_tashkeel)\n",
        "\n",
        "    matches += sum(o == p for o, p in zip(og, pred))\n",
        "    total += len(og)\n",
        "\n",
        "print(f\"Final acc: {matches * 100 / total:.2f}%\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "d8e0126d-10fc-48f3-beac-e17f98a49a3f"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "3c895400-79fd-49f2-9b1f-906698aca7e9",
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "3c895400-79fd-49f2-9b1f-906698aca7e9"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}