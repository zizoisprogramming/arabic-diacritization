{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4943355d",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-12-09T16:41:24.399338Z",
          "iopub.status.busy": "2025-12-09T16:41:24.399111Z",
          "iopub.status.idle": "2025-12-09T16:41:37.02373Z",
          "shell.execute_reply": "2025-12-09T16:41:37.022935Z",
          "shell.execute_reply.started": "2025-12-09T16:41:24.399315Z"
        },
        "id": "4943355d",
        "outputId": "43eb7edf-8879-4da2-8234-e70ba1e9a82b",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.1/162.1 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "bigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\n",
            "opentelemetry-proto 1.37.0 requires protobuf<7.0,>=5.0, but you have protobuf 3.20.3 which is incompatible.\n",
            "onnx 1.18.0 requires protobuf>=4.25.1, but you have protobuf 3.20.3 which is incompatible.\n",
            "a2a-sdk 0.3.10 requires protobuf>=5.29.5, but you have protobuf 3.20.3 which is incompatible.\n",
            "ray 2.51.1 requires click!=8.3.0,>=7.0, but you have click 8.3.0 which is incompatible.\n",
            "bigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\n",
            "tensorflow-metadata 1.17.2 requires protobuf>=4.25.2; python_version >= \"3.11\", but you have protobuf 3.20.3 which is incompatible.\n",
            "pydrive2 1.21.3 requires cryptography<44, but you have cryptography 46.0.3 which is incompatible.\n",
            "pydrive2 1.21.3 requires pyOpenSSL<=24.2.1,>=19.1.0, but you have pyopenssl 25.3.0 which is incompatible.\n",
            "ydf 0.13.0 requires protobuf<7.0.0,>=5.29.1, but you have protobuf 3.20.3 which is incompatible.\n",
            "grpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 3.20.3 which is incompatible.\n",
            "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2025.10.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m185.0/185.0 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q \"protobuf==3.20.*\"\n",
        "!pip install -q transformers arabert preprocess"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa5539c4-c043-4558-aca6-57945fc29458",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-12-09T16:41:37.026307Z",
          "iopub.status.busy": "2025-12-09T16:41:37.026032Z",
          "iopub.status.idle": "2025-12-09T16:42:04.817756Z",
          "shell.execute_reply": "2025-12-09T16:42:04.816912Z",
          "shell.execute_reply.started": "2025-12-09T16:41:37.026271Z"
        },
        "id": "aa5539c4-c043-4558-aca6-57945fc29458",
        "outputId": "e9ba34e1-722e-441c-b009-1fa2d19b92c4",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-09 16:41:38.717103: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1765298498.949045      47 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1765298499.022595      47 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import pickle\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import itertools\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from arabert.preprocess import ArabertPreprocessor"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c247254",
      "metadata": {
        "id": "0c247254"
      },
      "source": [
        "# Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38777fe6",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-12-09T16:42:04.81924Z",
          "iopub.status.busy": "2025-12-09T16:42:04.818634Z",
          "iopub.status.idle": "2025-12-09T16:42:04.823543Z",
          "shell.execute_reply": "2025-12-09T16:42:04.822775Z",
          "shell.execute_reply.started": "2025-12-09T16:42:04.819213Z"
        },
        "id": "38777fe6",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "char2idx_path = '/kaggle/input/arabicia-3/char2idx.json'\n",
        "arabic_letters_map = '/kaggle/input/arabic-letters-map/arabic_letters.pickle'\n",
        "# model_path = '/kaggle/input/arabic-diacritizer-residual/keras/1/1/model_with_features_v2_res.keras'\n",
        "char_embeddings_path = '/kaggle/input/embeddings-chars/keras/default/1/embedding_matrix(1).npy'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "71ee8771-13d2-4d26-9aec-0199b74076b7",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-12-09T16:42:04.825001Z",
          "iopub.status.busy": "2025-12-09T16:42:04.824686Z",
          "iopub.status.idle": "2025-12-09T16:42:04.840229Z",
          "shell.execute_reply": "2025-12-09T16:42:04.839419Z",
          "shell.execute_reply.started": "2025-12-09T16:42:04.824976Z"
        },
        "id": "71ee8771-13d2-4d26-9aec-0199b74076b7",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "test_text_path = '/kaggle/input/normal/dataset_no_diacritics.txt'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a82bd59",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-12-09T16:42:04.841358Z",
          "iopub.status.busy": "2025-12-09T16:42:04.84108Z",
          "iopub.status.idle": "2025-12-09T16:42:04.854484Z",
          "shell.execute_reply": "2025-12-09T16:42:04.853699Z",
          "shell.execute_reply.started": "2025-12-09T16:42:04.841335Z"
        },
        "id": "2a82bd59",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def get_diacritics_map():\n",
        "    # with open(diacritic2id_path, 'r', encoding='utf-8') as f:\n",
        "    #     diacritic2id = json.load(f)\n",
        "    diacritic2id = {\n",
        "        \"َ\": 0,\n",
        "        \"ً\": 1,\n",
        "        \"ُ\": 2,\n",
        "        \"ٌ\": 3,\n",
        "        \"ِ\": 4,\n",
        "        \"ٍ\": 5,\n",
        "        \"ْ\": 6,\n",
        "        \"ّ\": 7,\n",
        "        \"َّ\": 8,\n",
        "        \"ًّ\": 9,\n",
        "        \"ُّ\": 10,\n",
        "        \"ٌّ\": 11,\n",
        "        \"ِّ\": 12,\n",
        "        \"ٍّ\": 13,\n",
        "        \"\": 14\n",
        "    }\n",
        "    idx2label = {v: k for k, v in diacritic2id.items()}\n",
        "\n",
        "    return diacritic2id, idx2label\n",
        "\n",
        "def get_char_map():\n",
        "    with open(char2idx_path, 'r', encoding='utf-8') as f:\n",
        "        char2idx = json.load(f)\n",
        "    for key, value in char2idx.items():\n",
        "        if value != 0:\n",
        "            char2idx[key] = value - 1\n",
        "    idx2char = {k : v for v, k in char2idx.items()}\n",
        "\n",
        "    return char2idx, idx2char"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c9f6658",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-12-09T16:42:04.855495Z",
          "iopub.status.busy": "2025-12-09T16:42:04.85525Z",
          "iopub.status.idle": "2025-12-09T16:42:04.866192Z",
          "shell.execute_reply": "2025-12-09T16:42:04.865375Z",
          "shell.execute_reply.started": "2025-12-09T16:42:04.855479Z"
        },
        "id": "4c9f6658",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def get_arabic_characters():\n",
        "    with open(arabic_letters_map, 'rb') as f:\n",
        "        arabic_letters = pickle.load(f)\n",
        "    return arabic_letters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b97c37b-d9e7-448a-bad3-85cbe4501b14",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-12-09T16:42:04.869286Z",
          "iopub.status.busy": "2025-12-09T16:42:04.86905Z",
          "iopub.status.idle": "2025-12-09T16:42:04.889011Z",
          "shell.execute_reply": "2025-12-09T16:42:04.888272Z",
          "shell.execute_reply.started": "2025-12-09T16:42:04.869269Z"
        },
        "id": "4b97c37b-d9e7-448a-bad3-85cbe4501b14",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "char2idx, idx2char = get_char_map()\n",
        "diacritic2id, idx2label = get_diacritics_map()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bfadf730",
      "metadata": {
        "id": "bfadf730"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3576806d",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-12-09T16:42:04.890078Z",
          "iopub.status.busy": "2025-12-09T16:42:04.889821Z",
          "iopub.status.idle": "2025-12-09T16:42:04.895029Z",
          "shell.execute_reply": "2025-12-09T16:42:04.894191Z",
          "shell.execute_reply.started": "2025-12-09T16:42:04.890054Z"
        },
        "id": "3576806d",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "DIACRITICS_PATTERN = re.compile(r'[\\u064B-\\u0652]')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e3041bf",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-12-09T16:42:04.896358Z",
          "iopub.status.busy": "2025-12-09T16:42:04.896073Z",
          "iopub.status.idle": "2025-12-09T16:42:04.907724Z",
          "shell.execute_reply": "2025-12-09T16:42:04.906762Z",
          "shell.execute_reply.started": "2025-12-09T16:42:04.896334Z"
        },
        "id": "1e3041bf",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def split_text_and_diacritics(text):\n",
        "\n",
        "    letters = []\n",
        "    labels = []\n",
        "\n",
        "    i = 0\n",
        "    while i < len(text):\n",
        "        char = text[i]\n",
        "\n",
        "        if DIACRITICS_PATTERN.match(char):\n",
        "            if labels:\n",
        "                labels[-1] += char\n",
        "        else:\n",
        "            letters.append(char)\n",
        "            labels.append(\"\")\n",
        "\n",
        "        i += 1\n",
        "\n",
        "    return \"\".join(letters), labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de2291cb-493c-46f1-8467-635bb035aaea",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-12-09T16:42:04.908741Z",
          "iopub.status.busy": "2025-12-09T16:42:04.908493Z",
          "iopub.status.idle": "2025-12-09T16:42:08.285915Z",
          "shell.execute_reply": "2025-12-09T16:42:08.284869Z",
          "shell.execute_reply.started": "2025-12-09T16:42:04.908724Z"
        },
        "id": "de2291cb-493c-46f1-8467-635bb035aaea",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "!pip install -q emoji"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4dfa36b0-dc2d-400b-9590-9b613d26bcb0",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-12-09T16:42:08.28758Z",
          "iopub.status.busy": "2025-12-09T16:42:08.287209Z",
          "iopub.status.idle": "2025-12-09T16:42:08.314469Z",
          "shell.execute_reply": "2025-12-09T16:42:08.313538Z",
          "shell.execute_reply.started": "2025-12-09T16:42:08.287547Z"
        },
        "id": "4dfa36b0-dc2d-400b-9590-9b613d26bcb0",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import emoji\n",
        "import unicodedata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "475e996f",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-12-09T16:42:08.316009Z",
          "iopub.status.busy": "2025-12-09T16:42:08.315698Z",
          "iopub.status.idle": "2025-12-09T16:42:08.348076Z",
          "shell.execute_reply": "2025-12-09T16:42:08.347124Z",
          "shell.execute_reply.started": "2025-12-09T16:42:08.315983Z"
        },
        "id": "475e996f",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "numeric_pattern = r\"\\(\\s*\\d+\\s*/\\s*\\d+\\s*\\)\"\n",
        "english = r\"[a-zA-Z]\"\n",
        "numbers = r\"\\s*\\d+\\s*\"\n",
        "numering_items = r\"\\s*\\d+\\s*[-]\\s*\"\n",
        "empty_brackets = r'\\(\\s*\\)|\\[\\s*\\]|\\{\\s*\\}|<<\\s*>>|\"\\s*\"|\\'\\s*\\''\n",
        "\n",
        "\n",
        "def clean_punctuation_sequence(text):\n",
        "    collapsible = re.escape(\".,:;!?'\\\"/،؛؟\")\n",
        "    pattern = rf\"([{collapsible}])(?:\\s*\\1)+\"\n",
        "\n",
        "    return re.sub(pattern, r\"\\1\", text)\n",
        "\n",
        "def remove_emojis(text):\n",
        "    # replace_emoji removes emojis. replace='' effectively deletes them.\n",
        "    return emoji.replace_emoji(text, replace='')\n",
        "\n",
        "\n",
        "def remove_unbalanced_brackets(text):\n",
        "    pair_map = {')': '(', '}': '{', ']': '[', '>':'<', '»': '«', '\"':'\"', \"'\":\"'\"}\n",
        "    openers = set(['(', '{', '[', '<', '«', '\"', \"'\"])\n",
        "\n",
        "    stack = []\n",
        "    indices_to_remove = set()\n",
        "\n",
        "    for i, char in enumerate(text):\n",
        "        if char in openers:\n",
        "            stack.append((char, i))\n",
        "\n",
        "        elif char in pair_map:\n",
        "            if stack:\n",
        "                last_opener, _ = stack[-1]\n",
        "                if last_opener == pair_map[char]:\n",
        "                    stack.pop()\n",
        "                else:\n",
        "                    indices_to_remove.add(i)\n",
        "            else:\n",
        "                indices_to_remove.add(i)\n",
        "\n",
        "    for char, index in stack:\n",
        "        indices_to_remove.add(index)\n",
        "\n",
        "    return \"\".join([char for i, char in enumerate(text) if i not in indices_to_remove])\n",
        "\n",
        "def remove_formatting_codes(text):\n",
        "\n",
        "    return \"\".join(ch for ch in text\n",
        "                   if unicodedata.category(ch) != \"Cf\"\n",
        "                   and unicodedata.category(ch) != \"No\")\n",
        "\n",
        "def initial_process(line):\n",
        "    res = re.sub(numering_items, '', line)\n",
        "    res = re.sub(numeric_pattern, '', res)\n",
        "    res = re.sub(english, ' ', res)\n",
        "    res = re.sub(numbers, '', res)\n",
        "    res = re.sub(empty_brackets, '', res)\n",
        "    res = re.sub(',', '،', res)\n",
        "    res = re.sub(';', '؛', res)\n",
        "    res = re.sub(r'\\?', '؟', res)\n",
        "    res = re.sub(r'%', ' ', res)\n",
        "    res = re.sub(r'/', '', res)\n",
        "    res = re.sub(r'\\*', '', res)\n",
        "    res = re.sub(r'–', '-', res)\n",
        "    res = re.sub(r'_', ' - ', res)\n",
        "    res = re.sub(r'\\u2026', '.', res)\n",
        "    res = res.replace('\\u200f', '')\n",
        "    res = res.replace('\\u200d', '')\n",
        "    res = remove_formatting_codes(res)\n",
        "\n",
        "    res = remove_emojis(res)\n",
        "\n",
        "    res = clean_punctuation_sequence(res)\n",
        "\n",
        "    res = remove_unbalanced_brackets(res)\n",
        "\n",
        "    res = re.sub(r\"\\s+\", \" \", res).strip()\n",
        "\n",
        "    return res\n",
        "\n",
        "\n",
        "def split_citations_raw(line):\n",
        "    qal_list = [\n",
        "        \"قال\", \"قالت\", \"قالوا\", \"قلت\", \"قلنا\",\n",
        "        \"أقول\", \"يقول\", \"يقولون\", \"قيل\", \"يقال\"\n",
        "    ]\n",
        "\n",
        "    qal_regex = \"|\".join(qal_list)\n",
        "\n",
        "    qal_with_colon = rf\"(?:{qal_regex})\\s*[:：]\"\n",
        "\n",
        "\n",
        "    qawloho_regex = r\"(?:و|ف)?قول(?:ه)?(?:\\s*تعالى)?\"\n",
        "\n",
        "    trigger = rf\"({qal_with_colon}|{qawloho_regex})\"\n",
        "\n",
        "    final_lines = []\n",
        "    matches = list(re.finditer(trigger, line))\n",
        "\n",
        "    if not matches:\n",
        "        final_lines.append(line.strip())\n",
        "    else:\n",
        "        last_idx = 0\n",
        "        for m in matches:\n",
        "            start = m.start()\n",
        "            if line[last_idx:start]:\n",
        "                final_lines.append(line[last_idx:start])\n",
        "            last_idx = start\n",
        "\n",
        "        final_lines.append(line[last_idx:])\n",
        "\n",
        "    return final_lines\n",
        "\n",
        "def slide_window_raw(text, overlap=50, max_len=807):\n",
        "    if len(text) <= max_len:\n",
        "        return [text], [0]\n",
        "\n",
        "    chunks = []\n",
        "    overlaps = []\n",
        "\n",
        "    chunks.append(text[:max_len])\n",
        "    overlaps.append(0)\n",
        "\n",
        "    current_start = 0\n",
        "    text_len = len(text)\n",
        "\n",
        "    while True:\n",
        "        ideal_stride = max_len - overlap\n",
        "\n",
        "        ideal_next_start = current_start + ideal_stride\n",
        "\n",
        "        if ideal_next_start >= text_len:\n",
        "            break\n",
        "\n",
        "        found_next_start = -1\n",
        "\n",
        "        search_limit = current_start\n",
        "\n",
        "        for i in range(ideal_next_start, search_limit, -1):\n",
        "            if i < text_len and text[i] == ' ':\n",
        "                found_next_start = i + 1\n",
        "                break\n",
        "\n",
        "        if found_next_start == -1:\n",
        "            found_next_start = ideal_next_start\n",
        "\n",
        "        actual_overlap = (current_start + max_len) - found_next_start\n",
        "\n",
        "        if actual_overlap < 0:\n",
        "            actual_overlap = 0\n",
        "\n",
        "        next_chunk = text[found_next_start : found_next_start + max_len]\n",
        "\n",
        "        chunks.append(next_chunk)\n",
        "        overlaps.append(actual_overlap)\n",
        "\n",
        "        current_start = found_next_start\n",
        "\n",
        "        if current_start + max_len >= text_len:\n",
        "            break\n",
        "\n",
        "    return chunks, overlaps\n",
        "\n",
        "\n",
        "def prepare_for_predict():\n",
        "    all_recovery = []\n",
        "    assertions_text = []\n",
        "    assertions_tashkeel = []\n",
        "    test = True\n",
        "    curr_chunks = []\n",
        "    curr_overlaps = []\n",
        "\n",
        "    with open(f'{test_text_path}', \"r\", encoding=\"utf-8\") as file:\n",
        "\n",
        "        for line in file:\n",
        "\n",
        "            cleaned = initial_process(line.strip())\n",
        "            if test == True:\n",
        "                assertions_text.append(cleaned)\n",
        "                line = cleaned\n",
        "            else:\n",
        "                line, tashkeel = split_text_and_diacritics(cleaned)\n",
        "                assertions_text.append(line)\n",
        "                assertions_tashkeel.append(tashkeel)\n",
        "\n",
        "            raw_segments = split_citations_raw(line)\n",
        "            recovery = []\n",
        "\n",
        "            for seg in raw_segments:\n",
        "                t_chunks, t_overlaps = slide_window_raw(seg, overlap=50, max_len=807)\n",
        "                assert len(t_chunks) == len(t_overlaps), print(len(t_chunks), len(t_overlaps))\n",
        "\n",
        "                for i, chunk in enumerate(t_chunks):\n",
        "                    recovery.append(i)\n",
        "                    curr_chunks.append(chunk)\n",
        "\n",
        "                curr_overlaps.extend(t_overlaps)\n",
        "            all_recovery.append(recovery)\n",
        "\n",
        "    print(f\"Generated {len(curr_chunks)} chunks.\")\n",
        "    return curr_chunks, curr_overlaps, all_recovery, assertions_text, assertions_tashkeel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bdf5e723-557b-4b88-8ea2-fe7fd298194c",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-12-09T16:42:08.349327Z",
          "iopub.status.busy": "2025-12-09T16:42:08.349025Z",
          "iopub.status.idle": "2025-12-09T16:42:10.575568Z",
          "shell.execute_reply": "2025-12-09T16:42:10.574595Z",
          "shell.execute_reply.started": "2025-12-09T16:42:08.349302Z"
        },
        "id": "bdf5e723-557b-4b88-8ea2-fe7fd298194c",
        "outputId": "659f5a25-f010-4858-9151-683f79e46f75",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated 3191 chunks.\n"
          ]
        }
      ],
      "source": [
        "chunks, overlaps, recovery, assertions_text, assertions_tashkeel = prepare_for_predict()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "72140541",
      "metadata": {
        "id": "72140541"
      },
      "source": [
        "# Post Processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c88d970",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-12-09T16:42:10.576988Z",
          "iopub.status.busy": "2025-12-09T16:42:10.576549Z",
          "iopub.status.idle": "2025-12-09T16:42:10.585564Z",
          "shell.execute_reply": "2025-12-09T16:42:10.584807Z",
          "shell.execute_reply.started": "2025-12-09T16:42:10.576947Z"
        },
        "id": "7c88d970",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def reconstruct_text_window(chunks, overlaps):\n",
        "    if not chunks:\n",
        "        return \"\"\n",
        "\n",
        "    reconstructed_parts = []\n",
        "\n",
        "    for chunk, ov in zip(chunks[0:], overlaps):\n",
        "        reconstructed_parts.append(chunk[ov:])\n",
        "\n",
        "    return \"\".join(reconstructed_parts)\n",
        "\n",
        "\n",
        "def arabic_only_text_and_tashkeel(text, tashkeel):\n",
        "    ARABIC_CHARS = get_arabic_characters()\n",
        "    return \"\".join([char for char in text if char in ARABIC_CHARS or char == \" \"]), [tashkeel[i] for i, char in enumerate(text) if char in ARABIC_CHARS or char == \" \"]\n",
        "\n",
        "def arabic_only_text_and_tashkeel_no_spaces(text, tashkeel):\n",
        "    ARABIC_CHARS = get_arabic_characters()\n",
        "    return \"\".join([char for char in text if char in ARABIC_CHARS]), [tashkeel[i] for i, char in enumerate(text) if char in ARABIC_CHARS]\n",
        "\n",
        "def post_process(chunks, overlaps, recovery):\n",
        "    results = []\n",
        "    start_chnk_idx = 0\n",
        "    end_chnk_idx = 0\n",
        "\n",
        "    for i in range(len(recovery)):\n",
        "        zero_before = False\n",
        "        res = ''\n",
        "        for j in recovery[i]:\n",
        "            if j == 0:\n",
        "                if zero_before:\n",
        "                    res += reconstruct_text_window(chunks[start_chnk_idx:end_chnk_idx + 1], overlaps[start_chnk_idx:end_chnk_idx + 1])\n",
        "                    start_chnk_idx = end_chnk_idx + 1\n",
        "                    end_chnk_idx += 1\n",
        "                zero_before = True\n",
        "            else:\n",
        "                end_chnk_idx += 1\n",
        "\n",
        "        res += reconstruct_text_window(chunks[start_chnk_idx:end_chnk_idx + 1], overlaps[start_chnk_idx:end_chnk_idx + 1])\n",
        "        start_chnk_idx = end_chnk_idx + 1\n",
        "        end_chnk_idx += 1\n",
        "        results.append(res)\n",
        "\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "291b7a47-3b99-4580-88f2-8ebeaf026955",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-12-09T16:42:10.586781Z",
          "iopub.status.busy": "2025-12-09T16:42:10.586518Z",
          "iopub.status.idle": "2025-12-09T16:42:10.601425Z",
          "shell.execute_reply": "2025-12-09T16:42:10.600634Z",
          "shell.execute_reply.started": "2025-12-09T16:42:10.58676Z"
        },
        "id": "291b7a47-3b99-4580-88f2-8ebeaf026955",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def reconstruct_diacritics_window(chunks, overlaps):\n",
        "    if not chunks:\n",
        "        return np.array([])\n",
        "\n",
        "    reconstructed_parts = []\n",
        "\n",
        "    for chunk, ov in zip(chunks, overlaps):\n",
        "        reconstructed_parts.append(chunk[ov:])\n",
        "\n",
        "    return np.concatenate(reconstructed_parts)\n",
        "\n",
        "\n",
        "def post_process_diacritics(chunks, overlaps, recovery):\n",
        "    results = []\n",
        "    start_chnk_idx = 0\n",
        "    end_chnk_idx = 0\n",
        "\n",
        "    for i in range(len(recovery)):\n",
        "        zero_before = False\n",
        "\n",
        "        res = np.array([], dtype=int)\n",
        "\n",
        "        for j in recovery[i]:\n",
        "            if j == 0:\n",
        "                if zero_before:\n",
        "                    segment = reconstruct_diacritics_window(\n",
        "                        chunks[start_chnk_idx : end_chnk_idx + 1],\n",
        "                        overlaps[start_chnk_idx : end_chnk_idx + 1]\n",
        "                    )\n",
        "                    res = np.concatenate([res, segment])\n",
        "\n",
        "                    start_chnk_idx = end_chnk_idx + 1\n",
        "                    end_chnk_idx += 1\n",
        "                zero_before = True\n",
        "            else:\n",
        "                end_chnk_idx += 1\n",
        "\n",
        "        segment = reconstruct_diacritics_window(\n",
        "            chunks[start_chnk_idx : end_chnk_idx + 1],\n",
        "            overlaps[start_chnk_idx : end_chnk_idx + 1]\n",
        "        )\n",
        "        res = np.concatenate([res, segment])\n",
        "\n",
        "        start_chnk_idx = end_chnk_idx + 1\n",
        "        end_chnk_idx += 1\n",
        "\n",
        "        results.append(res)\n",
        "\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "70f52a9d-ef07-4ffc-aa7b-01a70eee1860",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-12-09T16:42:10.602474Z",
          "iopub.status.busy": "2025-12-09T16:42:10.602211Z",
          "iopub.status.idle": "2025-12-09T16:42:10.617043Z",
          "shell.execute_reply": "2025-12-09T16:42:10.616196Z",
          "shell.execute_reply.started": "2025-12-09T16:42:10.602453Z"
        },
        "id": "70f52a9d-ef07-4ffc-aa7b-01a70eee1860",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def get_finals(results, labels, tokens=True):\n",
        "    flat_labels = list(itertools.chain.from_iterable(labels))\n",
        "    if tokens:\n",
        "        new_flat_labels = [idx2label[label] for label in flat_labels]\n",
        "    else:\n",
        "        new_flat_labels = flat_labels\n",
        "    idx = 0\n",
        "    final_results = []\n",
        "    for result in results:\n",
        "        final_str = ''\n",
        "        for char in result:\n",
        "            final_str += char + new_flat_labels[idx]\n",
        "            idx += 1\n",
        "        final_results.append(final_str)\n",
        "    return final_results"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c802d3df",
      "metadata": {
        "id": "c802d3df"
      },
      "source": [
        "# Extract Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c12ea8cd",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "8140959da46f42ee8a4a401f6b1f28e2",
            "8d07821ba1d14c7b89d373827d49610f",
            "cba0c12cb6684ebabd74bbcb95174dda",
            "2c838b514c2d41b3888663725733c233",
            "9f8a72432f9f4174b3bc0b90c34347eb",
            "80aacb804efa45ae92791d13c56a642a"
          ]
        },
        "execution": {
          "iopub.execute_input": "2025-12-09T16:42:10.618073Z",
          "iopub.status.busy": "2025-12-09T16:42:10.617786Z",
          "iopub.status.idle": "2025-12-09T16:42:22.619692Z",
          "shell.execute_reply": "2025-12-09T16:42:22.618814Z",
          "shell.execute_reply.started": "2025-12-09T16:42:10.618045Z"
        },
        "id": "c12ea8cd",
        "outputId": "ec94c1c3-6707-4b9d-aee8-b889cc8455c9",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8140959da46f42ee8a4a401f6b1f28e2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/392 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8d07821ba1d14c7b89d373827d49610f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/503 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cba0c12cb6684ebabd74bbcb95174dda",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2c838b514c2d41b3888663725733c233",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9f8a72432f9f4174b3bc0b90c34347eb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "80aacb804efa45ae92791d13c56a642a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/541M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "# arabert_model_name = \"aubmindlab/bert-base-arabertv02\"\n",
        "# bert_tokenizer = AutoTokenizer.from_pretrained(arabert_model_name)\n",
        "# bert_model = AutoModel.from_pretrained(arabert_model_name)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# bert_model.to(device)\n",
        "# bert_model.eval()\n",
        "# arabert_prep = ArabertPreprocessor(model_name=arabert_model_name)\n",
        "\n",
        "\n",
        "MODEL_NAME = \"aubmindlab/araelectra-base-discriminator\"\n",
        "\n",
        "electra_tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "electra_model = AutoModel.from_pretrained(MODEL_NAME)\n",
        "electra_model.to(device)\n",
        "electra_model.eval()\n",
        "\n",
        "\n",
        "custom_char_embedding = np.load(char_embeddings_path)\n",
        "\n",
        "# def get_arabert_embeddings(sentence: str):\n",
        "\n",
        "#     tokens = bert_tokenizer(sentence, return_tensors=\"pt\", truncation=True, padding=True)\n",
        "#     tokens = {k: v.to(device) for k, v in tokens.items()}\n",
        "\n",
        "#     with torch.no_grad():\n",
        "#         output = bert_model(**tokens)\n",
        "\n",
        "#     emb = output.last_hidden_state.squeeze(0).cpu()\n",
        "#     token_list = bert_tokenizer.convert_ids_to_tokens(tokens[\"input_ids\"][0])\n",
        "\n",
        "#     return emb.numpy(), token_list\n",
        "\n",
        "\n",
        "def get_araelectra_embeddings(sentence, device=\"cuda\"):\n",
        "    \"\"\"\n",
        "    Get token-level embeddings from AraELECTRA\n",
        "    Returns a list of sentence embeddings (list of token embeddings)\n",
        "    \"\"\"\n",
        "    electra_model.to(device)\n",
        "    inputs = electra_tokenizer(sentence, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
        "    token_ids = inputs['input_ids'][0]\n",
        "\n",
        "    # 2. Convert those IDs back to text tokens\n",
        "    tokens = electra_tokenizer.convert_ids_to_tokens(token_ids)\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "    # Get outputs (last hidden state)\n",
        "    with torch.no_grad():\n",
        "        outputs = electra_model(**inputs)\n",
        "        last_hidden_state = outputs.last_hidden_state  # [batch_size, seq_len, hidden_size]\n",
        "    # Remove batch dimension and convert to list of embeddings per token\n",
        "    token_embeddings = last_hidden_state.squeeze(0)  # [seq_len, hidden_size]\n",
        "    return token_embeddings, tokens\n",
        "\n",
        "def extract_custom_char_embeddings(char):\n",
        "    char2idx, _ = get_char_map()\n",
        "    return custom_char_embedding[char2idx[char]]\n",
        "\n",
        "def tokens_to_word_embeddings(tokens, embeddings):\n",
        "    word_embeddings = []\n",
        "    current_word_embs = []\n",
        "\n",
        "    for token, emb in zip(tokens, embeddings):\n",
        "        emb_tensor = torch.tensor(emb) if isinstance(emb, np.ndarray) else emb\n",
        "\n",
        "        if token.startswith(\"##\"):\n",
        "            current_word_embs.append(emb_tensor)\n",
        "        else:\n",
        "            if current_word_embs:\n",
        "                word_embeddings.append(torch.mean(torch.stack(current_word_embs), dim=0))\n",
        "            current_word_embs = [emb_tensor]\n",
        "\n",
        "    if current_word_embs:\n",
        "        word_embeddings.append(torch.mean(torch.stack(current_word_embs), dim=0))\n",
        "\n",
        "    return torch.stack(word_embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c192470",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-12-09T16:42:22.620938Z",
          "iopub.status.busy": "2025-12-09T16:42:22.620626Z",
          "iopub.status.idle": "2025-12-09T16:42:22.632323Z",
          "shell.execute_reply": "2025-12-09T16:42:22.631297Z",
          "shell.execute_reply.started": "2025-12-09T16:42:22.620911Z"
        },
        "id": "6c192470",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# def zizo_features(sentence: str):\n",
        "\n",
        "#     sentence_vec = []\n",
        "\n",
        "#     arabert_emb, tokens = get_arabert_embeddings(sentence)\n",
        "#     final_arabert_emb = tokens_to_word_embeddings(tokens, arabert_emb)\n",
        "\n",
        "#     words_raw = sentence.split()\n",
        "#     word_idx = 0\n",
        "#     char_in_word_idx = 0\n",
        "\n",
        "#     emb_dim = final_arabert_emb[0].shape[0]\n",
        "\n",
        "#     for i, char in enumerate(sentence):\n",
        "\n",
        "#         char_emb = extract_custom_char_embeddings(char)\n",
        "#         char_emb_array = np.array(char_emb).flatten()\n",
        "\n",
        "#         if char == ' ':\n",
        "#             bert_vec = np.zeros(emb_dim)\n",
        "\n",
        "#         else:\n",
        "#             bert_vec = final_arabert_emb[word_idx]\n",
        "#             if isinstance(bert_vec, torch.Tensor):\n",
        "#                 bert_vec = bert_vec.numpy()\n",
        "\n",
        "#             char_in_word_idx += 1\n",
        "\n",
        "#             if char_in_word_idx == len(words_raw[word_idx]):\n",
        "#                 word_idx += 1\n",
        "#                 char_in_word_idx = 0\n",
        "\n",
        "#         char_vector = np.concatenate([bert_vec, char_emb_array])\n",
        "#         sentence_vec.append(char_vector)\n",
        "\n",
        "#     return sentence_vec\n",
        "\n",
        "def zizo_features_electra(sentence: str):\n",
        "\n",
        "    sentence_vec = []\n",
        "\n",
        "    araelectra_emb, tokens = get_araelectra_embeddings(sentence)\n",
        "    final_araelectra_emb = tokens_to_word_embeddings(tokens, araelectra_emb)\n",
        "\n",
        "    words_raw = sentence.split()\n",
        "    word_idx = 0\n",
        "    char_in_word_idx = 0\n",
        "\n",
        "    emb_dim = final_araelectra_emb[0].shape[0]\n",
        "\n",
        "    for i, char in enumerate(sentence):\n",
        "\n",
        "        char_emb = extract_custom_char_embeddings(char)\n",
        "        char_emb_array = np.array(char_emb).flatten()\n",
        "\n",
        "        if char in punctuation:\n",
        "            araelectra_vec = np.zeros(emb_dim)\n",
        "\n",
        "        else:\n",
        "            araelectra_vec = final_araelectra_emb[word_idx]\n",
        "            if isinstance(araelectra_vec, torch.Tensor):\n",
        "                araelectra_vec = araelectra_vec.cpu().numpy()\n",
        "\n",
        "            char_in_word_idx += 1\n",
        "\n",
        "            if char_in_word_idx == len(words_raw[word_idx]):\n",
        "                word_idx += 1\n",
        "                char_in_word_idx = 0\n",
        "\n",
        "        char_vector = np.concatenate([araelectra_vec, char_emb_array])\n",
        "        sentence_vec.append(char_vector)\n",
        "\n",
        "    return sentence_vec\n",
        "\n",
        "# def extract_features(sentences):\n",
        "#     all_sentence_features = []\n",
        "\n",
        "#     for i in tqdm(range(len(sentences)), total=len(sentences), desc=\"extracting features\"):\n",
        "#         sent = sentences[i]\n",
        "#         features_list = zizo_features(\"\".join(sent))\n",
        "\n",
        "#         all_sentence_features.append(np.array(features_list, dtype=np.float16))\n",
        "\n",
        "#     return all_sentence_features\n",
        "\n",
        "def extract_features_electra(sentences):\n",
        "    all_sentence_features = []\n",
        "\n",
        "    for i in tqdm(range(len(sentences)), total=len(sentences), desc=\"extracting features\"):\n",
        "        sent = sentences[i]\n",
        "        features_list = zizo_features_electra(\"\".join(sent))\n",
        "\n",
        "        all_sentence_features.append(np.array(features_list, dtype=np.float16))\n",
        "\n",
        "    return all_sentence_features"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3cf52ca1",
      "metadata": {
        "id": "3cf52ca1"
      },
      "source": [
        "# Predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b99d3ec0-0608-48c7-903a-e53daae9f4ac",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-12-09T16:42:22.633593Z",
          "iopub.status.busy": "2025-12-09T16:42:22.63331Z",
          "iopub.status.idle": "2025-12-09T16:42:33.508508Z",
          "shell.execute_reply": "2025-12-09T16:42:33.507675Z",
          "shell.execute_reply.started": "2025-12-09T16:42:22.633569Z"
        },
        "id": "b99d3ec0-0608-48c7-903a-e53daae9f4ac",
        "outputId": "20a799ac-4393-4c75-fde5-a778db9f45ce",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "I0000 00:00:1765298542.991061      47 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13392 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "I0000 00:00:1765298542.991757      47 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13942 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n"
          ]
        }
      ],
      "source": [
        "electra_all_model = tf.keras.models.load_model(f'/kaggle/input/arabic-diacritizer-araelectra-all-v2/keras/1/1/araelectra_all_v2.keras', compile=False)\n",
        "electra_lastchar_model = tf.keras.models.load_model(f'/kaggle/input/last_char_electra_test_v3/keras/1/1/last_char_electra_test_v3.keras', compile=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed31e647",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-12-09T16:42:33.509971Z",
          "iopub.status.busy": "2025-12-09T16:42:33.509706Z",
          "iopub.status.idle": "2025-12-09T16:42:33.524284Z",
          "shell.execute_reply": "2025-12-09T16:42:33.523483Z",
          "shell.execute_reply.started": "2025-12-09T16:42:33.50995Z"
        },
        "id": "ed31e647",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "\n",
        "# Configuration\n",
        "INTAHA = r'\\s+ا\\s*هـ?\\s+'\n",
        "BATCH_SIZE = 32\n",
        "PADDING_INPUT = -99999.0\n",
        "INPUT_DIM = 1024\n",
        "\n",
        "# [FIX 1] Added 'features' argument (it was missing in your definition)\n",
        "def predict(text_chunks):\n",
        "\n",
        "    # [FIX 2] Calculate Global Max Length to prevent retracing\n",
        "    # We find the longest sentence in the entire dataset\n",
        "    global_max_len = max([len(f) for f in features])\n",
        "\n",
        "    # Optional: You can cap this if you have outliers (e.g., min(global_max_len, 512))\n",
        "    print(f\"Padding all batches to fixed length: {global_max_len}\")\n",
        "\n",
        "    sentence_lengths = [len(f) for f in features]\n",
        "\n",
        "    def test_set_generator():\n",
        "        for i in range(len(features)):\n",
        "            yield features[i], [sentence_lengths[i]], text_chunks[i]\n",
        "\n",
        "    test_dataset = tf.data.Dataset.from_generator(\n",
        "        test_set_generator,\n",
        "        output_signature=(\n",
        "            tf.TensorSpec(shape=(None, INPUT_DIM), dtype=tf.float32),\n",
        "            tf.TensorSpec(shape=(1,), dtype=tf.int32),\n",
        "            tf.TensorSpec(shape=(), dtype=tf.string)\n",
        "        )\n",
        "    ).padded_batch(\n",
        "        BATCH_SIZE,\n",
        "        # [FIX 3] Enforce Fixed Shapes\n",
        "        # Instead of 'None' (dynamic), we use 'global_max_len'\n",
        "        padded_shapes=(\n",
        "            [global_max_len, INPUT_DIM],\n",
        "            [1],\n",
        "            []\n",
        "        ),\n",
        "        padding_values=(PADDING_INPUT, 0, \"\")\n",
        "    )\n",
        "\n",
        "    all_predictions = []\n",
        "\n",
        "    print(\"Starting prediction...\")\n",
        "\n",
        "    # Using predict_on_batch inside a loop is okay now because\n",
        "    # the input shape is CONSTANT (Batch_Size, Global_Max_Len, 1024)\n",
        "    for batch_x, batch_lens, batch_text in test_dataset:\n",
        "\n",
        "        batch_probs = electra_all_model.predict_on_batch(batch_x)\n",
        "        batch_pred_ids = np.argmax(batch_probs, axis=-1)\n",
        "\n",
        "        batch_probs_lc = electra_lastchar_model.predict_on_batch(batch_x)\n",
        "        batch_pred_ids_lc = np.argmax(batch_probs_lc, axis=-1)\n",
        "\n",
        "        current_batch_lengths = batch_lens.numpy().flatten()\n",
        "        batch_size_current = batch_pred_ids.shape[0]\n",
        "\n",
        "        for k in range(batch_size_current):\n",
        "\n",
        "            valid_len = current_batch_lengths[k]\n",
        "\n",
        "            # Decode text\n",
        "            current_text_str = batch_text[k].numpy().decode('utf-8')\n",
        "\n",
        "            # Slice to valid length (remove the global padding)\n",
        "            pred_seq = batch_pred_ids[k][:valid_len]\n",
        "\n",
        "            # Safety slice for text\n",
        "            current_text_str = current_text_str[:valid_len]\n",
        "\n",
        "            # Logic to merge models\n",
        "            for i, char in enumerate(current_text_str):\n",
        "                if char == ' ':\n",
        "                    if i > 0:\n",
        "                        pred_seq[i - 1] = batch_pred_ids_lc[k][i - 1]\n",
        "\n",
        "            if len(current_text_str) > 0 and current_text_str[-1] != ' ':\n",
        "                pred_seq[-1] = batch_pred_ids_lc[k][valid_len - 1]\n",
        "\n",
        "            all_predictions.append(pred_seq)\n",
        "\n",
        "    return all_predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7fc4acfb-37d7-4de4-b3d2-312fdf6577a2",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-12-09T16:42:33.525418Z",
          "iopub.status.busy": "2025-12-09T16:42:33.525126Z",
          "iopub.status.idle": "2025-12-09T16:47:31.56625Z",
          "shell.execute_reply": "2025-12-09T16:47:31.565513Z",
          "shell.execute_reply.started": "2025-12-09T16:42:33.525394Z"
        },
        "id": "7fc4acfb-37d7-4de4-b3d2-312fdf6577a2",
        "outputId": "29b93edb-268f-42cb-a556-56b33285236f",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "extracting features: 100%|██████████| 3191/3191 [04:58<00:00, 10.71it/s]\n"
          ]
        }
      ],
      "source": [
        "punctuation = ['.', ':', '{', '}', '[', ']', '(', ')', '؛', '«', '»', '!', '،', '؟', '-', ' ']\n",
        "features = extract_features_electra(chunks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a087e846-8394-43c3-ab62-971a014f9a95",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-12-09T16:47:31.570322Z",
          "iopub.status.busy": "2025-12-09T16:47:31.570064Z",
          "iopub.status.idle": "2025-12-09T16:48:29.458424Z",
          "shell.execute_reply": "2025-12-09T16:48:29.457529Z",
          "shell.execute_reply.started": "2025-12-09T16:47:31.570302Z"
        },
        "id": "a087e846-8394-43c3-ab62-971a014f9a95",
        "outputId": "0fb0c27b-4669-40e4-9308-e8da7d09f6bf",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Padding all batches to fixed length: 807\n",
            "Starting prediction...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "I0000 00:00:1765298854.091937     161 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
          ]
        }
      ],
      "source": [
        "all_predictions = predict(chunks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "834b3cbf-b688-441b-a8f9-05a4fd62c062",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-12-09T16:48:29.459764Z",
          "iopub.status.busy": "2025-12-09T16:48:29.459437Z",
          "iopub.status.idle": "2025-12-09T16:48:29.463986Z",
          "shell.execute_reply": "2025-12-09T16:48:29.463344Z",
          "shell.execute_reply.started": "2025-12-09T16:48:29.459741Z"
        },
        "id": "834b3cbf-b688-441b-a8f9-05a4fd62c062",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# results = post_process(chunks, overlaps, recovery)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e704182-cbcf-495f-8c71-61babaedc3cb",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-12-09T16:48:29.465138Z",
          "iopub.status.busy": "2025-12-09T16:48:29.464858Z",
          "iopub.status.idle": "2025-12-09T16:48:29.494328Z",
          "shell.execute_reply": "2025-12-09T16:48:29.493541Z",
          "shell.execute_reply.started": "2025-12-09T16:48:29.465108Z"
        },
        "id": "0e704182-cbcf-495f-8c71-61babaedc3cb",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "pred_diac = post_process_diacritics(all_predictions, overlaps, recovery)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37dc0fc2-5e02-4eb4-b080-6b5d238e4650",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-12-09T16:48:29.49535Z",
          "iopub.status.busy": "2025-12-09T16:48:29.495121Z",
          "iopub.status.idle": "2025-12-09T16:48:29.498783Z",
          "shell.execute_reply": "2025-12-09T16:48:29.497978Z",
          "shell.execute_reply.started": "2025-12-09T16:48:29.495327Z"
        },
        "id": "37dc0fc2-5e02-4eb4-b080-6b5d238e4650",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# predicted_text = get_finals(results, pred_diac)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1769536-700a-4df6-a9f1-56feb1c34c16",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-12-09T16:48:29.499864Z",
          "iopub.status.busy": "2025-12-09T16:48:29.499535Z",
          "iopub.status.idle": "2025-12-09T16:48:29.518509Z",
          "shell.execute_reply": "2025-12-09T16:48:29.517839Z",
          "shell.execute_reply.started": "2025-12-09T16:48:29.499834Z"
        },
        "id": "b1769536-700a-4df6-a9f1-56feb1c34c16",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "with open(f'{test_text_path}', \"r\", encoding=\"utf-8\") as file:\n",
        "    lines = file.readlines()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d8e0126d-10fc-48f3-beac-e17f98a49a3f",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-12-09T16:48:29.519528Z",
          "iopub.status.busy": "2025-12-09T16:48:29.519251Z",
          "iopub.status.idle": "2025-12-09T16:48:29.523642Z",
          "shell.execute_reply": "2025-12-09T16:48:29.522921Z",
          "shell.execute_reply.started": "2025-12-09T16:48:29.519511Z"
        },
        "id": "d8e0126d-10fc-48f3-beac-e17f98a49a3f",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# start_index = 0\n",
        "# current_lines = lines\n",
        "# current_preds = predicted_text\n",
        "# matches = 0\n",
        "# total = 0\n",
        "\n",
        "# for line_str, pred_str in zip(current_lines, current_preds):\n",
        "#     og_text, og_tashkeel = split_text_and_diacritics(initial_process(line_str.strip()))\n",
        "#     ll, og = arabic_only_text_and_tashkeel(og_text, og_tashkeel)\n",
        "\n",
        "#     pred_text, pred_tashkeel = split_text_and_diacritics(pred_str.strip())\n",
        "#     _, pred = arabic_only_text_and_tashkeel(pred_text, pred_tashkeel)\n",
        "\n",
        "#     for i, (char, o, p) in enumerate(zip(ll, og, pred)):\n",
        "\n",
        "#         if char == ' ':\n",
        "#             continue\n",
        "\n",
        "#         is_last_char = (i == len(ll) - 1) or (ll[i+1] == ' ')\n",
        "\n",
        "#         if not is_last_char:\n",
        "#             if o == p:\n",
        "#                 matches += 1\n",
        "#             total += 1\n",
        "\n",
        "# print(f\"Internal Diacritic Accuracy (No Last Char): {matches * 100 / total:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "835ce1bc-564b-47ca-8b6a-89a374eaead4",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-12-09T16:48:29.524506Z",
          "iopub.status.busy": "2025-12-09T16:48:29.524292Z",
          "iopub.status.idle": "2025-12-09T16:48:29.538569Z",
          "shell.execute_reply": "2025-12-09T16:48:29.53776Z",
          "shell.execute_reply.started": "2025-12-09T16:48:29.52449Z"
        },
        "id": "835ce1bc-564b-47ca-8b6a-89a374eaead4",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c895400-79fd-49f2-9b1f-906698aca7e9",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-12-09T16:48:29.539738Z",
          "iopub.status.busy": "2025-12-09T16:48:29.539486Z",
          "iopub.status.idle": "2025-12-09T16:48:33.110943Z",
          "shell.execute_reply": "2025-12-09T16:48:33.10999Z",
          "shell.execute_reply.started": "2025-12-09T16:48:29.539719Z"
        },
        "id": "3c895400-79fd-49f2-9b1f-906698aca7e9",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "start_index = 0\n",
        "current_lines = lines\n",
        "current_preds = pred_diac\n",
        "matches = 0\n",
        "total = 0\n",
        "all_labels = []\n",
        "\n",
        "for line_str, pred_label in zip(current_lines, current_preds):\n",
        "    cleaned = initial_process(line_str.strip())\n",
        "    new_sent, pred = arabic_only_text_and_tashkeel_no_spaces(cleaned, pred_label)\n",
        "    all_labels.extend(pred)\n",
        "\n",
        "ids = [i for i in range(len(all_labels))]\n",
        "# print(f\"Internal Diacritic Accuracy (No Last Char): {matches * 100 / total:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "42098910-a2d8-47bb-a7cc-54db29dda8a8",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-12-09T16:48:33.112096Z",
          "iopub.status.busy": "2025-12-09T16:48:33.111834Z",
          "iopub.status.idle": "2025-12-09T16:48:33.647469Z",
          "shell.execute_reply": "2025-12-09T16:48:33.646575Z",
          "shell.execute_reply.started": "2025-12-09T16:48:33.112072Z"
        },
        "id": "42098910-a2d8-47bb-a7cc-54db29dda8a8",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame({\n",
        "    'ID': ids,\n",
        "    'label': all_labels\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d06ced6d-1319-4927-88f1-82a6cc3bc65f",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-12-09T16:48:33.648605Z",
          "iopub.status.busy": "2025-12-09T16:48:33.648337Z",
          "iopub.status.idle": "2025-12-09T16:48:33.770366Z",
          "shell.execute_reply": "2025-12-09T16:48:33.769447Z",
          "shell.execute_reply.started": "2025-12-09T16:48:33.648587Z"
        },
        "id": "d06ced6d-1319-4927-88f1-82a6cc3bc65f",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "test_df = pd.read_csv('/kaggle/input/normal/test_no_diacritics.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa984914-f241-4202-87a7-dc679f31169d",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-12-09T16:48:33.772081Z",
          "iopub.status.busy": "2025-12-09T16:48:33.771403Z",
          "iopub.status.idle": "2025-12-09T16:48:33.948649Z",
          "shell.execute_reply": "2025-12-09T16:48:33.947714Z",
          "shell.execute_reply.started": "2025-12-09T16:48:33.772059Z"
        },
        "id": "fa984914-f241-4202-87a7-dc679f31169d",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "df.to_csv('submissions_all_chars_4.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28d88017-3e5b-46ed-b0ab-5c0e11d0bef3",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-12-09T16:49:49.413965Z",
          "iopub.status.busy": "2025-12-09T16:49:49.413499Z",
          "iopub.status.idle": "2025-12-09T16:49:49.453877Z",
          "shell.execute_reply": "2025-12-09T16:49:49.452824Z",
          "shell.execute_reply.started": "2025-12-09T16:49:49.413927Z"
        },
        "id": "28d88017-3e5b-46ed-b0ab-5c0e11d0bef3",
        "outputId": "4ebde01a-c011-46dc-dcaa-78040fdb3293",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>line_number</th>\n",
              "      <th>letter</th>\n",
              "      <th>case_ending</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>ف</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>ي</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>ا</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>ل</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>م</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>237235</th>\n",
              "      <td>237235</td>\n",
              "      <td>2468</td>\n",
              "      <td>ب</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>237236</th>\n",
              "      <td>237236</td>\n",
              "      <td>2468</td>\n",
              "      <td>ن</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>237237</th>\n",
              "      <td>237237</td>\n",
              "      <td>2468</td>\n",
              "      <td>ش</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>237238</th>\n",
              "      <td>237238</td>\n",
              "      <td>2468</td>\n",
              "      <td>ي</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>237239</th>\n",
              "      <td>237239</td>\n",
              "      <td>2468</td>\n",
              "      <td>ء</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>237240 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            id  line_number letter  case_ending\n",
              "0            0            0      ف        False\n",
              "1            1            0      ي         True\n",
              "2            2            0      ا        False\n",
              "3            3            0      ل        False\n",
              "4            4            0      م        False\n",
              "...        ...          ...    ...          ...\n",
              "237235  237235         2468      ب        False\n",
              "237236  237236         2468      ن         True\n",
              "237237  237237         2468      ش        False\n",
              "237238  237238         2468      ي        False\n",
              "237239  237239         2468      ء         True\n",
              "\n",
              "[237240 rows x 4 columns]"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ed41dc0-5a9a-4284-bbde-17d25823ed5c",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-12-09T16:49:49.699995Z",
          "iopub.status.busy": "2025-12-09T16:49:49.699715Z",
          "iopub.status.idle": "2025-12-09T16:49:49.709012Z",
          "shell.execute_reply": "2025-12-09T16:49:49.708055Z",
          "shell.execute_reply.started": "2025-12-09T16:49:49.699975Z"
        },
        "id": "3ed41dc0-5a9a-4284-bbde-17d25823ed5c",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "test_df_ce = test_df[test_df['case_ending'] == True]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ba116e3-e169-4c2a-97bf-9b3d5541044d",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-12-09T16:49:50.024143Z",
          "iopub.status.busy": "2025-12-09T16:49:50.023864Z",
          "iopub.status.idle": "2025-12-09T16:49:50.034142Z",
          "shell.execute_reply": "2025-12-09T16:49:50.033418Z",
          "shell.execute_reply.started": "2025-12-09T16:49:50.02412Z"
        },
        "id": "6ba116e3-e169-4c2a-97bf-9b3d5541044d",
        "outputId": "31c6bb44-dba4-4c6d-a953-ce62e14ab581",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>line_number</th>\n",
              "      <th>letter</th>\n",
              "      <th>case_ending</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>ي</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>ل</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>م</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>18</td>\n",
              "      <td>0</td>\n",
              "      <td>د</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>ن</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>237224</th>\n",
              "      <td>237224</td>\n",
              "      <td>2468</td>\n",
              "      <td>ا</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>237228</th>\n",
              "      <td>237228</td>\n",
              "      <td>2468</td>\n",
              "      <td>ن</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>237231</th>\n",
              "      <td>237231</td>\n",
              "      <td>2468</td>\n",
              "      <td>ى</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>237236</th>\n",
              "      <td>237236</td>\n",
              "      <td>2468</td>\n",
              "      <td>ن</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>237239</th>\n",
              "      <td>237239</td>\n",
              "      <td>2468</td>\n",
              "      <td>ء</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>56736 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            id  line_number letter  case_ending\n",
              "1            1            0      ي         True\n",
              "7            7            0      ل         True\n",
              "12          12            0      م         True\n",
              "18          18            0      د         True\n",
              "20          20            0      ن         True\n",
              "...        ...          ...    ...          ...\n",
              "237224  237224         2468      ا         True\n",
              "237228  237228         2468      ن         True\n",
              "237231  237231         2468      ى         True\n",
              "237236  237236         2468      ن         True\n",
              "237239  237239         2468      ء         True\n",
              "\n",
              "[56736 rows x 4 columns]"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_df_ce"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "530068a2-9ae8-4ec8-8904-5fbe2b0f067b",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-12-09T16:49:52.593948Z",
          "iopub.status.busy": "2025-12-09T16:49:52.593124Z",
          "iopub.status.idle": "2025-12-09T16:49:52.611422Z",
          "shell.execute_reply": "2025-12-09T16:49:52.610505Z",
          "shell.execute_reply.started": "2025-12-09T16:49:52.593919Z"
        },
        "id": "530068a2-9ae8-4ec8-8904-5fbe2b0f067b",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "ce_df = df[df['ID'].isin(test_df_ce['id'])]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d633c748-e5c5-441b-b089-1decc714ad1f",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-12-09T16:49:53.179803Z",
          "iopub.status.busy": "2025-12-09T16:49:53.178957Z",
          "iopub.status.idle": "2025-12-09T16:49:53.188145Z",
          "shell.execute_reply": "2025-12-09T16:49:53.187358Z",
          "shell.execute_reply.started": "2025-12-09T16:49:53.179777Z"
        },
        "id": "d633c748-e5c5-441b-b089-1decc714ad1f",
        "outputId": "ac922b26-bfbc-44d6-a13f-5370bd936ece",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>208</th>\n",
              "      <td>208</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      ID  label\n",
              "208  208     14"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ce_df[ce_df['ID'] == 208]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "091d363a-21b4-4111-ae3e-5e91a59043aa",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-12-09T16:49:54.133387Z",
          "iopub.status.busy": "2025-12-09T16:49:54.132634Z",
          "iopub.status.idle": "2025-12-09T16:49:54.17966Z",
          "shell.execute_reply": "2025-12-09T16:49:54.178816Z",
          "shell.execute_reply.started": "2025-12-09T16:49:54.13336Z"
        },
        "id": "091d363a-21b4-4111-ae3e-5e91a59043aa",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "ce_df.to_csv('submissions_last_char_2.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bde2b3f1-04ef-4643-849f-01b9829304f0",
      "metadata": {
        "id": "bde2b3f1-04ef-4643-849f-01b9829304f0",
        "trusted": true
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "full_pipeline",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "datasetId": 8855126,
          "sourceId": 13898942,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 8861767,
          "sourceId": 13908408,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 8916698,
          "sourceId": 13989718,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 8943213,
          "sourceId": 14047777,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 8943230,
          "sourceId": 14047800,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 8958050,
          "sourceId": 14072827,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 8958271,
          "sourceId": 14073120,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 8958780,
          "sourceId": 14073839,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 8958800,
          "sourceId": 14073869,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 8958802,
          "sourceId": 14073872,
          "sourceType": "datasetVersion"
        },
        {
          "isSourceIdPinned": true,
          "modelId": 525712,
          "modelInstanceId": 511023,
          "sourceId": 674220,
          "sourceType": "modelInstanceVersion"
        },
        {
          "isSourceIdPinned": true,
          "modelId": 526936,
          "modelInstanceId": 512293,
          "sourceId": 675738,
          "sourceType": "modelInstanceVersion"
        },
        {
          "isSourceIdPinned": true,
          "modelId": 527061,
          "modelInstanceId": 512419,
          "sourceId": 675905,
          "sourceType": "modelInstanceVersion"
        },
        {
          "isSourceIdPinned": true,
          "modelId": 528054,
          "modelInstanceId": 513419,
          "sourceId": 677088,
          "sourceType": "modelInstanceVersion"
        },
        {
          "isSourceIdPinned": true,
          "modelId": 528434,
          "modelInstanceId": 513795,
          "sourceId": 677554,
          "sourceType": "modelInstanceVersion"
        },
        {
          "isSourceIdPinned": true,
          "modelId": 528556,
          "modelInstanceId": 513917,
          "sourceId": 677697,
          "sourceType": "modelInstanceVersion"
        },
        {
          "isSourceIdPinned": true,
          "modelId": 528785,
          "modelInstanceId": 514142,
          "sourceId": 677958,
          "sourceType": "modelInstanceVersion"
        },
        {
          "isSourceIdPinned": true,
          "modelId": 528853,
          "modelInstanceId": 514211,
          "sourceId": 678037,
          "sourceType": "modelInstanceVersion"
        },
        {
          "isSourceIdPinned": true,
          "modelId": 528876,
          "modelInstanceId": 514234,
          "sourceId": 678063,
          "sourceType": "modelInstanceVersion"
        }
      ],
      "dockerImageVersionId": 31192,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "project (3.12.3)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
